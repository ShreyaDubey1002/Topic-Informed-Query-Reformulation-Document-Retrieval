{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d286f79ed8ae479dbc98e1ed1c59f47a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a365d4dfabb64bdea8cd220945213a36",
              "IPY_MODEL_e44a559288254026837cdb1681d4cad1",
              "IPY_MODEL_1ba3c4387a77463c88765de16ba2a8e0"
            ],
            "layout": "IPY_MODEL_997503bac1c2446f9f3cfdb711aa33c7"
          }
        },
        "a365d4dfabb64bdea8cd220945213a36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_110fd9ac470f4f37ab8db2eba7786899",
            "placeholder": "​",
            "style": "IPY_MODEL_e13b1a5dfc1c4cdb8914b2097056c7c1",
            "value": "Downloading: 100%"
          }
        },
        "e44a559288254026837cdb1681d4cad1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d66dc87e563849978362149e1eec1189",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ce9e93898b6a47aa8f6205dc12855000",
            "value": 28
          }
        },
        "1ba3c4387a77463c88765de16ba2a8e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f7c71bcfbf74983acef4450f706ca6b",
            "placeholder": "​",
            "style": "IPY_MODEL_86089fade5284cf4a8ccf35d58830600",
            "value": " 28.0/28.0 [00:00&lt;00:00, 818B/s]"
          }
        },
        "997503bac1c2446f9f3cfdb711aa33c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "110fd9ac470f4f37ab8db2eba7786899": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e13b1a5dfc1c4cdb8914b2097056c7c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d66dc87e563849978362149e1eec1189": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce9e93898b6a47aa8f6205dc12855000": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3f7c71bcfbf74983acef4450f706ca6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86089fade5284cf4a8ccf35d58830600": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "725ead6763d34f06906e99cbd25d36f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_858b2620103345f1a7405cf0677853c0",
              "IPY_MODEL_a27f4abf5e9a47deb03162fcd8b49564",
              "IPY_MODEL_4e1c1548393a4a759dcce1ed56f8b8db"
            ],
            "layout": "IPY_MODEL_cb8caf34451a46ba8eb55a6551377496"
          }
        },
        "858b2620103345f1a7405cf0677853c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9859a32d4ee2431e8dc9def3c91bb7ef",
            "placeholder": "​",
            "style": "IPY_MODEL_0f1b8604df6d4c0dbdb9c0cef38b18df",
            "value": "Downloading: 100%"
          }
        },
        "a27f4abf5e9a47deb03162fcd8b49564": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c840954a29004569b4fd3ba4e1bd9115",
            "max": 483,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ed44b6bca49e4ac4b19d64d28379005b",
            "value": 483
          }
        },
        "4e1c1548393a4a759dcce1ed56f8b8db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22b22d6749b643cdaab5b4ba9e9515db",
            "placeholder": "​",
            "style": "IPY_MODEL_403d972f7fdf4b99affff48ff44d8143",
            "value": " 483/483 [00:00&lt;00:00, 12.5kB/s]"
          }
        },
        "cb8caf34451a46ba8eb55a6551377496": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9859a32d4ee2431e8dc9def3c91bb7ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f1b8604df6d4c0dbdb9c0cef38b18df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c840954a29004569b4fd3ba4e1bd9115": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed44b6bca49e4ac4b19d64d28379005b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "22b22d6749b643cdaab5b4ba9e9515db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "403d972f7fdf4b99affff48ff44d8143": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3fe462a7778a44f884f19b56a79e66a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_171c87e133e14742b636f6f6bab32e24",
              "IPY_MODEL_4c1e70fddd3641c4a0fd7845228373b2",
              "IPY_MODEL_396212cfbdd44c72a9b70658ea66c8df"
            ],
            "layout": "IPY_MODEL_86c21a534d444d76b090d2d90eb577d1"
          }
        },
        "171c87e133e14742b636f6f6bab32e24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a02ed4f4e03a494c98ada9f7c6a05c15",
            "placeholder": "​",
            "style": "IPY_MODEL_ff04160d7fa746b696919f7d587cb5b4",
            "value": "Downloading: 100%"
          }
        },
        "4c1e70fddd3641c4a0fd7845228373b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f084b3aa1bf4781ac981e7721824579",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2f102b7fb43544bea08f0e0c0a83a45d",
            "value": 231508
          }
        },
        "396212cfbdd44c72a9b70658ea66c8df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_836a5eb054ad4388959d064c63e289e1",
            "placeholder": "​",
            "style": "IPY_MODEL_96ebbd28f7f748daa30ff6ca0b654925",
            "value": " 232k/232k [00:00&lt;00:00, 619kB/s]"
          }
        },
        "86c21a534d444d76b090d2d90eb577d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a02ed4f4e03a494c98ada9f7c6a05c15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff04160d7fa746b696919f7d587cb5b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f084b3aa1bf4781ac981e7721824579": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f102b7fb43544bea08f0e0c0a83a45d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "836a5eb054ad4388959d064c63e289e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96ebbd28f7f748daa30ff6ca0b654925": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eaebc00e48634c8281a51e4eca46517b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_081340ac3a884001855a3767eda5df53",
              "IPY_MODEL_fd594e2d21e647ee9103cee45162b16b",
              "IPY_MODEL_8a3ba10a5d654f6c9c52ed113d455645"
            ],
            "layout": "IPY_MODEL_acdcef4c7eb0410f89e1e7136dd648dd"
          }
        },
        "081340ac3a884001855a3767eda5df53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9385ce0f002947ed9c892cfad0c6306a",
            "placeholder": "​",
            "style": "IPY_MODEL_c3ad62e74daa4e0cb7f5f906305722b5",
            "value": "Downloading: 100%"
          }
        },
        "fd594e2d21e647ee9103cee45162b16b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0684c2841deb4857945915ff370e93b6",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4fa23f07ff5b4253a97c52979015ed9d",
            "value": 466062
          }
        },
        "8a3ba10a5d654f6c9c52ed113d455645": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba6c633560554b23bf6960b82b6f78cb",
            "placeholder": "​",
            "style": "IPY_MODEL_1221b3f2a3af490da181a5fc53f80aee",
            "value": " 466k/466k [00:00&lt;00:00, 623kB/s]"
          }
        },
        "acdcef4c7eb0410f89e1e7136dd648dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9385ce0f002947ed9c892cfad0c6306a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3ad62e74daa4e0cb7f5f906305722b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0684c2841deb4857945915ff370e93b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fa23f07ff5b4253a97c52979015ed9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ba6c633560554b23bf6960b82b6f78cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1221b3f2a3af490da181a5fc53f80aee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f78b551af525452ea87194962198a3a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bfb45335414c4e2193961151df81e4eb",
              "IPY_MODEL_8ee11febe5884763ba0058a594dd774f",
              "IPY_MODEL_63499531b0c84a299531c991242d8c86"
            ],
            "layout": "IPY_MODEL_337cf14e8a8f4d4096a66bb936302d4d"
          }
        },
        "bfb45335414c4e2193961151df81e4eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0384ae31b294015a8c7b3afa02280a4",
            "placeholder": "​",
            "style": "IPY_MODEL_a8dac09b81e546919bcdab6aedeb6208",
            "value": "Downloading: 100%"
          }
        },
        "8ee11febe5884763ba0058a594dd774f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2af92d2d9a564141bb2c904b7334a25c",
            "max": 193,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_107bdd65a3f7437e889ea9b4cda65733",
            "value": 193
          }
        },
        "63499531b0c84a299531c991242d8c86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e8d11dc2a0b42b9a6c869c3b75829ee",
            "placeholder": "​",
            "style": "IPY_MODEL_daff7805473342299b22190f6be951d7",
            "value": " 193/193 [00:00&lt;00:00, 6.53kB/s]"
          }
        },
        "337cf14e8a8f4d4096a66bb936302d4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0384ae31b294015a8c7b3afa02280a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8dac09b81e546919bcdab6aedeb6208": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2af92d2d9a564141bb2c904b7334a25c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "107bdd65a3f7437e889ea9b4cda65733": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9e8d11dc2a0b42b9a6c869c3b75829ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "daff7805473342299b22190f6be951d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9b7e17be6bb495088c44568afddd26a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0e41d50dd71647568275489dcf75b953",
              "IPY_MODEL_0cd4579b6a71411a9bbb8f61ffe7d40f",
              "IPY_MODEL_3f6577417bd744ef836866d0e76fc9cd"
            ],
            "layout": "IPY_MODEL_f9507591af564d82a0a7de69ce935a1f"
          }
        },
        "0e41d50dd71647568275489dcf75b953": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_033cc8a942ad4cecb985c6f664e5fa08",
            "placeholder": "​",
            "style": "IPY_MODEL_2826d0789b2248f9b9ea4cb80095f31f",
            "value": "Downloading: 100%"
          }
        },
        "0cd4579b6a71411a9bbb8f61ffe7d40f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ecafd60720c2477ead9f0fc28035c8ca",
            "max": 267837019,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8809303a3fbf4d16845db03f82b9478a",
            "value": 267837019
          }
        },
        "3f6577417bd744ef836866d0e76fc9cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca1026c3d5c8459fa74f965973b0c2c0",
            "placeholder": "​",
            "style": "IPY_MODEL_25028d1c58664c25a9ca21945ae307e0",
            "value": " 268M/268M [00:06&lt;00:00, 41.5MB/s]"
          }
        },
        "f9507591af564d82a0a7de69ce935a1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "033cc8a942ad4cecb985c6f664e5fa08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2826d0789b2248f9b9ea4cb80095f31f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ecafd60720c2477ead9f0fc28035c8ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8809303a3fbf4d16845db03f82b9478a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ca1026c3d5c8459fa74f965973b0c2c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25028d1c58664c25a9ca21945ae307e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6c8a3b9cd8a043b78e778e44879042f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_84fce744e7964f61b293b07b61b231e8",
              "IPY_MODEL_b454276be0c4440dba986f86c64c6f18",
              "IPY_MODEL_5db8ff18ee1640b3ac51f07136a3550f"
            ],
            "layout": "IPY_MODEL_5b5530e85a5b434e9ec23f4109fa67c0"
          }
        },
        "84fce744e7964f61b293b07b61b231e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e39c1d29ebe745d0bb3d39c31c84c441",
            "placeholder": "​",
            "style": "IPY_MODEL_7136bae3740443c4ab7ffa14267ba153",
            "value": "Downloading: 100%"
          }
        },
        "b454276be0c4440dba986f86c64c6f18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c656e8ee0c4459d869a6c0665acb354",
            "max": 267967963,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c685715ebc7c46358aa570d4eb70fcbb",
            "value": 267967963
          }
        },
        "5db8ff18ee1640b3ac51f07136a3550f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92d77b1bda9d426f89c84afcc2844b55",
            "placeholder": "​",
            "style": "IPY_MODEL_9ea97cf32c0947feaaa184462662c310",
            "value": " 268M/268M [00:04&lt;00:00, 55.7MB/s]"
          }
        },
        "5b5530e85a5b434e9ec23f4109fa67c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e39c1d29ebe745d0bb3d39c31c84c441": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7136bae3740443c4ab7ffa14267ba153": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c656e8ee0c4459d869a6c0665acb354": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c685715ebc7c46358aa570d4eb70fcbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "92d77b1bda9d426f89c84afcc2844b55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ea97cf32c0947feaaa184462662c310": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe939762e9b744b783b186aa3a260f93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_741c2137a0d04eed88a7447e8ad93f1d",
              "IPY_MODEL_e9d564e449284345afdd877926641d14",
              "IPY_MODEL_d0d10d0bfdfc40808b6afe20e3ffc141"
            ],
            "layout": "IPY_MODEL_05aef73fef3740f69d6b5e080cd45fcd"
          }
        },
        "741c2137a0d04eed88a7447e8ad93f1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0760c8a2e575466290ae92192a09acb4",
            "placeholder": "​",
            "style": "IPY_MODEL_895707f81c664d3cb2d5be862d49e8a1",
            "value": "Downloading: 100%"
          }
        },
        "e9d564e449284345afdd877926641d14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17fb27a9c869407f861a900718966d27",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9cb1a2cbe4d44a6b90f3a7e2cd7ade5b",
            "value": 231508
          }
        },
        "d0d10d0bfdfc40808b6afe20e3ffc141": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e574b74b08b416db070420c08b09f75",
            "placeholder": "​",
            "style": "IPY_MODEL_3070683ce2574a0991cdebf7f4c1e200",
            "value": " 232k/232k [00:00&lt;00:00, 890kB/s]"
          }
        },
        "05aef73fef3740f69d6b5e080cd45fcd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0760c8a2e575466290ae92192a09acb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "895707f81c664d3cb2d5be862d49e8a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17fb27a9c869407f861a900718966d27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cb1a2cbe4d44a6b90f3a7e2cd7ade5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1e574b74b08b416db070420c08b09f75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3070683ce2574a0991cdebf7f4c1e200": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "91d3e4fcabca45f087ae9bdce8a8be7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3a65b0bec479443d8d12287a0cfe7e2b",
              "IPY_MODEL_a8b81b77c3da4c9491c0429512746981",
              "IPY_MODEL_25090749d8be4e4d813be47e1cc8f352"
            ],
            "layout": "IPY_MODEL_9ec959f277424726bd6c31e8a43681f9"
          }
        },
        "3a65b0bec479443d8d12287a0cfe7e2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47e1fc9686dd4a738f9b56eac6c1ab51",
            "placeholder": "​",
            "style": "IPY_MODEL_adc1c573363b46579db3bf7f5fc11e56",
            "value": "Downloading: 100%"
          }
        },
        "a8b81b77c3da4c9491c0429512746981": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a2beed955244b288c98a81d8eb49f55",
            "max": 383,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4a38e31b1ba84e40a9b4c9e432c08cea",
            "value": 383
          }
        },
        "25090749d8be4e4d813be47e1cc8f352": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb52b32eb8374beb949bab335671603a",
            "placeholder": "​",
            "style": "IPY_MODEL_37bad0b658f3445794dfd39cfeb700a8",
            "value": " 383/383 [00:00&lt;00:00, 10.8kB/s]"
          }
        },
        "9ec959f277424726bd6c31e8a43681f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47e1fc9686dd4a738f9b56eac6c1ab51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adc1c573363b46579db3bf7f5fc11e56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a2beed955244b288c98a81d8eb49f55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a38e31b1ba84e40a9b4c9e432c08cea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fb52b32eb8374beb949bab335671603a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37bad0b658f3445794dfd39cfeb700a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ae71459ac9e426b8b43e4c3b0f39d95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_30b32b74923443cdbe4e5306827c9484",
              "IPY_MODEL_9ab37425a2be4b17bfe883663897b912",
              "IPY_MODEL_6278db4da04149749bd63da46e73c3e1"
            ],
            "layout": "IPY_MODEL_322b610216754bd39e1123a9e15065a4"
          }
        },
        "30b32b74923443cdbe4e5306827c9484": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a10ecc588cc4ba1b1388cdeef089733",
            "placeholder": "​",
            "style": "IPY_MODEL_79324a505799441aaa3778cfb2c6abe0",
            "value": "Downloading: 100%"
          }
        },
        "9ab37425a2be4b17bfe883663897b912": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_525fa915bc59455f8ccfe899b9b51012",
            "max": 116252865,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_19a24e75eaf944bcbb71f6c4af8e9ef8",
            "value": 116252865
          }
        },
        "6278db4da04149749bd63da46e73c3e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d876dcb0b22c46928cb060cbbb1636f3",
            "placeholder": "​",
            "style": "IPY_MODEL_ee9d358370334d81a0f6fef923bf1624",
            "value": " 116M/116M [00:05&lt;00:00, 54.0MB/s]"
          }
        },
        "322b610216754bd39e1123a9e15065a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a10ecc588cc4ba1b1388cdeef089733": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79324a505799441aaa3778cfb2c6abe0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "525fa915bc59455f8ccfe899b9b51012": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19a24e75eaf944bcbb71f6c4af8e9ef8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d876dcb0b22c46928cb060cbbb1636f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee9d358370334d81a0f6fef923bf1624": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "91890ff6b2c54a519272d9902b6db2a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a00ccb4f22604643b59347d91c9ce603",
              "IPY_MODEL_f8e356d8f4fc41d3881ed99986e76413",
              "IPY_MODEL_302039702de8487aa15e09b9e8a6aa44"
            ],
            "layout": "IPY_MODEL_c0f70243974947d28f5db021a075daf8"
          }
        },
        "a00ccb4f22604643b59347d91c9ce603": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_158955bf7a2a472692e2b94c4622d191",
            "placeholder": "​",
            "style": "IPY_MODEL_2f79f4836ee94e2da0cae601471b64be",
            "value": "Downloading: 100%"
          }
        },
        "f8e356d8f4fc41d3881ed99986e76413": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7cd78c5fa7234b66a5e47f606ea74ad8",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fa8f513f1d894f868238c9c54eb5321b",
            "value": 231508
          }
        },
        "302039702de8487aa15e09b9e8a6aa44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_366b9d58894a4876a80e8c71bdac87cd",
            "placeholder": "​",
            "style": "IPY_MODEL_7389db67ac434362a78a7324a7013540",
            "value": " 232k/232k [00:00&lt;00:00, 638kB/s]"
          }
        },
        "c0f70243974947d28f5db021a075daf8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "158955bf7a2a472692e2b94c4622d191": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f79f4836ee94e2da0cae601471b64be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7cd78c5fa7234b66a5e47f606ea74ad8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa8f513f1d894f868238c9c54eb5321b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "366b9d58894a4876a80e8c71bdac87cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7389db67ac434362a78a7324a7013540": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4375929584c45d985c8d9575acb647f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1113fc0ae4134c30be0a1574b0b97487",
              "IPY_MODEL_5c7ebb3ea3f04e4182dde84e44c975a4",
              "IPY_MODEL_2d28b260693d4ad28d7bec55d1f90415"
            ],
            "layout": "IPY_MODEL_90bee7fbf52b43e6959b58f5f304bf1c"
          }
        },
        "1113fc0ae4134c30be0a1574b0b97487": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67e0dd78b4fa4b198dde0837f3343375",
            "placeholder": "​",
            "style": "IPY_MODEL_7877fc239bc346059efc46d4eedced1d",
            "value": "Downloading: 100%"
          }
        },
        "5c7ebb3ea3f04e4182dde84e44c975a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e72799d96ef4c86bf10ebf3ab2dc78b",
            "max": 383,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_67f08704007c4d7db753c45b7a7329c8",
            "value": 383
          }
        },
        "2d28b260693d4ad28d7bec55d1f90415": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00814a4a1ba845159f3665bd4a6e7e0a",
            "placeholder": "​",
            "style": "IPY_MODEL_efa592a2ab894ba3a4666ce8210e72ce",
            "value": " 383/383 [00:00&lt;00:00, 4.98kB/s]"
          }
        },
        "90bee7fbf52b43e6959b58f5f304bf1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67e0dd78b4fa4b198dde0837f3343375": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7877fc239bc346059efc46d4eedced1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e72799d96ef4c86bf10ebf3ab2dc78b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67f08704007c4d7db753c45b7a7329c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "00814a4a1ba845159f3665bd4a6e7e0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efa592a2ab894ba3a4666ce8210e72ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "71a028ad70f344f78de2970e80fcc0bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_98c3a7a0dfd94f6fbcadf01ba8e89afd",
              "IPY_MODEL_37709841d0b64bc39335ef7c5d685d8d",
              "IPY_MODEL_857927423f23472f814abc596854e4de"
            ],
            "layout": "IPY_MODEL_720949646d5c41cd83a8f9291cbff09f"
          }
        },
        "98c3a7a0dfd94f6fbcadf01ba8e89afd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f839805d55f343ad998f8e59975b899f",
            "placeholder": "​",
            "style": "IPY_MODEL_2de2e374bb0d4205a55ccd810128372e",
            "value": "Downloading: 100%"
          }
        },
        "37709841d0b64bc39335ef7c5d685d8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5375b914b1b4f339eafe792bad4eec3",
            "max": 116252865,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a6ff25f62e714e1cbd926b48f3c901c0",
            "value": 116252865
          }
        },
        "857927423f23472f814abc596854e4de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f391c39f71749c9939399f822242a5b",
            "placeholder": "​",
            "style": "IPY_MODEL_b00e868ad5e54a0aac13a0f53ea18100",
            "value": " 116M/116M [00:03&lt;00:00, 42.6MB/s]"
          }
        },
        "720949646d5c41cd83a8f9291cbff09f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f839805d55f343ad998f8e59975b899f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2de2e374bb0d4205a55ccd810128372e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5375b914b1b4f339eafe792bad4eec3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6ff25f62e714e1cbd926b48f3c901c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6f391c39f71749c9939399f822242a5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b00e868ad5e54a0aac13a0f53ea18100": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e59zVgQRRUxx",
        "outputId": "07a305e1-cb1e-4817-e874-48951db0e14a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (1.3.5)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 9.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 20.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 69.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "XXRhOFoHorCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive/', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBflFQ22osQM",
        "outputId": "343cfa9c-1fcf-424b-db5a-81849d8b4f79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AuoZCdbsDQmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SpkoOsPvDQuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WPDlOG0_DQwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pZndHmXFDQzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import csv\n",
        "import pandas as pd\n",
        "\n",
        "csv.field_size_limit(sys.maxsize)\n",
        "\n",
        "fr = open(\"/content/drive/MyDrive/collectionandqueries/queries.train.tsv\", \"r\")\n",
        "\n",
        "input_file = csv.reader(fr, delimiter = \"\\t\")\n",
        "\n",
        "final_query_ids = {}\n",
        "\n",
        "count = 0\n",
        "n_count = 0\n",
        "index = 0\n",
        "\n",
        "for query_id, query_text in input_file:\n",
        "    final_query_ids[query_id] = query_text\n",
        "      \n",
        "print ('final_query_ids : ' + str(len(final_query_ids)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zAZmJHzDQ2b",
        "outputId": "bc824858-7243-42de-ed41-91f2db7c0028"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "final_query_ids : 808731\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import csv\n",
        "import pandas as pd\n",
        "\n",
        "csv.field_size_limit(sys.maxsize)\n",
        "\n",
        "fr = open(\"/content/drive/MyDrive/collectionandqueries/20KDocs/qrels_fulldocs_subset_preprocessed_20K.tsv\", \"r\")\n",
        "qrels_doc_ids = {}\n",
        "qrels_docs = {}\n",
        "\n",
        "input_file = csv.reader(fr, delimiter = \"\\t\")\n",
        "\n",
        "count = 0\n",
        "max_count = 20000\n",
        "\n",
        "for DocID, Doc in input_file:\n",
        "    count = count + 1\n",
        "    if (count == 1):\n",
        "      continue\n",
        "    #print('count of qrels : ' + str(count))\n",
        "    if DocID in qrels_doc_ids.keys():  \n",
        "      qrels_doc_ids[DocID] = qrels_doc_ids[DocID] + 1\n",
        "    else:\n",
        "      qrels_doc_ids[DocID] = 1 \n",
        "      qrels_docs[DocID] = Doc  \n",
        "    if (count > max_count):\n",
        "      break    \n",
        "print('len(qrels_doc_ids) : ' + str(len(qrels_doc_ids)))\n",
        "print('len(qrels_docs) : ' + str(len(qrels_docs)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wG0ZhWEeDVMj",
        "outputId": "9e13cba0-3344-4265-b175-a118e2a8c65f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(qrels_doc_ids) : 20000\n",
            "len(qrels_docs) : 20000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import csv\n",
        "import pandas as pd\n",
        "\n",
        "csv.field_size_limit(sys.maxsize)\n",
        "\n",
        "fr = open(\"/content/drive/MyDrive/collectionandqueries/qrels.train.tsv\", \"r\")\n",
        "\n",
        "input_file = csv.reader(fr, delimiter = \"\\t\")\n",
        "\n",
        "query_ids = []\n",
        "queries = []\n",
        "document_ids = [] \n",
        "labels = []\n",
        "documents = []\n",
        "\n",
        "count = 0\n",
        "max_count = 5000\n",
        "index = 0\n",
        "\n",
        "for query_id, qo, document_id, relevance in input_file:\n",
        "    if document_id in qrels_doc_ids.keys() and query_id in final_query_ids.keys():  \n",
        "      query_ids.append(query_id)\n",
        "      queries.append(final_query_ids[query_id])\n",
        "      document_ids.append(document_id)\n",
        "      documents.append(qrels_docs[document_id])\n",
        "      labels.append(int(relevance))\n",
        "      count = count + 1\n",
        "      if (count >= max_count):\n",
        "        break\n",
        "print('len(qrels_query_ids) : ' + str(len(query_ids)))\n",
        "print('len(queries) : ' + str(len(queries)))\n",
        "print('len(document_ids) : ' + str(len(document_ids)))\n",
        "print('len(documents) : ' + str(len(documents)))\n",
        "print('len(labels) : ' + str(len(labels)))\n",
        "print('count : ' + str(count))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LX-WllTDYbv",
        "outputId": "ecf12a53-1431-46b6-ddce-6bb184c6f7d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(qrels_query_ids) : 5000\n",
            "len(queries) : 5000\n",
            "len(document_ids) : 5000\n",
            "len(documents) : 5000\n",
            "len(labels) : 5000\n",
            "count : 5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_queries, val_queries, train_docs, val_docs, train_labels, val_labels = train_test_split(\n",
        "    queries, \n",
        "    documents, \n",
        "    labels, \n",
        "    test_size=.2\n",
        ")"
      ],
      "metadata": {
        "id": "eZn1TR20DlCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizerFast\n",
        "\n",
        "model_name = \"google/bert_uncased_L-4_H-512_A-8\"\n",
        "tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
        "\n",
        "train_encodings = tokenizer(train_queries, train_docs, truncation=True, padding='max_length', max_length=128)\n",
        "val_encodings = tokenizer(val_queries, val_docs, truncation=True, padding='max_length', max_length=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "fe939762e9b744b783b186aa3a260f93",
            "741c2137a0d04eed88a7447e8ad93f1d",
            "e9d564e449284345afdd877926641d14",
            "d0d10d0bfdfc40808b6afe20e3ffc141",
            "05aef73fef3740f69d6b5e080cd45fcd",
            "0760c8a2e575466290ae92192a09acb4",
            "895707f81c664d3cb2d5be862d49e8a1",
            "17fb27a9c869407f861a900718966d27",
            "9cb1a2cbe4d44a6b90f3a7e2cd7ade5b",
            "1e574b74b08b416db070420c08b09f75",
            "3070683ce2574a0991cdebf7f4c1e200",
            "91d3e4fcabca45f087ae9bdce8a8be7a",
            "3a65b0bec479443d8d12287a0cfe7e2b",
            "a8b81b77c3da4c9491c0429512746981",
            "25090749d8be4e4d813be47e1cc8f352",
            "9ec959f277424726bd6c31e8a43681f9",
            "47e1fc9686dd4a738f9b56eac6c1ab51",
            "adc1c573363b46579db3bf7f5fc11e56",
            "4a2beed955244b288c98a81d8eb49f55",
            "4a38e31b1ba84e40a9b4c9e432c08cea",
            "fb52b32eb8374beb949bab335671603a",
            "37bad0b658f3445794dfd39cfeb700a8"
          ]
        },
        "id": "CG2urxP3H9-f",
        "outputId": "a5c88b2d-8cbd-4652-92b8-b813d095d0c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fe939762e9b744b783b186aa3a260f93"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/383 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "91d3e4fcabca45f087ae9bdce8a8be7a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "class OurDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = OurDataset(train_encodings, train_labels)\n",
        "val_dataset = OurDataset(val_encodings, val_labels)\n"
      ],
      "metadata": {
        "id": "jcJmnsTpIHoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158,
          "referenced_widgets": [
            "7ae71459ac9e426b8b43e4c3b0f39d95",
            "30b32b74923443cdbe4e5306827c9484",
            "9ab37425a2be4b17bfe883663897b912",
            "6278db4da04149749bd63da46e73c3e1",
            "322b610216754bd39e1123a9e15065a4",
            "4a10ecc588cc4ba1b1388cdeef089733",
            "79324a505799441aaa3778cfb2c6abe0",
            "525fa915bc59455f8ccfe899b9b51012",
            "19a24e75eaf944bcbb71f6c4af8e9ef8",
            "d876dcb0b22c46928cb060cbbb1636f3",
            "ee9d358370334d81a0f6fef923bf1624"
          ]
        },
        "id": "TQJgSvxBISb_",
        "outputId": "1f8e301a-9f34-46da-beaa-dfd8caa9a8cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/116M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7ae71459ac9e426b8b43e4c3b0f39d95"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google/bert_uncased_L-4_H-512_A-8 were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-4_H-512_A-8 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.base_model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "yjIogH-3IXVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install evaluate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Nrg68QrWaFsi",
        "outputId": "bba728f6-71ca-4dd7-9557-c94e2e147e94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.3.0-py3-none-any.whl (72 kB)\n",
            "\u001b[K     |████████████████████████████████| 72 kB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from evaluate) (1.3.5)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 18.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from evaluate) (4.64.1)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (2022.11.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.11.1)\n",
            "Collecting datasets>=2.0.0\n",
            "  Downloading datasets-2.7.1-py3-none-any.whl (451 kB)\n",
            "\u001b[K     |████████████████████████████████| 451 kB 53.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.3.6)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 56.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from evaluate) (1.21.6)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from evaluate) (21.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (3.8.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.1.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.1.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->evaluate) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (2.10)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 63.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->evaluate) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->evaluate) (1.15.0)\n",
            "Installing collected packages: urllib3, xxhash, responses, multiprocess, datasets, evaluate\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed datasets-2.7.1 evaluate-0.3.0 multiprocess-0.70.14 responses-0.18.0 urllib3-1.25.11 xxhash-3.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "from sklearn.metrics import ndcg_score\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "import evaluate\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def my_compute_metrics_ndcg(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    print ('predictions : ' + str(predictions))\n",
        "    predictions2 = tf.nn.log_softmax(predictions, axis=-1)\n",
        "    #print(classification_report(labels, predictions))\n",
        "    return ndcg_score(predictions2, labels)\n",
        "\"\"\"\n",
        "\n",
        "def my_compute_metrics_precision(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    metric = evaluate.load(\"precision\")\n",
        "    #print('predictions : ' + str(predictions))\n",
        "    #print('labels : ' + str(labels))\n",
        "    #if task != \"stsb\":\n",
        "    predictions = np.argmax(predictions, axis=-1)\n",
        "    #else:\n",
        "    #predictions = predictions[:]\n",
        "    print(classification_report(labels, predictions))\n",
        "    return metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    evaluation_strategy=\"epoch\",     # Evaluation is done at the end of each epoch.\n",
        "    num_train_epochs=2,              # total number of training epochs\n",
        "    per_device_train_batch_size=16,  # batch size per device during training\n",
        "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
        "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    save_total_limit=1,              # limit the total amount of checkpoints. Deletes the older checkpoints.    \n",
        ")\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,                         # the instantiated Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=val_dataset,             # evaluation dataset\n",
        "    #compute_metrics = my_compute_metrics_ndcg\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1CvQCHQrIDw6",
        "outputId": "6799db03-0f11-44d0-8a4c-0be3a7677641"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 4000\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 500\n",
            "  Number of trainable parameters = 1026\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [500/500 10:54, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.002679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.003900</td>\n",
              "      <td>0.000770</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to ./results/checkpoint-500\n",
            "Configuration saved in ./results/checkpoint-500/config.json\n",
            "Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "***** Running Prediction *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-06fe5a435a9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_queries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pred : '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, test_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2884\u001b[0m         \u001b[0meval_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_loop\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_legacy_prediction_loop\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2885\u001b[0;31m         output = eval_loop(\n\u001b[0m\u001b[1;32m   2886\u001b[0m             \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Prediction\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2887\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2977\u001b[0m         \u001b[0mobserved_num_examples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m         \u001b[0;31m# Main evaluation loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m             \u001b[0;31m# Update the observed num examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0mobserved_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/trainer_utils.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m    694\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_remove_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_collator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/data/data_collator.py\u001b[0m in \u001b[0;36mdefault_data_collator\u001b[0;34m(features, return_tensors)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_tensors\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch_default_data_collator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mreturn_tensors\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"tf\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf_default_data_collator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/data/data_collator.py\u001b[0m in \u001b[0;36mtorch_default_data_collator\u001b[0;34m(features)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m     \u001b[0mfirst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/data/data_collator.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m     \u001b[0mfirst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: vars() argument must have __dict__ attribute"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install trectools"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqGx7dXyqYis",
        "outputId": "1f242c10-9e72-460a-83f7-0779719cef6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting trectools\n",
            "  Downloading trectools-0.0.49.tar.gz (28 kB)\n",
            "Requirement already satisfied: pandas>=0.15.0 in /usr/local/lib/python3.8/dist-packages (from trectools) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from trectools) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.15 in /usr/local/lib/python3.8/dist-packages (from trectools) (1.0.2)\n",
            "Requirement already satisfied: scipy>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from trectools) (1.7.3)\n",
            "Collecting sarge>=0.1.1\n",
            "  Downloading sarge-0.1.7.post1-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.8/dist-packages (from trectools) (4.9.1)\n",
            "Requirement already satisfied: bs4>=0.0.0.1 in /usr/local/lib/python3.8/dist-packages (from trectools) (0.0.1)\n",
            "Requirement already satisfied: matplotlib>=1.5 in /usr/local/lib/python3.8/dist-packages (from trectools) (3.2.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from bs4>=0.0.0.1->trectools) (4.6.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.5->trectools) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.5->trectools) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.5->trectools) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.5->trectools) (1.4.4)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.15.0->trectools) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib>=1.5->trectools) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.15->trectools) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.15->trectools) (1.2.0)\n",
            "Building wheels for collected packages: trectools\n",
            "  Building wheel for trectools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for trectools: filename=trectools-0.0.49-py3-none-any.whl size=27140 sha256=a6bd070f16cc24a35aefae315dfbf82fc45ef2cfa83019406cec0d6b88f0c0ae\n",
            "  Stored in directory: /root/.cache/pip/wheels/6a/cd/17/9a6b28af70445d948c97018b43b9181acd2fdd23e115ee2055\n",
            "Successfully built trectools\n",
            "Installing collected packages: sarge, trectools\n",
            "Successfully installed sarge-0.1.7.post1 trectools-0.0.49\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = trainer.predict(val_dataset)\n",
        "#predictions = \n",
        "#print('pred : ' + str(pred))\n",
        "\n",
        "# making qrel \n",
        "qrel = {}\n",
        "qids, seen, i = [], {}, 0\n",
        "for q in val_queries:\n",
        "  if q in seen:\n",
        "    qids.append(seen[q])\n",
        "  else:\n",
        "    seen[q] = i\n",
        "    qids.append(i)\n",
        "    i+=1\n",
        "qrel={\n",
        "    \"query\": qids,\n",
        "    \"q0\": val_queries,\n",
        "    \"docid\": val_docs,\n",
        "    \"rel\": val_labels\n",
        "}\n",
        "run = {\n",
        "    \"query\": qids,\n",
        "    \"q0\": val_queries,\n",
        "    \"docid\": val_docs,\n",
        "    \"rank\": pred[1].tolist(),\n",
        "    \"score\": [max(l) for l in pred[0].tolist()],\n",
        "    \"system\": [\"test\" for i in qids]\n",
        "}\n",
        "trec_eval = evaluate.load(\"trec_eval\")\n",
        "results = trec_eval.compute(references=[qrel], predictions=[run])\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "ht-z6x1vpzOJ",
        "outputId": "1187d471-4ac9-47b8-a5e8-ef7fb04f6c40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'runid': 'test',\n",
              " 'num_ret': 1000,\n",
              " 'num_rel': 1000,\n",
              " 'num_rel_ret': 1000,\n",
              " 'num_q': 977,\n",
              " 'map': 1.0,\n",
              " 'gm_map': 1.0,\n",
              " 'bpref': 0.0,\n",
              " 'Rprec': 1.0,\n",
              " 'recip_rank': 1.0,\n",
              " 'P@5': 0.20470829068577281,\n",
              " 'P@10': 0.10235414534288641,\n",
              " 'P@15': 0.0682360968952576,\n",
              " 'P@20': 0.051177072671443204,\n",
              " 'P@30': 0.0341180484476288,\n",
              " 'P@100': 0.01023541453428864,\n",
              " 'P@200': 0.00511770726714432,\n",
              " 'P@500': 0.0020470829068577286,\n",
              " 'P@1000': 0.0010235414534288643,\n",
              " 'NDCG@5': 1.0,\n",
              " 'NDCG@10': 1.0,\n",
              " 'NDCG@15': 1.0,\n",
              " 'NDCG@20': 1.0,\n",
              " 'NDCG@30': 1.0,\n",
              " 'NDCG@100': 1.0,\n",
              " 'NDCG@200': 1.0,\n",
              " 'NDCG@500': 1.0,\n",
              " 'NDCG@1000': 1.0}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "wzwvwenbUXoh",
        "outputId": "b740f7e3-4ab7-4307-e06d-c1c866a559b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [16/16 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00      1000\n",
            "\n",
            "    accuracy                           1.00      1000\n",
            "   macro avg       1.00      1.00      1.00      1000\n",
            "weighted avg       1.00      1.00      1.00      1000\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.010652759112417698,\n",
              " 'eval_precision': 1.0,\n",
              " 'eval_runtime': 3.1007,\n",
              " 'eval_samples_per_second': 322.511,\n",
              " 'eval_steps_per_second': 5.16,\n",
              " 'epoch': 2.0}"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HJC35c_-DQ5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9zXkqE73DQ8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QdwO0oyfDRHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RNVQS4PUDRKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas\n",
        "from pandas import read_csv\n",
        "training_data = read_csv(\"/content/drive/MyDrive/collectionandqueries/20KDocs/qrels_fulldocs_subset_preprocessed_20K.tsv\", delimiter = \"\\t\")\n",
        "training_data.head()"
      ],
      "metadata": {
        "id": "hKzoTWcvRitt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "3d9ad887-215e-4dc8-ceba-40422c6a9ec5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   document_id                                      document_text\n",
              "0           16  approach base theory justice consider crime wr...\n",
              "1           49  colorâurine variety colors often shades yell...\n",
              "2           60  inborn error bile acid synthesis produce lifet...\n",
              "3           81  organ left side body cause pain left rib cage ...\n",
              "4          389  word convict elegcw elegxo means bring light e..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6368bf78-7c28-440e-93ab-9ec1fcb38213\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document_id</th>\n",
              "      <th>document_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>16</td>\n",
              "      <td>approach base theory justice consider crime wr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>49</td>\n",
              "      <td>colorâurine variety colors often shades yell...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>60</td>\n",
              "      <td>inborn error bile acid synthesis produce lifet...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>81</td>\n",
              "      <td>organ left side body cause pain left rib cage ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>389</td>\n",
              "      <td>word convict elegcw elegxo means bring light e...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6368bf78-7c28-440e-93ab-9ec1fcb38213')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6368bf78-7c28-440e-93ab-9ec1fcb38213 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6368bf78-7c28-440e-93ab-9ec1fcb38213');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas\n",
        "from pandas import read_csv\n",
        "all_queries = read_csv(\"/content/drive/MyDrive/collectionandqueries/20KDocs/qrels_queries.tsv\", delimiter = \"\\t\")\n",
        "all_queries.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "E-7ew6cypizz",
        "outputId": "f1c58ec9-9009-4f1f-dd1c-494f95ea0d44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   query_id                                         query_text\n",
              "0    737889                  what is decentralization process.\n",
              "1    570009         what are the four major groups of elements\n",
              "2    918533  what was introduced to the human diet in what ...\n",
              "3   1176220              average temperatures barcelona israel\n",
              "4    291569      how many pairs of chromosomes in a human cell"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-027fa578-da4f-4607-87b8-39994dc54cf1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query_id</th>\n",
              "      <th>query_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>737889</td>\n",
              "      <td>what is decentralization process.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>570009</td>\n",
              "      <td>what are the four major groups of elements</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>918533</td>\n",
              "      <td>what was introduced to the human diet in what ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1176220</td>\n",
              "      <td>average temperatures barcelona israel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>291569</td>\n",
              "      <td>how many pairs of chromosomes in a human cell</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-027fa578-da4f-4607-87b8-39994dc54cf1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-027fa578-da4f-4607-87b8-39994dc54cf1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-027fa578-da4f-4607-87b8-39994dc54cf1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas\n",
        "from pandas import read_csv\n",
        "all_qrels = read_csv(\"/content/drive/MyDrive/collectionandqueries/qrels.train.tsv\", delimiter = \"\\t\")\n",
        "all_qrels.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "y83Xjf5lqZ6V",
        "outputId": "ba03b86b-31ad-45d9-81de-babaf2765dcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   1185869  0  0.1  1\n",
              "0  1185868  0   16  1\n",
              "1   597651  0   49  1\n",
              "2   403613  0   60  1\n",
              "3  1183785  0  389  1\n",
              "4   312651  0  616  1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c5b57213-50d7-4366-9b85-104b7a84792e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1185869</th>\n",
              "      <th>0</th>\n",
              "      <th>0.1</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1185868</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>597651</td>\n",
              "      <td>0</td>\n",
              "      <td>49</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>403613</td>\n",
              "      <td>0</td>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1183785</td>\n",
              "      <td>0</td>\n",
              "      <td>389</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>312651</td>\n",
              "      <td>0</td>\n",
              "      <td>616</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c5b57213-50d7-4366-9b85-104b7a84792e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c5b57213-50d7-4366-9b85-104b7a84792e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c5b57213-50d7-4366-9b85-104b7a84792e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(training_data[\"document_text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpTIxJuUqC-x",
        "outputId": "4d6ddebc-ca01-4060-e55a-26230f4efa3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20000"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYsV4H8fCpZ-",
        "outputId": "c7bbd720-167c-4d94-c139-a7f6add53ac9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_queries, val_queries, train_docs, val_docs, train_labels, val_labels = train_test_split(\n",
        "    training_data[\"document_id\"].tolist(), \n",
        "    training_data[\"document_text\"].tolist(), \n",
        "    #training_data[\"label\"].tolist(), \n",
        "    test_size=.2\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-c5cd83b181de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m train_queries, val_queries, train_docs, val_docs, train_labels, val_labels = train_test_split(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtraining_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"document_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtraining_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"document_text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#training_data[\"label\"].tolist(),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 6, got 4)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSUXN17rRls9",
        "outputId": "204b15fe-84c0-4e3c-9418-0db2a4dcac74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 24.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 58.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 77.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8ruaTL4oV3hF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R7yTSMdbi4eM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f9ZceVCEi4kF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z4rfXWuF72UO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rWFw4xOb72W2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "pos_neg_ration = 4\n",
        "\n",
        "# Maximal number of training samples we want to use\n",
        "max_train_samples = 5e4\n",
        "\n",
        "\n",
        "### Now we read the MS Marco dataset\n",
        "data_folder = '/content/drive/MyDrive/collectionandqueries/'\n",
        "os.makedirs(data_folder, exist_ok=True)\n",
        "\n",
        "\n",
        "#### Read the corpus files, that contain all the passages. Store them in the corpus dict\n",
        "corpus = {}\n",
        "collection_filepath = os.path.join(data_folder, 'collection.tsv')\n",
        "if not os.path.exists(collection_filepath):\n",
        "    print('collection.tsv not found')\n",
        "\n",
        "with open(collection_filepath, 'r', encoding='utf8') as fIn:\n",
        "    for line in fIn:\n",
        "        pid, passage = line.strip().split(\"\\t\")\n",
        "        corpus[pid] = passage\n",
        "print('len(corpus.keys() : ' + str(len(corpus.keys())))\n",
        "\n",
        "### Read the train queries, store in queries dict\n",
        "queries = {}\n",
        "queries_filepath = os.path.join(data_folder, 'queries.train.tsv')\n",
        "if not os.path.exists(queries_filepath):\n",
        "    print('queries.train.tsv not found')\n",
        "\n",
        "with open(queries_filepath, 'r', encoding='utf8') as fIn:\n",
        "    for line in fIn:\n",
        "        qid, query = line.strip().split(\"\\t\")\n",
        "        queries[qid] = query\n",
        "\n",
        "print('len(queries.keys() : ' + str(len(queries.keys())))\n",
        "\n",
        "### Now we create our training & dev data\n",
        "all_query_ids = []\n",
        "all_queries = []\n",
        "all_document_ids = [] \n",
        "all_labels = []\n",
        "all_documents = []\n",
        "\n",
        "\"\"\"\n",
        "train_samples = []\n",
        "dev_samples = {}\n",
        "\n",
        "# We use 200 random queries from the train set for evaluation during training\n",
        "# Each query has at least one relevant and up to 200 irrelevant (negative) passages\n",
        "num_dev_queries = 200\n",
        "num_max_dev_negatives = 200\n",
        "\n",
        "# msmarco-qidpidtriples.rnd-shuf.train-eval.tsv.gz and msmarco-qidpidtriples.rnd-shuf.train.tsv.gz is a randomly\n",
        "# shuffled version of qidpidtriples.train.full.2.tsv.gz from the MS Marco website\n",
        "# We extracted in the train-eval split 500 random queries that can be used for evaluation during training\n",
        "train_eval_filepath = os.path.join(data_folder, 'msmarco-qidpidtriples.rnd-shuf.train-eval.tsv')\n",
        "if not os.path.exists(train_eval_filepath):\n",
        "    print('msmarco-qidpidtriples.rnd-shuf.train-eval.tsv not found')\n",
        "\n",
        "with open(train_eval_filepath, 'r', encoding='utf8') as fIn:\n",
        "    for line in fIn:\n",
        "        qid, pos_id, neg_id = line.strip().split()\n",
        "\n",
        "        if qid not in dev_samples and len(dev_samples) < num_dev_queries:\n",
        "            dev_samples[qid] = {'query': queries[qid], 'positive': set(), 'negative': set()}\n",
        "\n",
        "        if qid in dev_samples:\n",
        "            dev_samples[qid]['positive'].add(corpus[pos_id])\n",
        "            all_query_ids.append(qid)\n",
        "            all_queries.append(queries[qid])\n",
        "            all_document_ids.append(pos_id)\n",
        "            all_documents.append(corpus([pos_id]))\n",
        "            all_labels.append(1)\n",
        "            \n",
        "\n",
        "            if len(dev_samples[qid]['negative']) < num_max_dev_negatives:\n",
        "                dev_samples[qid]['negative'].add(corpus[neg_id])\n",
        "                all_query_ids.append(qid)\n",
        "                all_queries.append(queries[qid])\n",
        "                all_document_ids.append(neg_id)\n",
        "                all_documents.append(corpus([neg_id]))\n",
        "                all_labels.append(0)\n",
        "                \n",
        "\n",
        "print('len(dev_samples.keys()) : ' + str(len(dev_samples.keys())))\n",
        "\"\"\"\n",
        "\n",
        "# Read our training file\n",
        "train_filepath = os.path.join(data_folder, 'qidpidtriples-subset.train-200K.tsv')\n",
        "if not os.path.exists(train_filepath):\n",
        "    print('qidpidtriples-subset.train-200K.tsv not found')\n",
        "\n",
        "cnt = 0\n",
        "with open(train_filepath, 'r', encoding='utf8') as fIn:\n",
        "    for line in fIn:\n",
        "        qid, pos_id, neg_id = line.strip().split()\n",
        "\n",
        "        query = queries[qid]\n",
        "        if (cnt % (pos_neg_ration+1)) == 0:\n",
        "            passage = corpus[pos_id]\n",
        "            label = 1\n",
        "            all_query_ids.append(qid)\n",
        "            all_queries.append(query)\n",
        "            all_document_ids.append(pos_id)\n",
        "            all_documents.append(passage)\n",
        "            all_labels.append(label)\n",
        "        else:\n",
        "            passage = corpus[neg_id]\n",
        "            label = 0\n",
        "            all_query_ids.append(qid)\n",
        "            all_queries.append(queries[qid])\n",
        "            all_document_ids.append(neg_id)\n",
        "            all_documents.append(passage)\n",
        "            all_labels.append(label)\n",
        "\n",
        "        #train_samples.append(InputExample(texts=[query, passage], label=label))\n",
        "        cnt += 1\n",
        "\n",
        "        if cnt >= max_train_samples:\n",
        "            break\n",
        "print('len(all_query_ids) : ' + str(len(all_query_ids)))\n",
        "print('len(all_queries) : ' + str(len(all_queries)))\n",
        "print('len(all_document_ids) : ' + str(len(all_document_ids)))\n",
        "print('len(all_documents) : ' + str(len(all_documents)))\n",
        "print('len(all_labels) : ' + str(len(all_labels)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3qiZzKBi4mz",
        "outputId": "dc13d0af-d3ca-412f-c9d6-19ba72f52671"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(corpus.keys() : 8841823\n",
            "len(queries.keys() : 808731\n",
            "len(all_query_ids) : 50000\n",
            "len(all_queries) : 50000\n",
            "len(all_document_ids) : 50000\n",
            "len(all_documents) : 50000\n",
            "len(all_labels) : 50000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_queries, val_queries, train_docs, val_docs, train_labels, val_labels = train_test_split(\n",
        "    all_queries, \n",
        "    all_documents, \n",
        "    all_labels, \n",
        "    test_size=.2\n",
        ")"
      ],
      "metadata": {
        "id": "4SPmt2zS2cwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizerFast\n",
        "\n",
        "model_name = \"google/bert_uncased_L-4_H-512_A-8\"\n",
        "tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
        "\n",
        "train_encodings = tokenizer(train_queries, train_docs, truncation=True, padding='max_length', max_length=128)\n",
        "val_encodings = tokenizer(val_queries, val_docs, truncation=True, padding='max_length', max_length=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kmllMei2cDI",
        "outputId": "112772b5-3672-4b15-8223-d6e80555eb2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--google--bert_uncased_L-4_H-512_A-8/snapshots/606e4d55252882ac25ba1f1d1a182075830f5a90/vocab.txt\n",
            "loading file tokenizer.json from cache at None\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at None\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--bert_uncased_L-4_H-512_A-8/snapshots/606e4d55252882ac25ba1f1d1a182075830f5a90/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"google/bert_uncased_L-4_H-512_A-8\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 512,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 2048,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 8,\n",
            "  \"num_hidden_layers\": 4,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--bert_uncased_L-4_H-512_A-8/snapshots/606e4d55252882ac25ba1f1d1a182075830f5a90/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"google/bert_uncased_L-4_H-512_A-8\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 512,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 2048,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 8,\n",
            "  \"num_hidden_layers\": 4,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "class OurDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = OurDataset(train_encodings, train_labels)\n",
        "val_dataset = OurDataset(val_encodings, val_labels)\n"
      ],
      "metadata": {
        "id": "hQeyaEem2cHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXvT8afH2cKI",
        "outputId": "b70914bb-7549-4447-b5de-05c8b5f074f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--bert_uncased_L-4_H-512_A-8/snapshots/606e4d55252882ac25ba1f1d1a182075830f5a90/config.json\n",
            "Model config BertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 512,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 2048,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 8,\n",
            "  \"num_hidden_layers\": 4,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--google--bert_uncased_L-4_H-512_A-8/snapshots/606e4d55252882ac25ba1f1d1a182075830f5a90/pytorch_model.bin\n",
            "Some weights of the model checkpoint at google/bert_uncased_L-4_H-512_A-8 were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-4_H-512_A-8 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.base_model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "Zf3_Mdgx29F8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install evaluate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQRWtWhP29Ik",
        "outputId": "9e2ec3b6-4564-48fa-ae4a-94a27aa26c60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.8/dist-packages (0.4.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from evaluate) (3.1.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from evaluate) (1.3.5)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.3.6)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from evaluate) (1.21.6)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (2.7.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from evaluate) (21.3)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.70.14)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.11.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from evaluate) (4.64.1)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.18.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (2022.11.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (2.23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (3.8.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.1.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.1.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.3)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->evaluate) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (3.0.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->evaluate) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->evaluate) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "from sklearn.metrics import ndcg_score\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "import evaluate\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def my_compute_metrics_ndcg(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    print ('predictions : ' + str(predictions))\n",
        "    predictions2 = tf.nn.log_softmax(predictions, axis=-1)\n",
        "    #print(classification_report(labels, predictions))\n",
        "    return ndcg_score(predictions2, labels)\n",
        "\"\"\"\n",
        "\n",
        "def my_compute_metrics_precision(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    metric = evaluate.load(\"precision\")\n",
        "    #print('predictions : ' + str(predictions))\n",
        "    #print('labels : ' + str(labels))\n",
        "    #if task != \"stsb\":\n",
        "    predictions = np.argmax(predictions, axis=-1)\n",
        "    #else:\n",
        "    #predictions = predictions[:]\n",
        "    print(classification_report(labels, predictions))\n",
        "    return metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "\n",
        "# You can define your custom compute_metrics function. It takes an `EvalPrediction` object (a namedtuple with a\n",
        "# predictions and label_ids field) and has to return a dictionary string to float.\n",
        "def compute_metrics2(pred):\n",
        "    \"\"\"\n",
        "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
        "    preds = np.argmax(preds, axis=1)\n",
        "    return metric.compute(predictions=preds, references=p.label_ids)   \n",
        "    \"\"\"\n",
        "    print('pred : ' + str(pred))\n",
        "    # Get the metric function\n",
        "    trec_eval = evaluate.load(\"trec_eval\")\n",
        "    qrel = {}\n",
        "    qids, seen, i = [], {}, 0\n",
        "    for q in val_queries:\n",
        "      if q in seen:\n",
        "        qids.append(seen[q])\n",
        "      else:\n",
        "        seen[q] = i\n",
        "        qids.append(i)\n",
        "        i+=1\n",
        "    qrel={\n",
        "      \"query\": qids,\n",
        "      \"q0\": val_queries,\n",
        "      \"docid\": val_docs,\n",
        "      \"rel\": val_labels\n",
        "    }\n",
        "    run = {\n",
        "      \"query\": qids,\n",
        "      \"q0\": val_queries,\n",
        "      \"docid\": val_docs,\n",
        "      \"rank\": pred[1].tolist(),\n",
        "      \"score\": [max(l) for l in pred[0].tolist()],\n",
        "      \"system\": [\"test\" for i in qids]\n",
        "    }    \n",
        "    results = trec_eval.compute(references=[qrel], predictions=[run]) \n",
        "    return results\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    evaluation_strategy=\"epoch\",     # Evaluation is done at the end of each epoch.\n",
        "    num_train_epochs=2,              # total number of training epochs\n",
        "    per_device_train_batch_size=16,  # batch size per device during training\n",
        "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
        "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    learning_rate=0.005,\n",
        "    save_total_limit=1,              # limit the total amount of checkpoints. Deletes the older checkpoints.    \n",
        ")\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,                         # the instantiated Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=val_dataset,             # evaluation dataset\n",
        "    compute_metrics = compute_metrics2\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4I-s9U-l29LK",
        "outputId": "97e01b9d-5605-49a4-d8f1-f3b4a1fda09e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "***** Running training *****\n",
            "  Num examples = 40000\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 5000\n",
            "  Number of trainable parameters = 1026\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5000' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5000/5000 02:38, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Runid</th>\n",
              "      <th>Num Ret</th>\n",
              "      <th>Num Rel</th>\n",
              "      <th>Num Rel Ret</th>\n",
              "      <th>Num Q</th>\n",
              "      <th>Map</th>\n",
              "      <th>Gm Map</th>\n",
              "      <th>Bpref</th>\n",
              "      <th>Rprec</th>\n",
              "      <th>Recip Rank</th>\n",
              "      <th>P@5</th>\n",
              "      <th>P@10</th>\n",
              "      <th>P@15</th>\n",
              "      <th>P@20</th>\n",
              "      <th>P@30</th>\n",
              "      <th>P@100</th>\n",
              "      <th>P@200</th>\n",
              "      <th>P@500</th>\n",
              "      <th>P@1000</th>\n",
              "      <th>Ndcg@5</th>\n",
              "      <th>Ndcg@10</th>\n",
              "      <th>Ndcg@15</th>\n",
              "      <th>Ndcg@20</th>\n",
              "      <th>Ndcg@30</th>\n",
              "      <th>Ndcg@100</th>\n",
              "      <th>Ndcg@200</th>\n",
              "      <th>Ndcg@500</th>\n",
              "      <th>Ndcg@1000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.408400</td>\n",
              "      <td>0.398975</td>\n",
              "      <td>test</td>\n",
              "      <td>10000</td>\n",
              "      <td>2019</td>\n",
              "      <td>2027</td>\n",
              "      <td>9861</td>\n",
              "      <td>0.203833</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.001217</td>\n",
              "      <td>0.201907</td>\n",
              "      <td>0.202921</td>\n",
              "      <td>0.041111</td>\n",
              "      <td>0.020556</td>\n",
              "      <td>0.013704</td>\n",
              "      <td>0.010278</td>\n",
              "      <td>0.006852</td>\n",
              "      <td>0.002056</td>\n",
              "      <td>0.001028</td>\n",
              "      <td>0.000411</td>\n",
              "      <td>0.000206</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.337000</td>\n",
              "      <td>0.316938</td>\n",
              "      <td>test</td>\n",
              "      <td>10000</td>\n",
              "      <td>2019</td>\n",
              "      <td>2027</td>\n",
              "      <td>9861</td>\n",
              "      <td>0.203630</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000811</td>\n",
              "      <td>0.201501</td>\n",
              "      <td>0.202718</td>\n",
              "      <td>0.041111</td>\n",
              "      <td>0.020556</td>\n",
              "      <td>0.013704</td>\n",
              "      <td>0.010278</td>\n",
              "      <td>0.006852</td>\n",
              "      <td>0.002056</td>\n",
              "      <td>0.001028</td>\n",
              "      <td>0.000411</td>\n",
              "      <td>0.000206</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./results/checkpoint-500\n",
            "Configuration saved in ./results/checkpoint-500/config.json\n",
            "Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-5000] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-1000\n",
            "Configuration saved in ./results/checkpoint-1000/config.json\n",
            "Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-500] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-1500\n",
            "Configuration saved in ./results/checkpoint-1500/config.json\n",
            "Model weights saved in ./results/checkpoint-1500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-1000] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-2000\n",
            "Configuration saved in ./results/checkpoint-2000/config.json\n",
            "Model weights saved in ./results/checkpoint-2000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-1500] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-2500\n",
            "Configuration saved in ./results/checkpoint-2500/config.json\n",
            "Model weights saved in ./results/checkpoint-2500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-2000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 10000\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f8935ed00a0>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to ./results/checkpoint-3000\n",
            "Configuration saved in ./results/checkpoint-3000/config.json\n",
            "Model weights saved in ./results/checkpoint-3000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-2500] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-3500\n",
            "Configuration saved in ./results/checkpoint-3500/config.json\n",
            "Model weights saved in ./results/checkpoint-3500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-3000] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-4000\n",
            "Configuration saved in ./results/checkpoint-4000/config.json\n",
            "Model weights saved in ./results/checkpoint-4000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-3500] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-4500\n",
            "Configuration saved in ./results/checkpoint-4500/config.json\n",
            "Model weights saved in ./results/checkpoint-4500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-4000] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-5000\n",
            "Configuration saved in ./results/checkpoint-5000/config.json\n",
            "Model weights saved in ./results/checkpoint-5000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-4500] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 10000\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f88374a5f10>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=5000, training_loss=0.3905830169677734, metrics={'train_runtime': 158.1736, 'train_samples_per_second': 505.774, 'train_steps_per_second': 31.611, 'total_flos': 790993428480000.0, 'train_loss': 0.3905830169677734, 'epoch': 2.0})"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "from sklearn.metrics import ndcg_score\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "import evaluate\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def my_compute_metrics_ndcg(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    print ('predictions : ' + str(predictions))\n",
        "    predictions2 = tf.nn.log_softmax(predictions, axis=-1)\n",
        "    #print(classification_report(labels, predictions))\n",
        "    return ndcg_score(predictions2, labels)\n",
        "\"\"\"\n",
        "\n",
        "def my_compute_metrics_precision(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    metric = evaluate.load(\"precision\")\n",
        "    #print('predictions : ' + str(predictions))\n",
        "    #print('labels : ' + str(labels))\n",
        "    #if task != \"stsb\":\n",
        "    predictions = np.argmax(predictions, axis=-1)\n",
        "    #else:\n",
        "    #predictions = predictions[:]\n",
        "    print(classification_report(labels, predictions))\n",
        "    return metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "\n",
        "# You can define your custom compute_metrics function. It takes an `EvalPrediction` object (a namedtuple with a\n",
        "# predictions and label_ids field) and has to return a dictionary string to float.\n",
        "def compute_metrics2(pred):\n",
        "    \"\"\"\n",
        "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
        "    preds = np.argmax(preds, axis=1)\n",
        "    return metric.compute(predictions=preds, references=p.label_ids)   \n",
        "    \"\"\"\n",
        "    print('pred : ' + str(pred))\n",
        "    # Get the metric function\n",
        "    trec_eval = evaluate.load(\"trec_eval\")\n",
        "    qrel = {}\n",
        "    qids, seen, i = [], {}, 0\n",
        "    for q in val_queries:\n",
        "      if q in seen:\n",
        "        qids.append(seen[q])\n",
        "      else:\n",
        "        seen[q] = i\n",
        "        qids.append(i)\n",
        "        i+=1\n",
        "    qrel={\n",
        "      \"query\": qids,\n",
        "      \"q0\": val_queries,\n",
        "      \"docid\": val_docs,\n",
        "      \"rel\": val_labels\n",
        "    }\n",
        "    run = {\n",
        "      \"query\": qids,\n",
        "      \"q0\": val_queries,\n",
        "      \"docid\": val_docs,\n",
        "      \"rank\": pred[1].tolist(),\n",
        "      \"score\": [max(l) for l in pred[0].tolist()],\n",
        "      \"system\": [\"test\" for i in qids]\n",
        "    }    \n",
        "    results = trec_eval.compute(references=[qrel], predictions=[run]) \n",
        "    return results\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    evaluation_strategy=\"epoch\",     # Evaluation is done at the end of each epoch.\n",
        "    num_train_epochs=20,              # total number of training epochs\n",
        "    per_device_train_batch_size=16,  # batch size per device during training\n",
        "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
        "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    learning_rate=0.5,\n",
        "    save_total_limit=1,              # limit the total amount of checkpoints. Deletes the older checkpoints.    \n",
        ")\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,                         # the instantiated Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=val_dataset,             # evaluation dataset\n",
        "    compute_metrics = compute_metrics2\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QSsfl7a8LwsY",
        "outputId": "9cdaf09f-4180-40fd-f808-4b9ae02214ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 40000\n",
            "  Num Epochs = 20\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 50000\n",
            "  Number of trainable parameters = 1026\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='50000' max='50000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [50000/50000 24:58, Epoch 20/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Runid</th>\n",
              "      <th>Num Ret</th>\n",
              "      <th>Num Rel</th>\n",
              "      <th>Num Rel Ret</th>\n",
              "      <th>Num Q</th>\n",
              "      <th>Map</th>\n",
              "      <th>Gm Map</th>\n",
              "      <th>Bpref</th>\n",
              "      <th>Rprec</th>\n",
              "      <th>Recip Rank</th>\n",
              "      <th>P@5</th>\n",
              "      <th>P@10</th>\n",
              "      <th>P@15</th>\n",
              "      <th>P@20</th>\n",
              "      <th>P@30</th>\n",
              "      <th>P@100</th>\n",
              "      <th>P@200</th>\n",
              "      <th>P@500</th>\n",
              "      <th>P@1000</th>\n",
              "      <th>Ndcg@5</th>\n",
              "      <th>Ndcg@10</th>\n",
              "      <th>Ndcg@15</th>\n",
              "      <th>Ndcg@20</th>\n",
              "      <th>Ndcg@30</th>\n",
              "      <th>Ndcg@100</th>\n",
              "      <th>Ndcg@200</th>\n",
              "      <th>Ndcg@500</th>\n",
              "      <th>Ndcg@1000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>12.781900</td>\n",
              "      <td>8.927734</td>\n",
              "      <td>test</td>\n",
              "      <td>10000</td>\n",
              "      <td>2019</td>\n",
              "      <td>2027</td>\n",
              "      <td>9861</td>\n",
              "      <td>0.204239</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.002028</td>\n",
              "      <td>0.202718</td>\n",
              "      <td>0.203326</td>\n",
              "      <td>0.041111</td>\n",
              "      <td>0.020556</td>\n",
              "      <td>0.013704</td>\n",
              "      <td>0.010278</td>\n",
              "      <td>0.006852</td>\n",
              "      <td>0.002056</td>\n",
              "      <td>0.001028</td>\n",
              "      <td>0.000411</td>\n",
              "      <td>0.000206</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>10.490900</td>\n",
              "      <td>9.888544</td>\n",
              "      <td>test</td>\n",
              "      <td>10000</td>\n",
              "      <td>2019</td>\n",
              "      <td>2027</td>\n",
              "      <td>9861</td>\n",
              "      <td>0.203580</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000710</td>\n",
              "      <td>0.201399</td>\n",
              "      <td>0.202667</td>\n",
              "      <td>0.041111</td>\n",
              "      <td>0.020556</td>\n",
              "      <td>0.013704</td>\n",
              "      <td>0.010278</td>\n",
              "      <td>0.006852</td>\n",
              "      <td>0.002056</td>\n",
              "      <td>0.001028</td>\n",
              "      <td>0.000411</td>\n",
              "      <td>0.000206</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>12.961900</td>\n",
              "      <td>16.784935</td>\n",
              "      <td>test</td>\n",
              "      <td>10000</td>\n",
              "      <td>2019</td>\n",
              "      <td>2027</td>\n",
              "      <td>9861</td>\n",
              "      <td>0.204442</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.002434</td>\n",
              "      <td>0.203123</td>\n",
              "      <td>0.203529</td>\n",
              "      <td>0.041111</td>\n",
              "      <td>0.020556</td>\n",
              "      <td>0.013704</td>\n",
              "      <td>0.010278</td>\n",
              "      <td>0.006852</td>\n",
              "      <td>0.002056</td>\n",
              "      <td>0.001028</td>\n",
              "      <td>0.000411</td>\n",
              "      <td>0.000206</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>11.634700</td>\n",
              "      <td>26.208387</td>\n",
              "      <td>test</td>\n",
              "      <td>10000</td>\n",
              "      <td>2019</td>\n",
              "      <td>2027</td>\n",
              "      <td>9861</td>\n",
              "      <td>0.204797</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.003144</td>\n",
              "      <td>0.203833</td>\n",
              "      <td>0.203884</td>\n",
              "      <td>0.041111</td>\n",
              "      <td>0.020556</td>\n",
              "      <td>0.013704</td>\n",
              "      <td>0.010278</td>\n",
              "      <td>0.006852</td>\n",
              "      <td>0.002056</td>\n",
              "      <td>0.001028</td>\n",
              "      <td>0.000411</td>\n",
              "      <td>0.000206</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>9.840400</td>\n",
              "      <td>9.297599</td>\n",
              "      <td>test</td>\n",
              "      <td>10000</td>\n",
              "      <td>2019</td>\n",
              "      <td>2027</td>\n",
              "      <td>9861</td>\n",
              "      <td>0.204340</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.002231</td>\n",
              "      <td>0.202921</td>\n",
              "      <td>0.203428</td>\n",
              "      <td>0.041111</td>\n",
              "      <td>0.020556</td>\n",
              "      <td>0.013704</td>\n",
              "      <td>0.010278</td>\n",
              "      <td>0.006852</td>\n",
              "      <td>0.002056</td>\n",
              "      <td>0.001028</td>\n",
              "      <td>0.000411</td>\n",
              "      <td>0.000206</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>8.801800</td>\n",
              "      <td>4.364242</td>\n",
              "      <td>test</td>\n",
              "      <td>10000</td>\n",
              "      <td>2019</td>\n",
              "      <td>2027</td>\n",
              "      <td>9861</td>\n",
              "      <td>0.203833</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.001217</td>\n",
              "      <td>0.201907</td>\n",
              "      <td>0.202921</td>\n",
              "      <td>0.041111</td>\n",
              "      <td>0.020556</td>\n",
              "      <td>0.013704</td>\n",
              "      <td>0.010278</td>\n",
              "      <td>0.006852</td>\n",
              "      <td>0.002056</td>\n",
              "      <td>0.001028</td>\n",
              "      <td>0.000411</td>\n",
              "      <td>0.000206</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>8.928300</td>\n",
              "      <td>4.940401</td>\n",
              "      <td>test</td>\n",
              "      <td>10000</td>\n",
              "      <td>2019</td>\n",
              "      <td>2027</td>\n",
              "      <td>9861</td>\n",
              "      <td>0.203783</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.001116</td>\n",
              "      <td>0.201805</td>\n",
              "      <td>0.202870</td>\n",
              "      <td>0.041111</td>\n",
              "      <td>0.020556</td>\n",
              "      <td>0.013704</td>\n",
              "      <td>0.010278</td>\n",
              "      <td>0.006852</td>\n",
              "      <td>0.002056</td>\n",
              "      <td>0.001028</td>\n",
              "      <td>0.000411</td>\n",
              "      <td>0.000206</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>7.190100</td>\n",
              "      <td>6.363775</td>\n",
              "      <td>test</td>\n",
              "      <td>10000</td>\n",
              "      <td>2019</td>\n",
              "      <td>2027</td>\n",
              "      <td>9861</td>\n",
              "      <td>0.203428</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000406</td>\n",
              "      <td>0.201095</td>\n",
              "      <td>0.202515</td>\n",
              "      <td>0.041111</td>\n",
              "      <td>0.020556</td>\n",
              "      <td>0.013704</td>\n",
              "      <td>0.010278</td>\n",
              "      <td>0.006852</td>\n",
              "      <td>0.002056</td>\n",
              "      <td>0.001028</td>\n",
              "      <td>0.000411</td>\n",
              "      <td>0.000206</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>7.104800</td>\n",
              "      <td>3.605003</td>\n",
              "      <td>test</td>\n",
              "      <td>10000</td>\n",
              "      <td>2019</td>\n",
              "      <td>2027</td>\n",
              "      <td>9861</td>\n",
              "      <td>0.203630</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000811</td>\n",
              "      <td>0.201501</td>\n",
              "      <td>0.202718</td>\n",
              "      <td>0.041111</td>\n",
              "      <td>0.020556</td>\n",
              "      <td>0.013704</td>\n",
              "      <td>0.010278</td>\n",
              "      <td>0.006852</td>\n",
              "      <td>0.002056</td>\n",
              "      <td>0.001028</td>\n",
              "      <td>0.000411</td>\n",
              "      <td>0.000206</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>7.423800</td>\n",
              "      <td>4.504321</td>\n",
              "      <td>test</td>\n",
              "      <td>10000</td>\n",
              "      <td>2019</td>\n",
              "      <td>2027</td>\n",
              "      <td>9861</td>\n",
              "      <td>0.203985</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.001521</td>\n",
              "      <td>0.202211</td>\n",
              "      <td>0.203073</td>\n",
              "      <td>0.041111</td>\n",
              "      <td>0.020556</td>\n",
              "      <td>0.013704</td>\n",
              "      <td>0.010278</td>\n",
              "      <td>0.006852</td>\n",
              "      <td>0.002056</td>\n",
              "      <td>0.001028</td>\n",
              "      <td>0.000411</td>\n",
              "      <td>0.000206</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>6.596700</td>\n",
              "      <td>14.393684</td>\n",
              "      <td>test</td>\n",
              "      <td>10000</td>\n",
              "      <td>2019</td>\n",
              "      <td>2027</td>\n",
              "      <td>9861</td>\n",
              "      <td>0.204898</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.003347</td>\n",
              "      <td>0.204036</td>\n",
              "      <td>0.203985</td>\n",
              "      <td>0.041111</td>\n",
              "      <td>0.020556</td>\n",
              "      <td>0.013704</td>\n",
              "      <td>0.010278</td>\n",
              "      <td>0.006852</td>\n",
              "      <td>0.002056</td>\n",
              "      <td>0.001028</td>\n",
              "      <td>0.000411</td>\n",
              "      <td>0.000206</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>5.723800</td>\n",
              "      <td>3.508503</td>\n",
              "      <td>test</td>\n",
              "      <td>10000</td>\n",
              "      <td>2019</td>\n",
              "      <td>2027</td>\n",
              "      <td>9861</td>\n",
              "      <td>0.203529</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000608</td>\n",
              "      <td>0.201298</td>\n",
              "      <td>0.202616</td>\n",
              "      <td>0.041111</td>\n",
              "      <td>0.020556</td>\n",
              "      <td>0.013704</td>\n",
              "      <td>0.010278</td>\n",
              "      <td>0.006852</td>\n",
              "      <td>0.002056</td>\n",
              "      <td>0.001028</td>\n",
              "      <td>0.000411</td>\n",
              "      <td>0.000206</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>5.613300</td>\n",
              "      <td>3.790847</td>\n",
              "      <td>test</td>\n",
              "      <td>10000</td>\n",
              "      <td>2019</td>\n",
              "      <td>2027</td>\n",
              "      <td>9861</td>\n",
              "      <td>0.203529</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000608</td>\n",
              "      <td>0.201298</td>\n",
              "      <td>0.202616</td>\n",
              "      <td>0.041111</td>\n",
              "      <td>0.020556</td>\n",
              "      <td>0.013704</td>\n",
              "      <td>0.010278</td>\n",
              "      <td>0.006852</td>\n",
              "      <td>0.002056</td>\n",
              "      <td>0.001028</td>\n",
              "      <td>0.000411</td>\n",
              "      <td>0.000206</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>4.414800</td>\n",
              "      <td>6.592463</td>\n",
              "      <td>test</td>\n",
              "      <td>10000</td>\n",
              "      <td>2019</td>\n",
              "      <td>2027</td>\n",
              "      <td>9861</td>\n",
              "      <td>0.203326</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000203</td>\n",
              "      <td>0.200892</td>\n",
              "      <td>0.202414</td>\n",
              "      <td>0.041111</td>\n",
              "      <td>0.020556</td>\n",
              "      <td>0.013704</td>\n",
              "      <td>0.010278</td>\n",
              "      <td>0.006852</td>\n",
              "      <td>0.002056</td>\n",
              "      <td>0.001028</td>\n",
              "      <td>0.000411</td>\n",
              "      <td>0.000206</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>4.232200</td>\n",
              "      <td>4.085636</td>\n",
              "      <td>test</td>\n",
              "      <td>10000</td>\n",
              "      <td>2019</td>\n",
              "      <td>2027</td>\n",
              "      <td>9861</td>\n",
              "      <td>0.203326</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000203</td>\n",
              "      <td>0.200892</td>\n",
              "      <td>0.202414</td>\n",
              "      <td>0.041111</td>\n",
              "      <td>0.020556</td>\n",
              "      <td>0.013704</td>\n",
              "      <td>0.010278</td>\n",
              "      <td>0.006852</td>\n",
              "      <td>0.002056</td>\n",
              "      <td>0.001028</td>\n",
              "      <td>0.000411</td>\n",
              "      <td>0.000206</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>3.381600</td>\n",
              "      <td>1.413009</td>\n",
              "      <td>test</td>\n",
              "      <td>10000</td>\n",
              "      <td>2019</td>\n",
              "      <td>2027</td>\n",
              "      <td>9861</td>\n",
              "      <td>0.203478</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000507</td>\n",
              "      <td>0.201197</td>\n",
              "      <td>0.202566</td>\n",
              "      <td>0.041111</td>\n",
              "      <td>0.020556</td>\n",
              "      <td>0.013704</td>\n",
              "      <td>0.010278</td>\n",
              "      <td>0.006852</td>\n",
              "      <td>0.002056</td>\n",
              "      <td>0.001028</td>\n",
              "      <td>0.000411</td>\n",
              "      <td>0.000206</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>2.508300</td>\n",
              "      <td>1.524543</td>\n",
              "      <td>test</td>\n",
              "      <td>10000</td>\n",
              "      <td>2019</td>\n",
              "      <td>2027</td>\n",
              "      <td>9861</td>\n",
              "      <td>0.203630</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000811</td>\n",
              "      <td>0.201501</td>\n",
              "      <td>0.202718</td>\n",
              "      <td>0.041111</td>\n",
              "      <td>0.020556</td>\n",
              "      <td>0.013704</td>\n",
              "      <td>0.010278</td>\n",
              "      <td>0.006852</td>\n",
              "      <td>0.002056</td>\n",
              "      <td>0.001028</td>\n",
              "      <td>0.000411</td>\n",
              "      <td>0.000206</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>1.732400</td>\n",
              "      <td>1.137235</td>\n",
              "      <td>test</td>\n",
              "      <td>10000</td>\n",
              "      <td>2019</td>\n",
              "      <td>2027</td>\n",
              "      <td>9861</td>\n",
              "      <td>0.203833</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.001217</td>\n",
              "      <td>0.201907</td>\n",
              "      <td>0.202921</td>\n",
              "      <td>0.041111</td>\n",
              "      <td>0.020556</td>\n",
              "      <td>0.013704</td>\n",
              "      <td>0.010278</td>\n",
              "      <td>0.006852</td>\n",
              "      <td>0.002056</td>\n",
              "      <td>0.001028</td>\n",
              "      <td>0.000411</td>\n",
              "      <td>0.000206</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>1.061600</td>\n",
              "      <td>0.581969</td>\n",
              "      <td>test</td>\n",
              "      <td>10000</td>\n",
              "      <td>2019</td>\n",
              "      <td>2027</td>\n",
              "      <td>9861</td>\n",
              "      <td>0.203630</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000811</td>\n",
              "      <td>0.201501</td>\n",
              "      <td>0.202718</td>\n",
              "      <td>0.041111</td>\n",
              "      <td>0.020556</td>\n",
              "      <td>0.013704</td>\n",
              "      <td>0.010278</td>\n",
              "      <td>0.006852</td>\n",
              "      <td>0.002056</td>\n",
              "      <td>0.001028</td>\n",
              "      <td>0.000411</td>\n",
              "      <td>0.000206</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.503000</td>\n",
              "      <td>0.344158</td>\n",
              "      <td>test</td>\n",
              "      <td>10000</td>\n",
              "      <td>2019</td>\n",
              "      <td>2027</td>\n",
              "      <td>9861</td>\n",
              "      <td>0.203681</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000913</td>\n",
              "      <td>0.201602</td>\n",
              "      <td>0.202768</td>\n",
              "      <td>0.041111</td>\n",
              "      <td>0.020556</td>\n",
              "      <td>0.013704</td>\n",
              "      <td>0.010278</td>\n",
              "      <td>0.006852</td>\n",
              "      <td>0.002056</td>\n",
              "      <td>0.001028</td>\n",
              "      <td>0.000411</td>\n",
              "      <td>0.000206</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "      <td>0.204035</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./results/checkpoint-500\n",
            "Configuration saved in ./results/checkpoint-500/config.json\n",
            "Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-5000] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-1000\n",
            "Configuration saved in ./results/checkpoint-1000/config.json\n",
            "Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-500] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-1500\n",
            "Configuration saved in ./results/checkpoint-1500/config.json\n",
            "Model weights saved in ./results/checkpoint-1500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-1000] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-2000\n",
            "Configuration saved in ./results/checkpoint-2000/config.json\n",
            "Model weights saved in ./results/checkpoint-2000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-1500] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-2500\n",
            "Configuration saved in ./results/checkpoint-2500/config.json\n",
            "Model weights saved in ./results/checkpoint-2500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-2000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 10000\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f8833ea3370>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to ./results/checkpoint-3000\n",
            "Configuration saved in ./results/checkpoint-3000/config.json\n",
            "Model weights saved in ./results/checkpoint-3000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-2500] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-3500\n",
            "Configuration saved in ./results/checkpoint-3500/config.json\n",
            "Model weights saved in ./results/checkpoint-3500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-3000] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-4000\n",
            "Configuration saved in ./results/checkpoint-4000/config.json\n",
            "Model weights saved in ./results/checkpoint-4000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-3500] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-4500\n",
            "Configuration saved in ./results/checkpoint-4500/config.json\n",
            "Model weights saved in ./results/checkpoint-4500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-4000] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-5000\n",
            "Configuration saved in ./results/checkpoint-5000/config.json\n",
            "Model weights saved in ./results/checkpoint-5000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-4500] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 10000\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f8935d95b20>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to ./results/checkpoint-5500\n",
            "Configuration saved in ./results/checkpoint-5500/config.json\n",
            "Model weights saved in ./results/checkpoint-5500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-5000] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-6000\n",
            "Configuration saved in ./results/checkpoint-6000/config.json\n",
            "Model weights saved in ./results/checkpoint-6000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-5500] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-6500\n",
            "Configuration saved in ./results/checkpoint-6500/config.json\n",
            "Model weights saved in ./results/checkpoint-6500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-6000] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-7000\n",
            "Configuration saved in ./results/checkpoint-7000/config.json\n",
            "Model weights saved in ./results/checkpoint-7000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-6500] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-7500\n",
            "Configuration saved in ./results/checkpoint-7500/config.json\n",
            "Model weights saved in ./results/checkpoint-7500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-7000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 10000\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f8935a9a820>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to ./results/checkpoint-8000\n",
            "Configuration saved in ./results/checkpoint-8000/config.json\n",
            "Model weights saved in ./results/checkpoint-8000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-7500] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-8500\n",
            "Configuration saved in ./results/checkpoint-8500/config.json\n",
            "Model weights saved in ./results/checkpoint-8500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-8000] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-9000\n",
            "Configuration saved in ./results/checkpoint-9000/config.json\n",
            "Model weights saved in ./results/checkpoint-9000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-8500] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-9500\n",
            "Configuration saved in ./results/checkpoint-9500/config.json\n",
            "Model weights saved in ./results/checkpoint-9500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-9000] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-10000\n",
            "Configuration saved in ./results/checkpoint-10000/config.json\n",
            "Model weights saved in ./results/checkpoint-10000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-9500] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 10000\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f8a72d17df0>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to ./results/checkpoint-10500\n",
            "Configuration saved in ./results/checkpoint-10500/config.json\n",
            "Model weights saved in ./results/checkpoint-10500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-10000] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-11000\n",
            "Configuration saved in ./results/checkpoint-11000/config.json\n",
            "Model weights saved in ./results/checkpoint-11000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-10500] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-11500\n",
            "Configuration saved in ./results/checkpoint-11500/config.json\n",
            "Model weights saved in ./results/checkpoint-11500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-11000] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-12000\n",
            "Configuration saved in ./results/checkpoint-12000/config.json\n",
            "Model weights saved in ./results/checkpoint-12000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-11500] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-12500\n",
            "Configuration saved in ./results/checkpoint-12500/config.json\n",
            "Model weights saved in ./results/checkpoint-12500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-12000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 10000\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f893600a040>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to ./results/checkpoint-13000\n",
            "Configuration saved in ./results/checkpoint-13000/config.json\n",
            "Model weights saved in ./results/checkpoint-13000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-12500] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-13500\n",
            "Configuration saved in ./results/checkpoint-13500/config.json\n",
            "Model weights saved in ./results/checkpoint-13500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-13000] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-14000\n",
            "Configuration saved in ./results/checkpoint-14000/config.json\n",
            "Model weights saved in ./results/checkpoint-14000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-13500] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-14500\n",
            "Configuration saved in ./results/checkpoint-14500/config.json\n",
            "Model weights saved in ./results/checkpoint-14500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-14000] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-15000\n",
            "Configuration saved in ./results/checkpoint-15000/config.json\n",
            "Model weights saved in ./results/checkpoint-15000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-14500] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 10000\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f8a72d17df0>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to ./results/checkpoint-15500\n",
            "Configuration saved in ./results/checkpoint-15500/config.json\n",
            "Model weights saved in ./results/checkpoint-15500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-15000] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-16000\n",
            "Configuration saved in ./results/checkpoint-16000/config.json\n",
            "Model weights saved in ./results/checkpoint-16000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-15500] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-16500\n",
            "Configuration saved in ./results/checkpoint-16500/config.json\n",
            "Model weights saved in ./results/checkpoint-16500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-16000] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-17000\n",
            "Configuration saved in ./results/checkpoint-17000/config.json\n",
            "Model weights saved in ./results/checkpoint-17000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-16500] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-17500\n",
            "Configuration saved in ./results/checkpoint-17500/config.json\n",
            "Model weights saved in ./results/checkpoint-17500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-17000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 10000\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f893ddf4df0>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to ./results/checkpoint-18000\n",
            "Configuration saved in ./results/checkpoint-18000/config.json\n",
            "Model weights saved in ./results/checkpoint-18000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-17500] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-18500\n",
            "Configuration saved in ./results/checkpoint-18500/config.json\n",
            "Model weights saved in ./results/checkpoint-18500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-18000] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-19000\n",
            "Configuration saved in ./results/checkpoint-19000/config.json\n",
            "Model weights saved in ./results/checkpoint-19000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-18500] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-19500\n",
            "Configuration saved in ./results/checkpoint-19500/config.json\n",
            "Model weights saved in ./results/checkpoint-19500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-19000] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-20000\n",
            "Configuration saved in ./results/checkpoint-20000/config.json\n",
            "Model weights saved in ./results/checkpoint-20000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-19500] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 10000\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f8832286160>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to ./results/checkpoint-20500\n",
            "Configuration saved in ./results/checkpoint-20500/config.json\n",
            "Model weights saved in ./results/checkpoint-20500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-20000] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-21000\n",
            "Configuration saved in ./results/checkpoint-21000/config.json\n",
            "Model weights saved in ./results/checkpoint-21000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-20500] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-21500\n",
            "Configuration saved in ./results/checkpoint-21500/config.json\n",
            "Model weights saved in ./results/checkpoint-21500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-21000] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-22000\n",
            "Configuration saved in ./results/checkpoint-22000/config.json\n",
            "Model weights saved in ./results/checkpoint-22000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-21500] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-22500\n",
            "Configuration saved in ./results/checkpoint-22500/config.json\n",
            "Model weights saved in ./results/checkpoint-22500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-22000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 10000\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f893ddf4df0>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to ./results/checkpoint-23000\n",
            "Configuration saved in ./results/checkpoint-23000/config.json\n",
            "Model weights saved in ./results/checkpoint-23000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-22500] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-23500\n",
            "Configuration saved in ./results/checkpoint-23500/config.json\n",
            "Model weights saved in ./results/checkpoint-23500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-23000] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-24000\n",
            "Configuration saved in ./results/checkpoint-24000/config.json\n",
            "Model weights saved in ./results/checkpoint-24000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-23500] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-24500\n",
            "Configuration saved in ./results/checkpoint-24500/config.json\n",
            "Model weights saved in ./results/checkpoint-24500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-24000] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-25000\n",
            "Configuration saved in ./results/checkpoint-25000/config.json\n",
            "Model weights saved in ./results/checkpoint-25000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-24500] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 10000\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f8934e5eb20>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to ./results/checkpoint-25500\n",
            "Configuration saved in ./results/checkpoint-25500/config.json\n",
            "Model weights saved in ./results/checkpoint-25500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-25000] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-26000\n",
            "Configuration saved in ./results/checkpoint-26000/config.json\n",
            "Model weights saved in ./results/checkpoint-26000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-25500] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-26500\n",
            "Configuration saved in ./results/checkpoint-26500/config.json\n",
            "Model weights saved in ./results/checkpoint-26500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-26000] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-27000\n",
            "Configuration saved in ./results/checkpoint-27000/config.json\n",
            "Model weights saved in ./results/checkpoint-27000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-26500] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-27500\n",
            "Configuration saved in ./results/checkpoint-27500/config.json\n",
            "Model weights saved in ./results/checkpoint-27500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-27000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 10000\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f893a20e640>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to ./results/checkpoint-28000\n",
            "Configuration saved in ./results/checkpoint-28000/config.json\n",
            "Model weights saved in ./results/checkpoint-28000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-27500] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-28500\n",
            "Configuration saved in ./results/checkpoint-28500/config.json\n",
            "Model weights saved in ./results/checkpoint-28500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-28000] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-29000\n",
            "Configuration saved in ./results/checkpoint-29000/config.json\n",
            "Model weights saved in ./results/checkpoint-29000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-28500] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-29500\n",
            "Configuration saved in ./results/checkpoint-29500/config.json\n",
            "Model weights saved in ./results/checkpoint-29500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-29000] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-30000\n",
            "Configuration saved in ./results/checkpoint-30000/config.json\n",
            "Model weights saved in ./results/checkpoint-30000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-29500] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 10000\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f8934e5eb20>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to ./results/checkpoint-30500\n",
            "Configuration saved in ./results/checkpoint-30500/config.json\n",
            "Model weights saved in ./results/checkpoint-30500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-30000] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-31000\n",
            "Configuration saved in ./results/checkpoint-31000/config.json\n",
            "Model weights saved in ./results/checkpoint-31000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-30500] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-31500\n",
            "Configuration saved in ./results/checkpoint-31500/config.json\n",
            "Model weights saved in ./results/checkpoint-31500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-31000] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-32000\n",
            "Configuration saved in ./results/checkpoint-32000/config.json\n",
            "Model weights saved in ./results/checkpoint-32000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-31500] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-32500\n",
            "Configuration saved in ./results/checkpoint-32500/config.json\n",
            "Model weights saved in ./results/checkpoint-32500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-32000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 10000\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f8936e5a040>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to ./results/checkpoint-33000\n",
            "Configuration saved in ./results/checkpoint-33000/config.json\n",
            "Model weights saved in ./results/checkpoint-33000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-32500] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-33500\n",
            "Configuration saved in ./results/checkpoint-33500/config.json\n",
            "Model weights saved in ./results/checkpoint-33500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-33000] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-34000\n",
            "Configuration saved in ./results/checkpoint-34000/config.json\n",
            "Model weights saved in ./results/checkpoint-34000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-33500] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-34500\n",
            "Configuration saved in ./results/checkpoint-34500/config.json\n",
            "Model weights saved in ./results/checkpoint-34500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-34000] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-35000\n",
            "Configuration saved in ./results/checkpoint-35000/config.json\n",
            "Model weights saved in ./results/checkpoint-35000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-34500] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 10000\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f8934e5eb20>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to ./results/checkpoint-35500\n",
            "Configuration saved in ./results/checkpoint-35500/config.json\n",
            "Model weights saved in ./results/checkpoint-35500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-35000] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-36000\n",
            "Configuration saved in ./results/checkpoint-36000/config.json\n",
            "Model weights saved in ./results/checkpoint-36000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-35500] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-36500\n",
            "Configuration saved in ./results/checkpoint-36500/config.json\n",
            "Model weights saved in ./results/checkpoint-36500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-36000] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-37000\n",
            "Configuration saved in ./results/checkpoint-37000/config.json\n",
            "Model weights saved in ./results/checkpoint-37000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-36500] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-37500\n",
            "Configuration saved in ./results/checkpoint-37500/config.json\n",
            "Model weights saved in ./results/checkpoint-37500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-37000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 10000\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f8936e5a040>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to ./results/checkpoint-38000\n",
            "Configuration saved in ./results/checkpoint-38000/config.json\n",
            "Model weights saved in ./results/checkpoint-38000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-37500] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-38500\n",
            "Configuration saved in ./results/checkpoint-38500/config.json\n",
            "Model weights saved in ./results/checkpoint-38500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-38000] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-39000\n",
            "Configuration saved in ./results/checkpoint-39000/config.json\n",
            "Model weights saved in ./results/checkpoint-39000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-38500] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-39500\n",
            "Configuration saved in ./results/checkpoint-39500/config.json\n",
            "Model weights saved in ./results/checkpoint-39500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-39000] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-40000\n",
            "Configuration saved in ./results/checkpoint-40000/config.json\n",
            "Model weights saved in ./results/checkpoint-40000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-39500] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 10000\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f8846975f40>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to ./results/checkpoint-40500\n",
            "Configuration saved in ./results/checkpoint-40500/config.json\n",
            "Model weights saved in ./results/checkpoint-40500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-40000] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-41000\n",
            "Configuration saved in ./results/checkpoint-41000/config.json\n",
            "Model weights saved in ./results/checkpoint-41000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-40500] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-41500\n",
            "Configuration saved in ./results/checkpoint-41500/config.json\n",
            "Model weights saved in ./results/checkpoint-41500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-41000] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-42000\n",
            "Configuration saved in ./results/checkpoint-42000/config.json\n",
            "Model weights saved in ./results/checkpoint-42000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-41500] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-42500\n",
            "Configuration saved in ./results/checkpoint-42500/config.json\n",
            "Model weights saved in ./results/checkpoint-42500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-42000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 10000\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f8935ca2670>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to ./results/checkpoint-43000\n",
            "Configuration saved in ./results/checkpoint-43000/config.json\n",
            "Model weights saved in ./results/checkpoint-43000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-42500] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-43500\n",
            "Configuration saved in ./results/checkpoint-43500/config.json\n",
            "Model weights saved in ./results/checkpoint-43500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-43000] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-44000\n",
            "Configuration saved in ./results/checkpoint-44000/config.json\n",
            "Model weights saved in ./results/checkpoint-44000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-43500] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-44500\n",
            "Configuration saved in ./results/checkpoint-44500/config.json\n",
            "Model weights saved in ./results/checkpoint-44500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-44000] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-45000\n",
            "Configuration saved in ./results/checkpoint-45000/config.json\n",
            "Model weights saved in ./results/checkpoint-45000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-44500] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 10000\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f89349ae0a0>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to ./results/checkpoint-45500\n",
            "Configuration saved in ./results/checkpoint-45500/config.json\n",
            "Model weights saved in ./results/checkpoint-45500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-45000] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-46000\n",
            "Configuration saved in ./results/checkpoint-46000/config.json\n",
            "Model weights saved in ./results/checkpoint-46000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-45500] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-46500\n",
            "Configuration saved in ./results/checkpoint-46500/config.json\n",
            "Model weights saved in ./results/checkpoint-46500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-46000] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-47000\n",
            "Configuration saved in ./results/checkpoint-47000/config.json\n",
            "Model weights saved in ./results/checkpoint-47000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-46500] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-47500\n",
            "Configuration saved in ./results/checkpoint-47500/config.json\n",
            "Model weights saved in ./results/checkpoint-47500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-47000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 10000\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f8936e5a040>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to ./results/checkpoint-48000\n",
            "Configuration saved in ./results/checkpoint-48000/config.json\n",
            "Model weights saved in ./results/checkpoint-48000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-47500] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-48500\n",
            "Configuration saved in ./results/checkpoint-48500/config.json\n",
            "Model weights saved in ./results/checkpoint-48500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-48000] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-49000\n",
            "Configuration saved in ./results/checkpoint-49000/config.json\n",
            "Model weights saved in ./results/checkpoint-49000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-48500] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-49500\n",
            "Configuration saved in ./results/checkpoint-49500/config.json\n",
            "Model weights saved in ./results/checkpoint-49500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-49000] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-50000\n",
            "Configuration saved in ./results/checkpoint-50000/config.json\n",
            "Model weights saved in ./results/checkpoint-50000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-49500] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 10000\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f8832035f70>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=50000, training_loss=6.857176039428711, metrics={'train_runtime': 1498.803, 'train_samples_per_second': 533.759, 'train_steps_per_second': 33.36, 'total_flos': 7909934284800000.0, 'train_loss': 6.857176039428711, 'epoch': 20.0})"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install trectools"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-c882Rb73XzN",
        "outputId": "071864c9-e900-45b9-84bd-3becac267f53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: trectools in /usr/local/lib/python3.8/dist-packages (0.0.49)\n",
            "Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.8/dist-packages (from trectools) (4.9.1)\n",
            "Requirement already satisfied: scipy>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from trectools) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn>=0.15 in /usr/local/lib/python3.8/dist-packages (from trectools) (1.0.2)\n",
            "Requirement already satisfied: sarge>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from trectools) (0.1.7.post1)\n",
            "Requirement already satisfied: bs4>=0.0.0.1 in /usr/local/lib/python3.8/dist-packages (from trectools) (0.0.1)\n",
            "Requirement already satisfied: matplotlib>=1.5 in /usr/local/lib/python3.8/dist-packages (from trectools) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from trectools) (1.21.6)\n",
            "Requirement already satisfied: pandas>=0.15.0 in /usr/local/lib/python3.8/dist-packages (from trectools) (1.3.5)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from bs4>=0.0.0.1->trectools) (4.6.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.5->trectools) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.5->trectools) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.5->trectools) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.5->trectools) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.15.0->trectools) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib>=1.5->trectools) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.15->trectools) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.15->trectools) (1.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = trainer.predict(val_dataset)\n",
        "#predictions = \n",
        "#print('pred : ' + str(pred))\n",
        "\n",
        "# making qrel \n",
        "qrel = {}\n",
        "qids, seen, i = [], {}, 0\n",
        "for q in val_queries:\n",
        "  if q in seen:\n",
        "    qids.append(seen[q])\n",
        "  else:\n",
        "    seen[q] = i\n",
        "    qids.append(i)\n",
        "    i+=1\n",
        "qrel={\n",
        "    \"query\": qids,\n",
        "    \"q0\": val_queries,\n",
        "    \"docid\": val_docs,\n",
        "    \"rel\": val_labels\n",
        "}\n",
        "run = {\n",
        "    \"query\": qids,\n",
        "    \"q0\": val_queries,\n",
        "    \"docid\": val_docs,\n",
        "    \"rank\": pred[1].tolist(),\n",
        "    \"score\": [max(l) for l in pred[0].tolist()],\n",
        "    \"system\": [\"test\" for i in qids]\n",
        "}\n",
        "trec_eval = evaluate.load(\"trec_eval\")\n",
        "results = trec_eval.compute(references=[qrel], predictions=[run])\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "6vr2nQYQ3YEV",
        "outputId": "9b70f4dc-1eea-4172-97ae-dd465798c4ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 10000\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'runid': 'test',\n",
              " 'num_ret': 10000,\n",
              " 'num_rel': 2019,\n",
              " 'num_rel_ret': 2027,\n",
              " 'num_q': 9861,\n",
              " 'map': 0.20373187303518914,\n",
              " 'gm_map': nan,\n",
              " 'bpref': 0.0010140959334753068,\n",
              " 'Rprec': 0.2017036811682385,\n",
              " 'recip_rank': 0.20281918669506135,\n",
              " 'P@5': 0.04111144914308894,\n",
              " 'P@10': 0.02055572457154447,\n",
              " 'P@15': 0.013703816381029644,\n",
              " 'P@20': 0.010277862285772234,\n",
              " 'P@30': 0.006851908190514822,\n",
              " 'P@100': 0.002055572457154447,\n",
              " 'P@200': 0.0010277862285772235,\n",
              " 'P@500': 0.0004111144914308894,\n",
              " 'P@1000': 0.0002055572457154447,\n",
              " 'NDCG@5': 0.20403485096013158,\n",
              " 'NDCG@10': 0.20403485096013158,\n",
              " 'NDCG@15': 0.20403485096013158,\n",
              " 'NDCG@20': 0.20403485096013158,\n",
              " 'NDCG@30': 0.20403485096013158,\n",
              " 'NDCG@100': 0.20403485096013158,\n",
              " 'NDCG@200': 0.20403485096013158,\n",
              " 'NDCG@500': 0.20403485096013158,\n",
              " 'NDCG@1000': 0.20403485096013158}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hde1C4J_29Ng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qb6_Gg7RAVUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aTZMbszvAVYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DWET6epyAVbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "911zku9gAVeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bUQj995wAVhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mL69DxRaAVkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GTa0ZQpKAVnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SveYlQCTAVqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0Q8RWeLQAVt2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zaIQNXOjAVwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####Topic based queries"
      ],
      "metadata": {
        "id": "VLirPo2TAVz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "pos_neg_ration = 4\n",
        "\n",
        "# Maximal number of training samples we want to use\n",
        "max_train_samples = 5e4\n",
        "\n",
        "\n",
        "### Now we read the MS Marco dataset\n",
        "data_folder = '/content/drive/MyDrive/collectionandqueries/'\n",
        "os.makedirs(data_folder, exist_ok=True)\n",
        "\n",
        "\n",
        "#### Read the corpus files, that contain all the passages. Store them in the corpus dict\n",
        "corpus = {}\n",
        "collection_filepath = os.path.join(data_folder, 'collection.tsv')\n",
        "if not os.path.exists(collection_filepath):\n",
        "    print('collection.tsv not found')\n",
        "\n",
        "with open(collection_filepath, 'r', encoding='utf8') as fIn:\n",
        "    for line in fIn:\n",
        "        pid, passage = line.strip().split(\"\\t\")\n",
        "        corpus[pid] = passage\n",
        "print('len(corpus.keys() : ' + str(len(corpus.keys())))\n",
        "\n",
        "### Read the train queries, store in queries dict\n",
        "queries = {}\n",
        "queries_filepath = os.path.join(data_folder, 'queries.train.tsv')\n",
        "if not os.path.exists(queries_filepath):\n",
        "    print('queries.train.tsv not found')\n",
        "\n",
        "with open(queries_filepath, 'r', encoding='utf8') as fIn:\n",
        "    for line in fIn:\n",
        "        qid, query = line.strip().split(\"\\t\")\n",
        "        queries[qid] = query\n",
        "\n",
        "print('len(queries.keys() : ' + str(len(queries.keys())))\n",
        "\n",
        "### Now we create our training & dev data\n",
        "original_query_ids = []\n",
        "original_queries = []\n",
        "original_document_ids = [] \n",
        "original_labels = []\n",
        "original_documents = []\n",
        "\n",
        "\"\"\"\n",
        "train_samples = []\n",
        "dev_samples = {}\n",
        "\n",
        "# We use 200 random queries from the train set for evaluation during training\n",
        "# Each query has at least one relevant and up to 200 irrelevant (negative) passages\n",
        "num_dev_queries = 200\n",
        "num_max_dev_negatives = 200\n",
        "\n",
        "# msmarco-qidpidtriples.rnd-shuf.train-eval.tsv.gz and msmarco-qidpidtriples.rnd-shuf.train.tsv.gz is a randomly\n",
        "# shuffled version of qidpidtriples.train.full.2.tsv.gz from the MS Marco website\n",
        "# We extracted in the train-eval split 500 random queries that can be used for evaluation during training\n",
        "train_eval_filepath = os.path.join(data_folder, 'msmarco-qidpidtriples.rnd-shuf.train-eval.tsv')\n",
        "if not os.path.exists(train_eval_filepath):\n",
        "    print('msmarco-qidpidtriples.rnd-shuf.train-eval.tsv not found')\n",
        "\n",
        "with open(train_eval_filepath, 'r', encoding='utf8') as fIn:\n",
        "    for line in fIn:\n",
        "        qid, pos_id, neg_id = line.strip().split()\n",
        "\n",
        "        if qid not in dev_samples and len(dev_samples) < num_dev_queries:\n",
        "            dev_samples[qid] = {'query': queries[qid], 'positive': set(), 'negative': set()}\n",
        "\n",
        "        if qid in dev_samples:\n",
        "            dev_samples[qid]['positive'].add(corpus[pos_id])\n",
        "            all_query_ids.append(qid)\n",
        "            all_queries.append(queries[qid])\n",
        "            all_document_ids.append(pos_id)\n",
        "            all_documents.append(corpus([pos_id]))\n",
        "            all_labels.append(1)\n",
        "            \n",
        "\n",
        "            if len(dev_samples[qid]['negative']) < num_max_dev_negatives:\n",
        "                dev_samples[qid]['negative'].add(corpus[neg_id])\n",
        "                all_query_ids.append(qid)\n",
        "                all_queries.append(queries[qid])\n",
        "                all_document_ids.append(neg_id)\n",
        "                all_documents.append(corpus([neg_id]))\n",
        "                all_labels.append(0)\n",
        "                \n",
        "\n",
        "print('len(dev_samples.keys()) : ' + str(len(dev_samples.keys())))\n",
        "\"\"\"\n",
        "\n",
        "# Read our training file\n",
        "train_filepath = os.path.join(data_folder, 'qidpidtriples-subset.train-200K.tsv')\n",
        "if not os.path.exists(train_filepath):\n",
        "    print('qidpidtriples-subset.train-200K.tsv not found')\n",
        "\n",
        "cnt = 0\n",
        "with open(train_filepath, 'r', encoding='utf8') as fIn:\n",
        "    for line in fIn:\n",
        "        qid, pos_id, neg_id = line.strip().split()\n",
        "\n",
        "        query = queries[qid]\n",
        "        if (cnt % (pos_neg_ration+1)) == 0:\n",
        "            passage = corpus[pos_id]\n",
        "            label = 1\n",
        "            original_query_ids.append(qid)\n",
        "            original_queries.append(query)\n",
        "            original_document_ids.append(pos_id)\n",
        "            original_documents.append(passage)\n",
        "            original_labels.append(label)\n",
        "        else:\n",
        "            passage = corpus[neg_id]\n",
        "            label = 0\n",
        "            original_query_ids.append(qid)\n",
        "            original_queries.append(queries[qid])\n",
        "            original_document_ids.append(neg_id)\n",
        "            original_documents.append(passage)\n",
        "            original_labels.append(label)\n",
        "\n",
        "        #train_samples.append(InputExample(texts=[query, passage], label=label))\n",
        "        cnt += 1\n",
        "\n",
        "        if cnt >= max_train_samples:\n",
        "            break\n",
        "print('len(original_query_ids) : ' + str(len(original_query_ids)))\n",
        "print('len(original_queries) : ' + str(len(original_queries)))\n",
        "print('len(original_document_ids) : ' + str(len(original_document_ids)))\n",
        "print('len(original_documents) : ' + str(len(original_documents)))\n",
        "print('len(original_labels) : ' + str(len(original_labels)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iW7aMZXaAZyg",
        "outputId": "6af9eabc-9ab8-4e87-8d96-9cffff2f151a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(corpus.keys() : 8841823\n",
            "len(queries.keys() : 808731\n",
            "len(original_query_ids) : 50000\n",
            "len(original_queries) : 50000\n",
            "len(original_document_ids) : 50000\n",
            "len(original_documents) : 50000\n",
            "len(original_labels) : 50000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install rank_bm25"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDYpydYrgMqR",
        "outputId": "0dbc730f-9a3d-4372-aac3-df1da57aa523"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: rank_bm25 in /usr/local/lib/python3.8/dist-packages (0.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from rank_bm25) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "from rank_bm25 import BM25Okapi\n",
        "\n",
        "tokenized_corpus = [doc.split(\" \") for doc in original_documents]\n",
        "bm25 = BM25Okapi(tokenized_corpus)\n",
        "with open(\"/content/drive/MyDrive/collectionandqueries/BM25\", 'wb') as bm25File:\n",
        "  pickle.dump(bm25, bm25File)"
      ],
      "metadata": {
        "id": "FTtNRv8zfDtK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E_dMCeFshrPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AAKfK-dHhrSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "deNh2z7OhrVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8_Tyk5XFhrYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qvVkkDjMhrbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QWmQ-pVzhreC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aTHrhAPwhrhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4kEf2Nbuhrjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o8_HIpr3hrnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#bm25 baseline"
      ],
      "metadata": {
        "id": "hMLulZ4whrph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install rank_bm25"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDyMyX1DxWu3",
        "outputId": "afb129dc-b747-4ef6-b806-464a42120f08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: rank_bm25 in /usr/local/lib/python3.8/dist-packages (0.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from rank_bm25) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"/content/drive/MyDrive/collectionandqueries/BM25\", 'rb') as f:\n",
        "    # The protocol version used is detected automatically, so we do not\n",
        "    # have to specify it.\n",
        "    bm25 = pickle.load(f)"
      ],
      "metadata": {
        "id": "z4PRWJhog4KF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "pos_neg_ration = 4\n",
        "\n",
        "# Maximal number of training samples we want to use\n",
        "#max_train_samples = 5e4\n",
        "max_train_samples = 5e3\n",
        "\n",
        "### Now we read the MS Marco dataset\n",
        "data_folder = '/content/drive/MyDrive/collectionandqueries/'\n",
        "os.makedirs(data_folder, exist_ok=True)\n",
        "\n",
        "\n",
        "#### Read the corpus files, that contain all the passages. Store them in the corpus dict\n",
        "corpus = {}\n",
        "collection_filepath = os.path.join(data_folder, 'collection.tsv')\n",
        "if not os.path.exists(collection_filepath):\n",
        "    print('collection.tsv not found')\n",
        "\n",
        "with open(collection_filepath, 'r', encoding='utf8') as fIn:\n",
        "    for line in fIn:\n",
        "        pid, passage = line.strip().split(\"\\t\")\n",
        "        corpus[pid] = passage\n",
        "print('len(corpus.keys() : ' + str(len(corpus.keys())))\n",
        "\n",
        "### Read the train queries, store in queries dict\n",
        "queries = {}\n",
        "queries_filepath = os.path.join(data_folder, 'queries.train.tsv')\n",
        "if not os.path.exists(queries_filepath):\n",
        "    print('queries.train.tsv not found')\n",
        "\n",
        "with open(queries_filepath, 'r', encoding='utf8') as fIn:\n",
        "    for line in fIn:\n",
        "        qid, query = line.strip().split(\"\\t\")\n",
        "        queries[qid] = query\n",
        "\n",
        "print('len(queries.keys() : ' + str(len(queries.keys())))\n",
        "\n",
        "### Now we create our training & dev data\n",
        "all_query_ids = []\n",
        "all_queries = []\n",
        "all_document_ids = [] \n",
        "all_labels = []\n",
        "all_documents = []\n",
        "\n",
        "\"\"\"\n",
        "train_samples = []\n",
        "dev_samples = {}\n",
        "\n",
        "# We use 200 random queries from the train set for evaluation during training\n",
        "# Each query has at least one relevant and up to 200 irrelevant (negative) passages\n",
        "num_dev_queries = 200\n",
        "num_max_dev_negatives = 200\n",
        "\n",
        "# msmarco-qidpidtriples.rnd-shuf.train-eval.tsv.gz and msmarco-qidpidtriples.rnd-shuf.train.tsv.gz is a randomly\n",
        "# shuffled version of qidpidtriples.train.full.2.tsv.gz from the MS Marco website\n",
        "# We extracted in the train-eval split 500 random queries that can be used for evaluation during training\n",
        "train_eval_filepath = os.path.join(data_folder, 'msmarco-qidpidtriples.rnd-shuf.train-eval.tsv')\n",
        "if not os.path.exists(train_eval_filepath):\n",
        "    print('msmarco-qidpidtriples.rnd-shuf.train-eval.tsv not found')\n",
        "\n",
        "with open(train_eval_filepath, 'r', encoding='utf8') as fIn:\n",
        "    for line in fIn:\n",
        "        qid, pos_id, neg_id = line.strip().split()\n",
        "\n",
        "        if qid not in dev_samples and len(dev_samples) < num_dev_queries:\n",
        "            dev_samples[qid] = {'query': queries[qid], 'positive': set(), 'negative': set()}\n",
        "\n",
        "        if qid in dev_samples:\n",
        "            dev_samples[qid]['positive'].add(corpus[pos_id])\n",
        "            all_query_ids.append(qid)\n",
        "            all_queries.append(queries[qid])\n",
        "            all_document_ids.append(pos_id)\n",
        "            all_documents.append(corpus([pos_id]))\n",
        "            all_labels.append(1)\n",
        "            \n",
        "\n",
        "            if len(dev_samples[qid]['negative']) < num_max_dev_negatives:\n",
        "                dev_samples[qid]['negative'].add(corpus[neg_id])\n",
        "                all_query_ids.append(qid)\n",
        "                all_queries.append(queries[qid])\n",
        "                all_document_ids.append(neg_id)\n",
        "                all_documents.append(corpus([neg_id]))\n",
        "                all_labels.append(0)\n",
        "                \n",
        "\n",
        "print('len(dev_samples.keys()) : ' + str(len(dev_samples.keys())))\n",
        "\"\"\"\n",
        "\n",
        "# Read our training file\n",
        "train_filepath = os.path.join(data_folder, 'qidpidtriples-subset.train-200K.tsv')\n",
        "if not os.path.exists(train_filepath):\n",
        "    print('qidpidtriples-subset.train-200K.tsv not found')\n",
        "\n",
        "cnt = 0\n",
        "with open(train_filepath, 'r', encoding='utf8') as fIn:\n",
        "    for line in fIn:\n",
        "        qid, pos_id, neg_id = line.strip().split()\n",
        "        print('cnt : ' + str(cnt))\n",
        "        query = queries[qid]\n",
        "        if (cnt % (pos_neg_ration+1)) == 0:\n",
        "            #print('positive')\n",
        "            passage = corpus[pos_id]\n",
        "            label = 1\n",
        "            all_query_ids.append(qid)\n",
        "            all_queries.append(query)\n",
        "            all_document_ids.append(pos_id)\n",
        "            all_documents.append(passage)\n",
        "            all_labels.append(label)\n",
        "            bm25_passages = bm25.get_top_n(query, original_documents, n=3)\n",
        "            for bm25_passage in bm25_passages:\n",
        "              all_query_ids.append(qid)\n",
        "              all_queries.append(query)\n",
        "              all_document_ids.append(pos_id)\n",
        "              all_documents.append(bm25_passage)\n",
        "              all_labels.append(label)\n",
        "        else:\n",
        "            #print('negative')\n",
        "            passage = corpus[neg_id]\n",
        "            label = 0\n",
        "            all_query_ids.append(qid)\n",
        "            all_queries.append(queries[qid])\n",
        "            all_document_ids.append(neg_id)\n",
        "            all_documents.append(passage)\n",
        "            all_labels.append(label)\n",
        "\n",
        "        #train_samples.append(InputExample(texts=[query, passage], label=label))\n",
        "        cnt += 1\n",
        "\n",
        "        if cnt >= max_train_samples:\n",
        "            break\n",
        "print('len(all_query_ids) : ' + str(len(all_query_ids)))\n",
        "print('len(all_queries) : ' + str(len(all_queries)))\n",
        "print('len(all_document_ids) : ' + str(len(all_document_ids)))\n",
        "print('len(all_documents) : ' + str(len(all_documents)))\n",
        "print('len(all_labels) : ' + str(len(all_labels)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuqywrdphwTs",
        "outputId": "aaa89a2c-e684-44da-bdcb-6422174f66f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "cnt : 5\n",
            "cnt : 6\n",
            "cnt : 7\n",
            "cnt : 8\n",
            "cnt : 9\n",
            "cnt : 10\n",
            "cnt : 11\n",
            "cnt : 12\n",
            "cnt : 13\n",
            "cnt : 14\n",
            "cnt : 15\n",
            "cnt : 16\n",
            "cnt : 17\n",
            "cnt : 18\n",
            "cnt : 19\n",
            "cnt : 20\n",
            "cnt : 21\n",
            "cnt : 22\n",
            "cnt : 23\n",
            "cnt : 24\n",
            "cnt : 25\n",
            "cnt : 26\n",
            "cnt : 27\n",
            "cnt : 28\n",
            "cnt : 29\n",
            "cnt : 30\n",
            "cnt : 31\n",
            "cnt : 32\n",
            "cnt : 33\n",
            "cnt : 34\n",
            "cnt : 35\n",
            "cnt : 36\n",
            "cnt : 37\n",
            "cnt : 38\n",
            "cnt : 39\n",
            "cnt : 40\n",
            "cnt : 41\n",
            "cnt : 42\n",
            "cnt : 43\n",
            "cnt : 44\n",
            "cnt : 45\n",
            "cnt : 46\n",
            "cnt : 47\n",
            "cnt : 48\n",
            "cnt : 49\n",
            "cnt : 50\n",
            "cnt : 51\n",
            "cnt : 52\n",
            "cnt : 53\n",
            "cnt : 54\n",
            "cnt : 55\n",
            "cnt : 56\n",
            "cnt : 57\n",
            "cnt : 58\n",
            "cnt : 59\n",
            "cnt : 60\n",
            "cnt : 61\n",
            "cnt : 62\n",
            "cnt : 63\n",
            "cnt : 64\n",
            "cnt : 65\n",
            "cnt : 66\n",
            "cnt : 67\n",
            "cnt : 68\n",
            "cnt : 69\n",
            "cnt : 70\n",
            "cnt : 71\n",
            "cnt : 72\n",
            "cnt : 73\n",
            "cnt : 74\n",
            "cnt : 75\n",
            "cnt : 76\n",
            "cnt : 77\n",
            "cnt : 78\n",
            "cnt : 79\n",
            "cnt : 80\n",
            "cnt : 81\n",
            "cnt : 82\n",
            "cnt : 83\n",
            "cnt : 84\n",
            "cnt : 85\n",
            "cnt : 86\n",
            "cnt : 87\n",
            "cnt : 88\n",
            "cnt : 89\n",
            "cnt : 90\n",
            "cnt : 91\n",
            "cnt : 92\n",
            "cnt : 93\n",
            "cnt : 94\n",
            "cnt : 95\n",
            "cnt : 96\n",
            "cnt : 97\n",
            "cnt : 98\n",
            "cnt : 99\n",
            "cnt : 100\n",
            "cnt : 101\n",
            "cnt : 102\n",
            "cnt : 103\n",
            "cnt : 104\n",
            "cnt : 105\n",
            "cnt : 106\n",
            "cnt : 107\n",
            "cnt : 108\n",
            "cnt : 109\n",
            "cnt : 110\n",
            "cnt : 111\n",
            "cnt : 112\n",
            "cnt : 113\n",
            "cnt : 114\n",
            "cnt : 115\n",
            "cnt : 116\n",
            "cnt : 117\n",
            "cnt : 118\n",
            "cnt : 119\n",
            "cnt : 120\n",
            "cnt : 121\n",
            "cnt : 122\n",
            "cnt : 123\n",
            "cnt : 124\n",
            "cnt : 125\n",
            "cnt : 126\n",
            "cnt : 127\n",
            "cnt : 128\n",
            "cnt : 129\n",
            "cnt : 130\n",
            "cnt : 131\n",
            "cnt : 132\n",
            "cnt : 133\n",
            "cnt : 134\n",
            "cnt : 135\n",
            "cnt : 136\n",
            "cnt : 137\n",
            "cnt : 138\n",
            "cnt : 139\n",
            "cnt : 140\n",
            "cnt : 141\n",
            "cnt : 142\n",
            "cnt : 143\n",
            "cnt : 144\n",
            "cnt : 145\n",
            "cnt : 146\n",
            "cnt : 147\n",
            "cnt : 148\n",
            "cnt : 149\n",
            "cnt : 150\n",
            "cnt : 151\n",
            "cnt : 152\n",
            "cnt : 153\n",
            "cnt : 154\n",
            "cnt : 155\n",
            "cnt : 156\n",
            "cnt : 157\n",
            "cnt : 158\n",
            "cnt : 159\n",
            "cnt : 160\n",
            "cnt : 161\n",
            "cnt : 162\n",
            "cnt : 163\n",
            "cnt : 164\n",
            "cnt : 165\n",
            "cnt : 166\n",
            "cnt : 167\n",
            "cnt : 168\n",
            "cnt : 169\n",
            "cnt : 170\n",
            "cnt : 171\n",
            "cnt : 172\n",
            "cnt : 173\n",
            "cnt : 174\n",
            "cnt : 175\n",
            "cnt : 176\n",
            "cnt : 177\n",
            "cnt : 178\n",
            "cnt : 179\n",
            "cnt : 180\n",
            "cnt : 181\n",
            "cnt : 182\n",
            "cnt : 183\n",
            "cnt : 184\n",
            "cnt : 185\n",
            "cnt : 186\n",
            "cnt : 187\n",
            "cnt : 188\n",
            "cnt : 189\n",
            "cnt : 190\n",
            "cnt : 191\n",
            "cnt : 192\n",
            "cnt : 193\n",
            "cnt : 194\n",
            "cnt : 195\n",
            "cnt : 196\n",
            "cnt : 197\n",
            "cnt : 198\n",
            "cnt : 199\n",
            "cnt : 200\n",
            "cnt : 201\n",
            "cnt : 202\n",
            "cnt : 203\n",
            "cnt : 204\n",
            "cnt : 205\n",
            "cnt : 206\n",
            "cnt : 207\n",
            "cnt : 208\n",
            "cnt : 209\n",
            "cnt : 210\n",
            "cnt : 211\n",
            "cnt : 212\n",
            "cnt : 213\n",
            "cnt : 214\n",
            "cnt : 215\n",
            "cnt : 216\n",
            "cnt : 217\n",
            "cnt : 218\n",
            "cnt : 219\n",
            "cnt : 220\n",
            "cnt : 221\n",
            "cnt : 222\n",
            "cnt : 223\n",
            "cnt : 224\n",
            "cnt : 225\n",
            "cnt : 226\n",
            "cnt : 227\n",
            "cnt : 228\n",
            "cnt : 229\n",
            "cnt : 230\n",
            "cnt : 231\n",
            "cnt : 232\n",
            "cnt : 233\n",
            "cnt : 234\n",
            "cnt : 235\n",
            "cnt : 236\n",
            "cnt : 237\n",
            "cnt : 238\n",
            "cnt : 239\n",
            "cnt : 240\n",
            "cnt : 241\n",
            "cnt : 242\n",
            "cnt : 243\n",
            "cnt : 244\n",
            "cnt : 245\n",
            "cnt : 246\n",
            "cnt : 247\n",
            "cnt : 248\n",
            "cnt : 249\n",
            "cnt : 250\n",
            "cnt : 251\n",
            "cnt : 252\n",
            "cnt : 253\n",
            "cnt : 254\n",
            "cnt : 255\n",
            "cnt : 256\n",
            "cnt : 257\n",
            "cnt : 258\n",
            "cnt : 259\n",
            "cnt : 260\n",
            "cnt : 261\n",
            "cnt : 262\n",
            "cnt : 263\n",
            "cnt : 264\n",
            "cnt : 265\n",
            "cnt : 266\n",
            "cnt : 267\n",
            "cnt : 268\n",
            "cnt : 269\n",
            "cnt : 270\n",
            "cnt : 271\n",
            "cnt : 272\n",
            "cnt : 273\n",
            "cnt : 274\n",
            "cnt : 275\n",
            "cnt : 276\n",
            "cnt : 277\n",
            "cnt : 278\n",
            "cnt : 279\n",
            "cnt : 280\n",
            "cnt : 281\n",
            "cnt : 282\n",
            "cnt : 283\n",
            "cnt : 284\n",
            "cnt : 285\n",
            "cnt : 286\n",
            "cnt : 287\n",
            "cnt : 288\n",
            "cnt : 289\n",
            "cnt : 290\n",
            "cnt : 291\n",
            "cnt : 292\n",
            "cnt : 293\n",
            "cnt : 294\n",
            "cnt : 295\n",
            "cnt : 296\n",
            "cnt : 297\n",
            "cnt : 298\n",
            "cnt : 299\n",
            "cnt : 300\n",
            "cnt : 301\n",
            "cnt : 302\n",
            "cnt : 303\n",
            "cnt : 304\n",
            "cnt : 305\n",
            "cnt : 306\n",
            "cnt : 307\n",
            "cnt : 308\n",
            "cnt : 309\n",
            "cnt : 310\n",
            "cnt : 311\n",
            "cnt : 312\n",
            "cnt : 313\n",
            "cnt : 314\n",
            "cnt : 315\n",
            "cnt : 316\n",
            "cnt : 317\n",
            "cnt : 318\n",
            "cnt : 319\n",
            "cnt : 320\n",
            "cnt : 321\n",
            "cnt : 322\n",
            "cnt : 323\n",
            "cnt : 324\n",
            "cnt : 325\n",
            "cnt : 326\n",
            "cnt : 327\n",
            "cnt : 328\n",
            "cnt : 329\n",
            "cnt : 330\n",
            "cnt : 331\n",
            "cnt : 332\n",
            "cnt : 333\n",
            "cnt : 334\n",
            "cnt : 335\n",
            "cnt : 336\n",
            "cnt : 337\n",
            "cnt : 338\n",
            "cnt : 339\n",
            "cnt : 340\n",
            "cnt : 341\n",
            "cnt : 342\n",
            "cnt : 343\n",
            "cnt : 344\n",
            "cnt : 345\n",
            "cnt : 346\n",
            "cnt : 347\n",
            "cnt : 348\n",
            "cnt : 349\n",
            "cnt : 350\n",
            "cnt : 351\n",
            "cnt : 352\n",
            "cnt : 353\n",
            "cnt : 354\n",
            "cnt : 355\n",
            "cnt : 356\n",
            "cnt : 357\n",
            "cnt : 358\n",
            "cnt : 359\n",
            "cnt : 360\n",
            "cnt : 361\n",
            "cnt : 362\n",
            "cnt : 363\n",
            "cnt : 364\n",
            "cnt : 365\n",
            "cnt : 366\n",
            "cnt : 367\n",
            "cnt : 368\n",
            "cnt : 369\n",
            "cnt : 370\n",
            "cnt : 371\n",
            "cnt : 372\n",
            "cnt : 373\n",
            "cnt : 374\n",
            "cnt : 375\n",
            "cnt : 376\n",
            "cnt : 377\n",
            "cnt : 378\n",
            "cnt : 379\n",
            "cnt : 380\n",
            "cnt : 381\n",
            "cnt : 382\n",
            "cnt : 383\n",
            "cnt : 384\n",
            "cnt : 385\n",
            "cnt : 386\n",
            "cnt : 387\n",
            "cnt : 388\n",
            "cnt : 389\n",
            "cnt : 390\n",
            "cnt : 391\n",
            "cnt : 392\n",
            "cnt : 393\n",
            "cnt : 394\n",
            "cnt : 395\n",
            "cnt : 396\n",
            "cnt : 397\n",
            "cnt : 398\n",
            "cnt : 399\n",
            "cnt : 400\n",
            "cnt : 401\n",
            "cnt : 402\n",
            "cnt : 403\n",
            "cnt : 404\n",
            "cnt : 405\n",
            "cnt : 406\n",
            "cnt : 407\n",
            "cnt : 408\n",
            "cnt : 409\n",
            "cnt : 410\n",
            "cnt : 411\n",
            "cnt : 412\n",
            "cnt : 413\n",
            "cnt : 414\n",
            "cnt : 415\n",
            "cnt : 416\n",
            "cnt : 417\n",
            "cnt : 418\n",
            "cnt : 419\n",
            "cnt : 420\n",
            "cnt : 421\n",
            "cnt : 422\n",
            "cnt : 423\n",
            "cnt : 424\n",
            "cnt : 425\n",
            "cnt : 426\n",
            "cnt : 427\n",
            "cnt : 428\n",
            "cnt : 429\n",
            "cnt : 430\n",
            "cnt : 431\n",
            "cnt : 432\n",
            "cnt : 433\n",
            "cnt : 434\n",
            "cnt : 435\n",
            "cnt : 436\n",
            "cnt : 437\n",
            "cnt : 438\n",
            "cnt : 439\n",
            "cnt : 440\n",
            "cnt : 441\n",
            "cnt : 442\n",
            "cnt : 443\n",
            "cnt : 444\n",
            "cnt : 445\n",
            "cnt : 446\n",
            "cnt : 447\n",
            "cnt : 448\n",
            "cnt : 449\n",
            "cnt : 450\n",
            "cnt : 451\n",
            "cnt : 452\n",
            "cnt : 453\n",
            "cnt : 454\n",
            "cnt : 455\n",
            "cnt : 456\n",
            "cnt : 457\n",
            "cnt : 458\n",
            "cnt : 459\n",
            "cnt : 460\n",
            "cnt : 461\n",
            "cnt : 462\n",
            "cnt : 463\n",
            "cnt : 464\n",
            "cnt : 465\n",
            "cnt : 466\n",
            "cnt : 467\n",
            "cnt : 468\n",
            "cnt : 469\n",
            "cnt : 470\n",
            "cnt : 471\n",
            "cnt : 472\n",
            "cnt : 473\n",
            "cnt : 474\n",
            "cnt : 475\n",
            "cnt : 476\n",
            "cnt : 477\n",
            "cnt : 478\n",
            "cnt : 479\n",
            "cnt : 480\n",
            "cnt : 481\n",
            "cnt : 482\n",
            "cnt : 483\n",
            "cnt : 484\n",
            "cnt : 485\n",
            "cnt : 486\n",
            "cnt : 487\n",
            "cnt : 488\n",
            "cnt : 489\n",
            "cnt : 490\n",
            "cnt : 491\n",
            "cnt : 492\n",
            "cnt : 493\n",
            "cnt : 494\n",
            "cnt : 495\n",
            "cnt : 496\n",
            "cnt : 497\n",
            "cnt : 498\n",
            "cnt : 499\n",
            "cnt : 500\n",
            "cnt : 501\n",
            "cnt : 502\n",
            "cnt : 503\n",
            "cnt : 504\n",
            "cnt : 505\n",
            "cnt : 506\n",
            "cnt : 507\n",
            "cnt : 508\n",
            "cnt : 509\n",
            "cnt : 510\n",
            "cnt : 511\n",
            "cnt : 512\n",
            "cnt : 513\n",
            "cnt : 514\n",
            "cnt : 515\n",
            "cnt : 516\n",
            "cnt : 517\n",
            "cnt : 518\n",
            "cnt : 519\n",
            "cnt : 520\n",
            "cnt : 521\n",
            "cnt : 522\n",
            "cnt : 523\n",
            "cnt : 524\n",
            "cnt : 525\n",
            "cnt : 526\n",
            "cnt : 527\n",
            "cnt : 528\n",
            "cnt : 529\n",
            "cnt : 530\n",
            "cnt : 531\n",
            "cnt : 532\n",
            "cnt : 533\n",
            "cnt : 534\n",
            "cnt : 535\n",
            "cnt : 536\n",
            "cnt : 537\n",
            "cnt : 538\n",
            "cnt : 539\n",
            "cnt : 540\n",
            "cnt : 541\n",
            "cnt : 542\n",
            "cnt : 543\n",
            "cnt : 544\n",
            "cnt : 545\n",
            "cnt : 546\n",
            "cnt : 547\n",
            "cnt : 548\n",
            "cnt : 549\n",
            "cnt : 550\n",
            "cnt : 551\n",
            "cnt : 552\n",
            "cnt : 553\n",
            "cnt : 554\n",
            "cnt : 555\n",
            "cnt : 556\n",
            "cnt : 557\n",
            "cnt : 558\n",
            "cnt : 559\n",
            "cnt : 560\n",
            "cnt : 561\n",
            "cnt : 562\n",
            "cnt : 563\n",
            "cnt : 564\n",
            "cnt : 565\n",
            "cnt : 566\n",
            "cnt : 567\n",
            "cnt : 568\n",
            "cnt : 569\n",
            "cnt : 570\n",
            "cnt : 571\n",
            "cnt : 572\n",
            "cnt : 573\n",
            "cnt : 574\n",
            "cnt : 575\n",
            "cnt : 576\n",
            "cnt : 577\n",
            "cnt : 578\n",
            "cnt : 579\n",
            "cnt : 580\n",
            "cnt : 581\n",
            "cnt : 582\n",
            "cnt : 583\n",
            "cnt : 584\n",
            "cnt : 585\n",
            "cnt : 586\n",
            "cnt : 587\n",
            "cnt : 588\n",
            "cnt : 589\n",
            "cnt : 590\n",
            "cnt : 591\n",
            "cnt : 592\n",
            "cnt : 593\n",
            "cnt : 594\n",
            "cnt : 595\n",
            "cnt : 596\n",
            "cnt : 597\n",
            "cnt : 598\n",
            "cnt : 599\n",
            "cnt : 600\n",
            "cnt : 601\n",
            "cnt : 602\n",
            "cnt : 603\n",
            "cnt : 604\n",
            "cnt : 605\n",
            "cnt : 606\n",
            "cnt : 607\n",
            "cnt : 608\n",
            "cnt : 609\n",
            "cnt : 610\n",
            "cnt : 611\n",
            "cnt : 612\n",
            "cnt : 613\n",
            "cnt : 614\n",
            "cnt : 615\n",
            "cnt : 616\n",
            "cnt : 617\n",
            "cnt : 618\n",
            "cnt : 619\n",
            "cnt : 620\n",
            "cnt : 621\n",
            "cnt : 622\n",
            "cnt : 623\n",
            "cnt : 624\n",
            "cnt : 625\n",
            "cnt : 626\n",
            "cnt : 627\n",
            "cnt : 628\n",
            "cnt : 629\n",
            "cnt : 630\n",
            "cnt : 631\n",
            "cnt : 632\n",
            "cnt : 633\n",
            "cnt : 634\n",
            "cnt : 635\n",
            "cnt : 636\n",
            "cnt : 637\n",
            "cnt : 638\n",
            "cnt : 639\n",
            "cnt : 640\n",
            "cnt : 641\n",
            "cnt : 642\n",
            "cnt : 643\n",
            "cnt : 644\n",
            "cnt : 645\n",
            "cnt : 646\n",
            "cnt : 647\n",
            "cnt : 648\n",
            "cnt : 649\n",
            "cnt : 650\n",
            "cnt : 651\n",
            "cnt : 652\n",
            "cnt : 653\n",
            "cnt : 654\n",
            "cnt : 655\n",
            "cnt : 656\n",
            "cnt : 657\n",
            "cnt : 658\n",
            "cnt : 659\n",
            "cnt : 660\n",
            "cnt : 661\n",
            "cnt : 662\n",
            "cnt : 663\n",
            "cnt : 664\n",
            "cnt : 665\n",
            "cnt : 666\n",
            "cnt : 667\n",
            "cnt : 668\n",
            "cnt : 669\n",
            "cnt : 670\n",
            "cnt : 671\n",
            "cnt : 672\n",
            "cnt : 673\n",
            "cnt : 674\n",
            "cnt : 675\n",
            "cnt : 676\n",
            "cnt : 677\n",
            "cnt : 678\n",
            "cnt : 679\n",
            "cnt : 680\n",
            "cnt : 681\n",
            "cnt : 682\n",
            "cnt : 683\n",
            "cnt : 684\n",
            "cnt : 685\n",
            "cnt : 686\n",
            "cnt : 687\n",
            "cnt : 688\n",
            "cnt : 689\n",
            "cnt : 690\n",
            "cnt : 691\n",
            "cnt : 692\n",
            "cnt : 693\n",
            "cnt : 694\n",
            "cnt : 695\n",
            "cnt : 696\n",
            "cnt : 697\n",
            "cnt : 698\n",
            "cnt : 699\n",
            "cnt : 700\n",
            "cnt : 701\n",
            "cnt : 702\n",
            "cnt : 703\n",
            "cnt : 704\n",
            "cnt : 705\n",
            "cnt : 706\n",
            "cnt : 707\n",
            "cnt : 708\n",
            "cnt : 709\n",
            "cnt : 710\n",
            "cnt : 711\n",
            "cnt : 712\n",
            "cnt : 713\n",
            "cnt : 714\n",
            "cnt : 715\n",
            "cnt : 716\n",
            "cnt : 717\n",
            "cnt : 718\n",
            "cnt : 719\n",
            "cnt : 720\n",
            "cnt : 721\n",
            "cnt : 722\n",
            "cnt : 723\n",
            "cnt : 724\n",
            "cnt : 725\n",
            "cnt : 726\n",
            "cnt : 727\n",
            "cnt : 728\n",
            "cnt : 729\n",
            "cnt : 730\n",
            "cnt : 731\n",
            "cnt : 732\n",
            "cnt : 733\n",
            "cnt : 734\n",
            "cnt : 735\n",
            "cnt : 736\n",
            "cnt : 737\n",
            "cnt : 738\n",
            "cnt : 739\n",
            "cnt : 740\n",
            "cnt : 741\n",
            "cnt : 742\n",
            "cnt : 743\n",
            "cnt : 744\n",
            "cnt : 745\n",
            "cnt : 746\n",
            "cnt : 747\n",
            "cnt : 748\n",
            "cnt : 749\n",
            "cnt : 750\n",
            "cnt : 751\n",
            "cnt : 752\n",
            "cnt : 753\n",
            "cnt : 754\n",
            "cnt : 755\n",
            "cnt : 756\n",
            "cnt : 757\n",
            "cnt : 758\n",
            "cnt : 759\n",
            "cnt : 760\n",
            "cnt : 761\n",
            "cnt : 762\n",
            "cnt : 763\n",
            "cnt : 764\n",
            "cnt : 765\n",
            "cnt : 766\n",
            "cnt : 767\n",
            "cnt : 768\n",
            "cnt : 769\n",
            "cnt : 770\n",
            "cnt : 771\n",
            "cnt : 772\n",
            "cnt : 773\n",
            "cnt : 774\n",
            "cnt : 775\n",
            "cnt : 776\n",
            "cnt : 777\n",
            "cnt : 778\n",
            "cnt : 779\n",
            "cnt : 780\n",
            "cnt : 781\n",
            "cnt : 782\n",
            "cnt : 783\n",
            "cnt : 784\n",
            "cnt : 785\n",
            "cnt : 786\n",
            "cnt : 787\n",
            "cnt : 788\n",
            "cnt : 789\n",
            "cnt : 790\n",
            "cnt : 791\n",
            "cnt : 792\n",
            "cnt : 793\n",
            "cnt : 794\n",
            "cnt : 795\n",
            "cnt : 796\n",
            "cnt : 797\n",
            "cnt : 798\n",
            "cnt : 799\n",
            "cnt : 800\n",
            "cnt : 801\n",
            "cnt : 802\n",
            "cnt : 803\n",
            "cnt : 804\n",
            "cnt : 805\n",
            "cnt : 806\n",
            "cnt : 807\n",
            "cnt : 808\n",
            "cnt : 809\n",
            "cnt : 810\n",
            "cnt : 811\n",
            "cnt : 812\n",
            "cnt : 813\n",
            "cnt : 814\n",
            "cnt : 815\n",
            "cnt : 816\n",
            "cnt : 817\n",
            "cnt : 818\n",
            "cnt : 819\n",
            "cnt : 820\n",
            "cnt : 821\n",
            "cnt : 822\n",
            "cnt : 823\n",
            "cnt : 824\n",
            "cnt : 825\n",
            "cnt : 826\n",
            "cnt : 827\n",
            "cnt : 828\n",
            "cnt : 829\n",
            "cnt : 830\n",
            "cnt : 831\n",
            "cnt : 832\n",
            "cnt : 833\n",
            "cnt : 834\n",
            "cnt : 835\n",
            "cnt : 836\n",
            "cnt : 837\n",
            "cnt : 838\n",
            "cnt : 839\n",
            "cnt : 840\n",
            "cnt : 841\n",
            "cnt : 842\n",
            "cnt : 843\n",
            "cnt : 844\n",
            "cnt : 845\n",
            "cnt : 846\n",
            "cnt : 847\n",
            "cnt : 848\n",
            "cnt : 849\n",
            "cnt : 850\n",
            "cnt : 851\n",
            "cnt : 852\n",
            "cnt : 853\n",
            "cnt : 854\n",
            "cnt : 855\n",
            "cnt : 856\n",
            "cnt : 857\n",
            "cnt : 858\n",
            "cnt : 859\n",
            "cnt : 860\n",
            "cnt : 861\n",
            "cnt : 862\n",
            "cnt : 863\n",
            "cnt : 864\n",
            "cnt : 865\n",
            "cnt : 866\n",
            "cnt : 867\n",
            "cnt : 868\n",
            "cnt : 869\n",
            "cnt : 870\n",
            "cnt : 871\n",
            "cnt : 872\n",
            "cnt : 873\n",
            "cnt : 874\n",
            "cnt : 875\n",
            "cnt : 876\n",
            "cnt : 877\n",
            "cnt : 878\n",
            "cnt : 879\n",
            "cnt : 880\n",
            "cnt : 881\n",
            "cnt : 882\n",
            "cnt : 883\n",
            "cnt : 884\n",
            "cnt : 885\n",
            "cnt : 886\n",
            "cnt : 887\n",
            "cnt : 888\n",
            "cnt : 889\n",
            "cnt : 890\n",
            "cnt : 891\n",
            "cnt : 892\n",
            "cnt : 893\n",
            "cnt : 894\n",
            "cnt : 895\n",
            "cnt : 896\n",
            "cnt : 897\n",
            "cnt : 898\n",
            "cnt : 899\n",
            "cnt : 900\n",
            "cnt : 901\n",
            "cnt : 902\n",
            "cnt : 903\n",
            "cnt : 904\n",
            "cnt : 905\n",
            "cnt : 906\n",
            "cnt : 907\n",
            "cnt : 908\n",
            "cnt : 909\n",
            "cnt : 910\n",
            "cnt : 911\n",
            "cnt : 912\n",
            "cnt : 913\n",
            "cnt : 914\n",
            "cnt : 915\n",
            "cnt : 916\n",
            "cnt : 917\n",
            "cnt : 918\n",
            "cnt : 919\n",
            "cnt : 920\n",
            "cnt : 921\n",
            "cnt : 922\n",
            "cnt : 923\n",
            "cnt : 924\n",
            "cnt : 925\n",
            "cnt : 926\n",
            "cnt : 927\n",
            "cnt : 928\n",
            "cnt : 929\n",
            "cnt : 930\n",
            "cnt : 931\n",
            "cnt : 932\n",
            "cnt : 933\n",
            "cnt : 934\n",
            "cnt : 935\n",
            "cnt : 936\n",
            "cnt : 937\n",
            "cnt : 938\n",
            "cnt : 939\n",
            "cnt : 940\n",
            "cnt : 941\n",
            "cnt : 942\n",
            "cnt : 943\n",
            "cnt : 944\n",
            "cnt : 945\n",
            "cnt : 946\n",
            "cnt : 947\n",
            "cnt : 948\n",
            "cnt : 949\n",
            "cnt : 950\n",
            "cnt : 951\n",
            "cnt : 952\n",
            "cnt : 953\n",
            "cnt : 954\n",
            "cnt : 955\n",
            "cnt : 956\n",
            "cnt : 957\n",
            "cnt : 958\n",
            "cnt : 959\n",
            "cnt : 960\n",
            "cnt : 961\n",
            "cnt : 962\n",
            "cnt : 963\n",
            "cnt : 964\n",
            "cnt : 965\n",
            "cnt : 966\n",
            "cnt : 967\n",
            "cnt : 968\n",
            "cnt : 969\n",
            "cnt : 970\n",
            "cnt : 971\n",
            "cnt : 972\n",
            "cnt : 973\n",
            "cnt : 974\n",
            "cnt : 975\n",
            "cnt : 976\n",
            "cnt : 977\n",
            "cnt : 978\n",
            "cnt : 979\n",
            "cnt : 980\n",
            "cnt : 981\n",
            "cnt : 982\n",
            "cnt : 983\n",
            "cnt : 984\n",
            "cnt : 985\n",
            "cnt : 986\n",
            "cnt : 987\n",
            "cnt : 988\n",
            "cnt : 989\n",
            "cnt : 990\n",
            "cnt : 991\n",
            "cnt : 992\n",
            "cnt : 993\n",
            "cnt : 994\n",
            "cnt : 995\n",
            "cnt : 996\n",
            "cnt : 997\n",
            "cnt : 998\n",
            "cnt : 999\n",
            "cnt : 1000\n",
            "cnt : 1001\n",
            "cnt : 1002\n",
            "cnt : 1003\n",
            "cnt : 1004\n",
            "cnt : 1005\n",
            "cnt : 1006\n",
            "cnt : 1007\n",
            "cnt : 1008\n",
            "cnt : 1009\n",
            "cnt : 1010\n",
            "cnt : 1011\n",
            "cnt : 1012\n",
            "cnt : 1013\n",
            "cnt : 1014\n",
            "cnt : 1015\n",
            "cnt : 1016\n",
            "cnt : 1017\n",
            "cnt : 1018\n",
            "cnt : 1019\n",
            "cnt : 1020\n",
            "cnt : 1021\n",
            "cnt : 1022\n",
            "cnt : 1023\n",
            "cnt : 1024\n",
            "cnt : 1025\n",
            "cnt : 1026\n",
            "cnt : 1027\n",
            "cnt : 1028\n",
            "cnt : 1029\n",
            "cnt : 1030\n",
            "cnt : 1031\n",
            "cnt : 1032\n",
            "cnt : 1033\n",
            "cnt : 1034\n",
            "cnt : 1035\n",
            "cnt : 1036\n",
            "cnt : 1037\n",
            "cnt : 1038\n",
            "cnt : 1039\n",
            "cnt : 1040\n",
            "cnt : 1041\n",
            "cnt : 1042\n",
            "cnt : 1043\n",
            "cnt : 1044\n",
            "cnt : 1045\n",
            "cnt : 1046\n",
            "cnt : 1047\n",
            "cnt : 1048\n",
            "cnt : 1049\n",
            "cnt : 1050\n",
            "cnt : 1051\n",
            "cnt : 1052\n",
            "cnt : 1053\n",
            "cnt : 1054\n",
            "cnt : 1055\n",
            "cnt : 1056\n",
            "cnt : 1057\n",
            "cnt : 1058\n",
            "cnt : 1059\n",
            "cnt : 1060\n",
            "cnt : 1061\n",
            "cnt : 1062\n",
            "cnt : 1063\n",
            "cnt : 1064\n",
            "cnt : 1065\n",
            "cnt : 1066\n",
            "cnt : 1067\n",
            "cnt : 1068\n",
            "cnt : 1069\n",
            "cnt : 1070\n",
            "cnt : 1071\n",
            "cnt : 1072\n",
            "cnt : 1073\n",
            "cnt : 1074\n",
            "cnt : 1075\n",
            "cnt : 1076\n",
            "cnt : 1077\n",
            "cnt : 1078\n",
            "cnt : 1079\n",
            "cnt : 1080\n",
            "cnt : 1081\n",
            "cnt : 1082\n",
            "cnt : 1083\n",
            "cnt : 1084\n",
            "cnt : 1085\n",
            "cnt : 1086\n",
            "cnt : 1087\n",
            "cnt : 1088\n",
            "cnt : 1089\n",
            "cnt : 1090\n",
            "cnt : 1091\n",
            "cnt : 1092\n",
            "cnt : 1093\n",
            "cnt : 1094\n",
            "cnt : 1095\n",
            "cnt : 1096\n",
            "cnt : 1097\n",
            "cnt : 1098\n",
            "cnt : 1099\n",
            "cnt : 1100\n",
            "cnt : 1101\n",
            "cnt : 1102\n",
            "cnt : 1103\n",
            "cnt : 1104\n",
            "cnt : 1105\n",
            "cnt : 1106\n",
            "cnt : 1107\n",
            "cnt : 1108\n",
            "cnt : 1109\n",
            "cnt : 1110\n",
            "cnt : 1111\n",
            "cnt : 1112\n",
            "cnt : 1113\n",
            "cnt : 1114\n",
            "cnt : 1115\n",
            "cnt : 1116\n",
            "cnt : 1117\n",
            "cnt : 1118\n",
            "cnt : 1119\n",
            "cnt : 1120\n",
            "cnt : 1121\n",
            "cnt : 1122\n",
            "cnt : 1123\n",
            "cnt : 1124\n",
            "cnt : 1125\n",
            "cnt : 1126\n",
            "cnt : 1127\n",
            "cnt : 1128\n",
            "cnt : 1129\n",
            "cnt : 1130\n",
            "cnt : 1131\n",
            "cnt : 1132\n",
            "cnt : 1133\n",
            "cnt : 1134\n",
            "cnt : 1135\n",
            "cnt : 1136\n",
            "cnt : 1137\n",
            "cnt : 1138\n",
            "cnt : 1139\n",
            "cnt : 1140\n",
            "cnt : 1141\n",
            "cnt : 1142\n",
            "cnt : 1143\n",
            "cnt : 1144\n",
            "cnt : 1145\n",
            "cnt : 1146\n",
            "cnt : 1147\n",
            "cnt : 1148\n",
            "cnt : 1149\n",
            "cnt : 1150\n",
            "cnt : 1151\n",
            "cnt : 1152\n",
            "cnt : 1153\n",
            "cnt : 1154\n",
            "cnt : 1155\n",
            "cnt : 1156\n",
            "cnt : 1157\n",
            "cnt : 1158\n",
            "cnt : 1159\n",
            "cnt : 1160\n",
            "cnt : 1161\n",
            "cnt : 1162\n",
            "cnt : 1163\n",
            "cnt : 1164\n",
            "cnt : 1165\n",
            "cnt : 1166\n",
            "cnt : 1167\n",
            "cnt : 1168\n",
            "cnt : 1169\n",
            "cnt : 1170\n",
            "cnt : 1171\n",
            "cnt : 1172\n",
            "cnt : 1173\n",
            "cnt : 1174\n",
            "cnt : 1175\n",
            "cnt : 1176\n",
            "cnt : 1177\n",
            "cnt : 1178\n",
            "cnt : 1179\n",
            "cnt : 1180\n",
            "cnt : 1181\n",
            "cnt : 1182\n",
            "cnt : 1183\n",
            "cnt : 1184\n",
            "cnt : 1185\n",
            "cnt : 1186\n",
            "cnt : 1187\n",
            "cnt : 1188\n",
            "cnt : 1189\n",
            "cnt : 1190\n",
            "cnt : 1191\n",
            "cnt : 1192\n",
            "cnt : 1193\n",
            "cnt : 1194\n",
            "cnt : 1195\n",
            "cnt : 1196\n",
            "cnt : 1197\n",
            "cnt : 1198\n",
            "cnt : 1199\n",
            "cnt : 1200\n",
            "cnt : 1201\n",
            "cnt : 1202\n",
            "cnt : 1203\n",
            "cnt : 1204\n",
            "cnt : 1205\n",
            "cnt : 1206\n",
            "cnt : 1207\n",
            "cnt : 1208\n",
            "cnt : 1209\n",
            "cnt : 1210\n",
            "cnt : 1211\n",
            "cnt : 1212\n",
            "cnt : 1213\n",
            "cnt : 1214\n",
            "cnt : 1215\n",
            "cnt : 1216\n",
            "cnt : 1217\n",
            "cnt : 1218\n",
            "cnt : 1219\n",
            "cnt : 1220\n",
            "cnt : 1221\n",
            "cnt : 1222\n",
            "cnt : 1223\n",
            "cnt : 1224\n",
            "cnt : 1225\n",
            "cnt : 1226\n",
            "cnt : 1227\n",
            "cnt : 1228\n",
            "cnt : 1229\n",
            "cnt : 1230\n",
            "cnt : 1231\n",
            "cnt : 1232\n",
            "cnt : 1233\n",
            "cnt : 1234\n",
            "cnt : 1235\n",
            "cnt : 1236\n",
            "cnt : 1237\n",
            "cnt : 1238\n",
            "cnt : 1239\n",
            "cnt : 1240\n",
            "cnt : 1241\n",
            "cnt : 1242\n",
            "cnt : 1243\n",
            "cnt : 1244\n",
            "cnt : 1245\n",
            "cnt : 1246\n",
            "cnt : 1247\n",
            "cnt : 1248\n",
            "cnt : 1249\n",
            "cnt : 1250\n",
            "cnt : 1251\n",
            "cnt : 1252\n",
            "cnt : 1253\n",
            "cnt : 1254\n",
            "cnt : 1255\n",
            "cnt : 1256\n",
            "cnt : 1257\n",
            "cnt : 1258\n",
            "cnt : 1259\n",
            "cnt : 1260\n",
            "cnt : 1261\n",
            "cnt : 1262\n",
            "cnt : 1263\n",
            "cnt : 1264\n",
            "cnt : 1265\n",
            "cnt : 1266\n",
            "cnt : 1267\n",
            "cnt : 1268\n",
            "cnt : 1269\n",
            "cnt : 1270\n",
            "cnt : 1271\n",
            "cnt : 1272\n",
            "cnt : 1273\n",
            "cnt : 1274\n",
            "cnt : 1275\n",
            "cnt : 1276\n",
            "cnt : 1277\n",
            "cnt : 1278\n",
            "cnt : 1279\n",
            "cnt : 1280\n",
            "cnt : 1281\n",
            "cnt : 1282\n",
            "cnt : 1283\n",
            "cnt : 1284\n",
            "cnt : 1285\n",
            "cnt : 1286\n",
            "cnt : 1287\n",
            "cnt : 1288\n",
            "cnt : 1289\n",
            "cnt : 1290\n",
            "cnt : 1291\n",
            "cnt : 1292\n",
            "cnt : 1293\n",
            "cnt : 1294\n",
            "cnt : 1295\n",
            "cnt : 1296\n",
            "cnt : 1297\n",
            "cnt : 1298\n",
            "cnt : 1299\n",
            "cnt : 1300\n",
            "cnt : 1301\n",
            "cnt : 1302\n",
            "cnt : 1303\n",
            "cnt : 1304\n",
            "cnt : 1305\n",
            "cnt : 1306\n",
            "cnt : 1307\n",
            "cnt : 1308\n",
            "cnt : 1309\n",
            "cnt : 1310\n",
            "cnt : 1311\n",
            "cnt : 1312\n",
            "cnt : 1313\n",
            "cnt : 1314\n",
            "cnt : 1315\n",
            "cnt : 1316\n",
            "cnt : 1317\n",
            "cnt : 1318\n",
            "cnt : 1319\n",
            "cnt : 1320\n",
            "cnt : 1321\n",
            "cnt : 1322\n",
            "cnt : 1323\n",
            "cnt : 1324\n",
            "cnt : 1325\n",
            "cnt : 1326\n",
            "cnt : 1327\n",
            "cnt : 1328\n",
            "cnt : 1329\n",
            "cnt : 1330\n",
            "cnt : 1331\n",
            "cnt : 1332\n",
            "cnt : 1333\n",
            "cnt : 1334\n",
            "cnt : 1335\n",
            "cnt : 1336\n",
            "cnt : 1337\n",
            "cnt : 1338\n",
            "cnt : 1339\n",
            "cnt : 1340\n",
            "cnt : 1341\n",
            "cnt : 1342\n",
            "cnt : 1343\n",
            "cnt : 1344\n",
            "cnt : 1345\n",
            "cnt : 1346\n",
            "cnt : 1347\n",
            "cnt : 1348\n",
            "cnt : 1349\n",
            "cnt : 1350\n",
            "cnt : 1351\n",
            "cnt : 1352\n",
            "cnt : 1353\n",
            "cnt : 1354\n",
            "cnt : 1355\n",
            "cnt : 1356\n",
            "cnt : 1357\n",
            "cnt : 1358\n",
            "cnt : 1359\n",
            "cnt : 1360\n",
            "cnt : 1361\n",
            "cnt : 1362\n",
            "cnt : 1363\n",
            "cnt : 1364\n",
            "cnt : 1365\n",
            "cnt : 1366\n",
            "cnt : 1367\n",
            "cnt : 1368\n",
            "cnt : 1369\n",
            "cnt : 1370\n",
            "cnt : 1371\n",
            "cnt : 1372\n",
            "cnt : 1373\n",
            "cnt : 1374\n",
            "cnt : 1375\n",
            "cnt : 1376\n",
            "cnt : 1377\n",
            "cnt : 1378\n",
            "cnt : 1379\n",
            "cnt : 1380\n",
            "cnt : 1381\n",
            "cnt : 1382\n",
            "cnt : 1383\n",
            "cnt : 1384\n",
            "cnt : 1385\n",
            "cnt : 1386\n",
            "cnt : 1387\n",
            "cnt : 1388\n",
            "cnt : 1389\n",
            "cnt : 1390\n",
            "cnt : 1391\n",
            "cnt : 1392\n",
            "cnt : 1393\n",
            "cnt : 1394\n",
            "cnt : 1395\n",
            "cnt : 1396\n",
            "cnt : 1397\n",
            "cnt : 1398\n",
            "cnt : 1399\n",
            "cnt : 1400\n",
            "cnt : 1401\n",
            "cnt : 1402\n",
            "cnt : 1403\n",
            "cnt : 1404\n",
            "cnt : 1405\n",
            "cnt : 1406\n",
            "cnt : 1407\n",
            "cnt : 1408\n",
            "cnt : 1409\n",
            "cnt : 1410\n",
            "cnt : 1411\n",
            "cnt : 1412\n",
            "cnt : 1413\n",
            "cnt : 1414\n",
            "cnt : 1415\n",
            "cnt : 1416\n",
            "cnt : 1417\n",
            "cnt : 1418\n",
            "cnt : 1419\n",
            "cnt : 1420\n",
            "cnt : 1421\n",
            "cnt : 1422\n",
            "cnt : 1423\n",
            "cnt : 1424\n",
            "cnt : 1425\n",
            "cnt : 1426\n",
            "cnt : 1427\n",
            "cnt : 1428\n",
            "cnt : 1429\n",
            "cnt : 1430\n",
            "cnt : 1431\n",
            "cnt : 1432\n",
            "cnt : 1433\n",
            "cnt : 1434\n",
            "cnt : 1435\n",
            "cnt : 1436\n",
            "cnt : 1437\n",
            "cnt : 1438\n",
            "cnt : 1439\n",
            "cnt : 1440\n",
            "cnt : 1441\n",
            "cnt : 1442\n",
            "cnt : 1443\n",
            "cnt : 1444\n",
            "cnt : 1445\n",
            "cnt : 1446\n",
            "cnt : 1447\n",
            "cnt : 1448\n",
            "cnt : 1449\n",
            "cnt : 1450\n",
            "cnt : 1451\n",
            "cnt : 1452\n",
            "cnt : 1453\n",
            "cnt : 1454\n",
            "cnt : 1455\n",
            "cnt : 1456\n",
            "cnt : 1457\n",
            "cnt : 1458\n",
            "cnt : 1459\n",
            "cnt : 1460\n",
            "cnt : 1461\n",
            "cnt : 1462\n",
            "cnt : 1463\n",
            "cnt : 1464\n",
            "cnt : 1465\n",
            "cnt : 1466\n",
            "cnt : 1467\n",
            "cnt : 1468\n",
            "cnt : 1469\n",
            "cnt : 1470\n",
            "cnt : 1471\n",
            "cnt : 1472\n",
            "cnt : 1473\n",
            "cnt : 1474\n",
            "cnt : 1475\n",
            "cnt : 1476\n",
            "cnt : 1477\n",
            "cnt : 1478\n",
            "cnt : 1479\n",
            "cnt : 1480\n",
            "cnt : 1481\n",
            "cnt : 1482\n",
            "cnt : 1483\n",
            "cnt : 1484\n",
            "cnt : 1485\n",
            "cnt : 1486\n",
            "cnt : 1487\n",
            "cnt : 1488\n",
            "cnt : 1489\n",
            "cnt : 1490\n",
            "cnt : 1491\n",
            "cnt : 1492\n",
            "cnt : 1493\n",
            "cnt : 1494\n",
            "cnt : 1495\n",
            "cnt : 1496\n",
            "cnt : 1497\n",
            "cnt : 1498\n",
            "cnt : 1499\n",
            "cnt : 1500\n",
            "cnt : 1501\n",
            "cnt : 1502\n",
            "cnt : 1503\n",
            "cnt : 1504\n",
            "cnt : 1505\n",
            "cnt : 1506\n",
            "cnt : 1507\n",
            "cnt : 1508\n",
            "cnt : 1509\n",
            "cnt : 1510\n",
            "cnt : 1511\n",
            "cnt : 1512\n",
            "cnt : 1513\n",
            "cnt : 1514\n",
            "cnt : 1515\n",
            "cnt : 1516\n",
            "cnt : 1517\n",
            "cnt : 1518\n",
            "cnt : 1519\n",
            "cnt : 1520\n",
            "cnt : 1521\n",
            "cnt : 1522\n",
            "cnt : 1523\n",
            "cnt : 1524\n",
            "cnt : 1525\n",
            "cnt : 1526\n",
            "cnt : 1527\n",
            "cnt : 1528\n",
            "cnt : 1529\n",
            "cnt : 1530\n",
            "cnt : 1531\n",
            "cnt : 1532\n",
            "cnt : 1533\n",
            "cnt : 1534\n",
            "cnt : 1535\n",
            "cnt : 1536\n",
            "cnt : 1537\n",
            "cnt : 1538\n",
            "cnt : 1539\n",
            "cnt : 1540\n",
            "cnt : 1541\n",
            "cnt : 1542\n",
            "cnt : 1543\n",
            "cnt : 1544\n",
            "cnt : 1545\n",
            "cnt : 1546\n",
            "cnt : 1547\n",
            "cnt : 1548\n",
            "cnt : 1549\n",
            "cnt : 1550\n",
            "cnt : 1551\n",
            "cnt : 1552\n",
            "cnt : 1553\n",
            "cnt : 1554\n",
            "cnt : 1555\n",
            "cnt : 1556\n",
            "cnt : 1557\n",
            "cnt : 1558\n",
            "cnt : 1559\n",
            "cnt : 1560\n",
            "cnt : 1561\n",
            "cnt : 1562\n",
            "cnt : 1563\n",
            "cnt : 1564\n",
            "cnt : 1565\n",
            "cnt : 1566\n",
            "cnt : 1567\n",
            "cnt : 1568\n",
            "cnt : 1569\n",
            "cnt : 1570\n",
            "cnt : 1571\n",
            "cnt : 1572\n",
            "cnt : 1573\n",
            "cnt : 1574\n",
            "cnt : 1575\n",
            "cnt : 1576\n",
            "cnt : 1577\n",
            "cnt : 1578\n",
            "cnt : 1579\n",
            "cnt : 1580\n",
            "cnt : 1581\n",
            "cnt : 1582\n",
            "cnt : 1583\n",
            "cnt : 1584\n",
            "cnt : 1585\n",
            "cnt : 1586\n",
            "cnt : 1587\n",
            "cnt : 1588\n",
            "cnt : 1589\n",
            "cnt : 1590\n",
            "cnt : 1591\n",
            "cnt : 1592\n",
            "cnt : 1593\n",
            "cnt : 1594\n",
            "cnt : 1595\n",
            "cnt : 1596\n",
            "cnt : 1597\n",
            "cnt : 1598\n",
            "cnt : 1599\n",
            "cnt : 1600\n",
            "cnt : 1601\n",
            "cnt : 1602\n",
            "cnt : 1603\n",
            "cnt : 1604\n",
            "cnt : 1605\n",
            "cnt : 1606\n",
            "cnt : 1607\n",
            "cnt : 1608\n",
            "cnt : 1609\n",
            "cnt : 1610\n",
            "cnt : 1611\n",
            "cnt : 1612\n",
            "cnt : 1613\n",
            "cnt : 1614\n",
            "cnt : 1615\n",
            "cnt : 1616\n",
            "cnt : 1617\n",
            "cnt : 1618\n",
            "cnt : 1619\n",
            "cnt : 1620\n",
            "cnt : 1621\n",
            "cnt : 1622\n",
            "cnt : 1623\n",
            "cnt : 1624\n",
            "cnt : 1625\n",
            "cnt : 1626\n",
            "cnt : 1627\n",
            "cnt : 1628\n",
            "cnt : 1629\n",
            "cnt : 1630\n",
            "cnt : 1631\n",
            "cnt : 1632\n",
            "cnt : 1633\n",
            "cnt : 1634\n",
            "cnt : 1635\n",
            "cnt : 1636\n",
            "cnt : 1637\n",
            "cnt : 1638\n",
            "cnt : 1639\n",
            "cnt : 1640\n",
            "cnt : 1641\n",
            "cnt : 1642\n",
            "cnt : 1643\n",
            "cnt : 1644\n",
            "cnt : 1645\n",
            "cnt : 1646\n",
            "cnt : 1647\n",
            "cnt : 1648\n",
            "cnt : 1649\n",
            "cnt : 1650\n",
            "cnt : 1651\n",
            "cnt : 1652\n",
            "cnt : 1653\n",
            "cnt : 1654\n",
            "cnt : 1655\n",
            "cnt : 1656\n",
            "cnt : 1657\n",
            "cnt : 1658\n",
            "cnt : 1659\n",
            "cnt : 1660\n",
            "cnt : 1661\n",
            "cnt : 1662\n",
            "cnt : 1663\n",
            "cnt : 1664\n",
            "cnt : 1665\n",
            "cnt : 1666\n",
            "cnt : 1667\n",
            "cnt : 1668\n",
            "cnt : 1669\n",
            "cnt : 1670\n",
            "cnt : 1671\n",
            "cnt : 1672\n",
            "cnt : 1673\n",
            "cnt : 1674\n",
            "cnt : 1675\n",
            "cnt : 1676\n",
            "cnt : 1677\n",
            "cnt : 1678\n",
            "cnt : 1679\n",
            "cnt : 1680\n",
            "cnt : 1681\n",
            "cnt : 1682\n",
            "cnt : 1683\n",
            "cnt : 1684\n",
            "cnt : 1685\n",
            "cnt : 1686\n",
            "cnt : 1687\n",
            "cnt : 1688\n",
            "cnt : 1689\n",
            "cnt : 1690\n",
            "cnt : 1691\n",
            "cnt : 1692\n",
            "cnt : 1693\n",
            "cnt : 1694\n",
            "cnt : 1695\n",
            "cnt : 1696\n",
            "cnt : 1697\n",
            "cnt : 1698\n",
            "cnt : 1699\n",
            "cnt : 1700\n",
            "cnt : 1701\n",
            "cnt : 1702\n",
            "cnt : 1703\n",
            "cnt : 1704\n",
            "cnt : 1705\n",
            "cnt : 1706\n",
            "cnt : 1707\n",
            "cnt : 1708\n",
            "cnt : 1709\n",
            "cnt : 1710\n",
            "cnt : 1711\n",
            "cnt : 1712\n",
            "cnt : 1713\n",
            "cnt : 1714\n",
            "cnt : 1715\n",
            "cnt : 1716\n",
            "cnt : 1717\n",
            "cnt : 1718\n",
            "cnt : 1719\n",
            "cnt : 1720\n",
            "cnt : 1721\n",
            "cnt : 1722\n",
            "cnt : 1723\n",
            "cnt : 1724\n",
            "cnt : 1725\n",
            "cnt : 1726\n",
            "cnt : 1727\n",
            "cnt : 1728\n",
            "cnt : 1729\n",
            "cnt : 1730\n",
            "cnt : 1731\n",
            "cnt : 1732\n",
            "cnt : 1733\n",
            "cnt : 1734\n",
            "cnt : 1735\n",
            "cnt : 1736\n",
            "cnt : 1737\n",
            "cnt : 1738\n",
            "cnt : 1739\n",
            "cnt : 1740\n",
            "cnt : 1741\n",
            "cnt : 1742\n",
            "cnt : 1743\n",
            "cnt : 1744\n",
            "cnt : 1745\n",
            "cnt : 1746\n",
            "cnt : 1747\n",
            "cnt : 1748\n",
            "cnt : 1749\n",
            "cnt : 1750\n",
            "cnt : 1751\n",
            "cnt : 1752\n",
            "cnt : 1753\n",
            "cnt : 1754\n",
            "cnt : 1755\n",
            "cnt : 1756\n",
            "cnt : 1757\n",
            "cnt : 1758\n",
            "cnt : 1759\n",
            "cnt : 1760\n",
            "cnt : 1761\n",
            "cnt : 1762\n",
            "cnt : 1763\n",
            "cnt : 1764\n",
            "cnt : 1765\n",
            "cnt : 1766\n",
            "cnt : 1767\n",
            "cnt : 1768\n",
            "cnt : 1769\n",
            "cnt : 1770\n",
            "cnt : 1771\n",
            "cnt : 1772\n",
            "cnt : 1773\n",
            "cnt : 1774\n",
            "cnt : 1775\n",
            "cnt : 1776\n",
            "cnt : 1777\n",
            "cnt : 1778\n",
            "cnt : 1779\n",
            "cnt : 1780\n",
            "cnt : 1781\n",
            "cnt : 1782\n",
            "cnt : 1783\n",
            "cnt : 1784\n",
            "cnt : 1785\n",
            "cnt : 1786\n",
            "cnt : 1787\n",
            "cnt : 1788\n",
            "cnt : 1789\n",
            "cnt : 1790\n",
            "cnt : 1791\n",
            "cnt : 1792\n",
            "cnt : 1793\n",
            "cnt : 1794\n",
            "cnt : 1795\n",
            "cnt : 1796\n",
            "cnt : 1797\n",
            "cnt : 1798\n",
            "cnt : 1799\n",
            "cnt : 1800\n",
            "cnt : 1801\n",
            "cnt : 1802\n",
            "cnt : 1803\n",
            "cnt : 1804\n",
            "cnt : 1805\n",
            "cnt : 1806\n",
            "cnt : 1807\n",
            "cnt : 1808\n",
            "cnt : 1809\n",
            "cnt : 1810\n",
            "cnt : 1811\n",
            "cnt : 1812\n",
            "cnt : 1813\n",
            "cnt : 1814\n",
            "cnt : 1815\n",
            "cnt : 1816\n",
            "cnt : 1817\n",
            "cnt : 1818\n",
            "cnt : 1819\n",
            "cnt : 1820\n",
            "cnt : 1821\n",
            "cnt : 1822\n",
            "cnt : 1823\n",
            "cnt : 1824\n",
            "cnt : 1825\n",
            "cnt : 1826\n",
            "cnt : 1827\n",
            "cnt : 1828\n",
            "cnt : 1829\n",
            "cnt : 1830\n",
            "cnt : 1831\n",
            "cnt : 1832\n",
            "cnt : 1833\n",
            "cnt : 1834\n",
            "cnt : 1835\n",
            "cnt : 1836\n",
            "cnt : 1837\n",
            "cnt : 1838\n",
            "cnt : 1839\n",
            "cnt : 1840\n",
            "cnt : 1841\n",
            "cnt : 1842\n",
            "cnt : 1843\n",
            "cnt : 1844\n",
            "cnt : 1845\n",
            "cnt : 1846\n",
            "cnt : 1847\n",
            "cnt : 1848\n",
            "cnt : 1849\n",
            "cnt : 1850\n",
            "cnt : 1851\n",
            "cnt : 1852\n",
            "cnt : 1853\n",
            "cnt : 1854\n",
            "cnt : 1855\n",
            "cnt : 1856\n",
            "cnt : 1857\n",
            "cnt : 1858\n",
            "cnt : 1859\n",
            "cnt : 1860\n",
            "cnt : 1861\n",
            "cnt : 1862\n",
            "cnt : 1863\n",
            "cnt : 1864\n",
            "cnt : 1865\n",
            "cnt : 1866\n",
            "cnt : 1867\n",
            "cnt : 1868\n",
            "cnt : 1869\n",
            "cnt : 1870\n",
            "cnt : 1871\n",
            "cnt : 1872\n",
            "cnt : 1873\n",
            "cnt : 1874\n",
            "cnt : 1875\n",
            "cnt : 1876\n",
            "cnt : 1877\n",
            "cnt : 1878\n",
            "cnt : 1879\n",
            "cnt : 1880\n",
            "cnt : 1881\n",
            "cnt : 1882\n",
            "cnt : 1883\n",
            "cnt : 1884\n",
            "cnt : 1885\n",
            "cnt : 1886\n",
            "cnt : 1887\n",
            "cnt : 1888\n",
            "cnt : 1889\n",
            "cnt : 1890\n",
            "cnt : 1891\n",
            "cnt : 1892\n",
            "cnt : 1893\n",
            "cnt : 1894\n",
            "cnt : 1895\n",
            "cnt : 1896\n",
            "cnt : 1897\n",
            "cnt : 1898\n",
            "cnt : 1899\n",
            "cnt : 1900\n",
            "cnt : 1901\n",
            "cnt : 1902\n",
            "cnt : 1903\n",
            "cnt : 1904\n",
            "cnt : 1905\n",
            "cnt : 1906\n",
            "cnt : 1907\n",
            "cnt : 1908\n",
            "cnt : 1909\n",
            "cnt : 1910\n",
            "cnt : 1911\n",
            "cnt : 1912\n",
            "cnt : 1913\n",
            "cnt : 1914\n",
            "cnt : 1915\n",
            "cnt : 1916\n",
            "cnt : 1917\n",
            "cnt : 1918\n",
            "cnt : 1919\n",
            "cnt : 1920\n",
            "cnt : 1921\n",
            "cnt : 1922\n",
            "cnt : 1923\n",
            "cnt : 1924\n",
            "cnt : 1925\n",
            "cnt : 1926\n",
            "cnt : 1927\n",
            "cnt : 1928\n",
            "cnt : 1929\n",
            "cnt : 1930\n",
            "cnt : 1931\n",
            "cnt : 1932\n",
            "cnt : 1933\n",
            "cnt : 1934\n",
            "cnt : 1935\n",
            "cnt : 1936\n",
            "cnt : 1937\n",
            "cnt : 1938\n",
            "cnt : 1939\n",
            "cnt : 1940\n",
            "cnt : 1941\n",
            "cnt : 1942\n",
            "cnt : 1943\n",
            "cnt : 1944\n",
            "cnt : 1945\n",
            "cnt : 1946\n",
            "cnt : 1947\n",
            "cnt : 1948\n",
            "cnt : 1949\n",
            "cnt : 1950\n",
            "cnt : 1951\n",
            "cnt : 1952\n",
            "cnt : 1953\n",
            "cnt : 1954\n",
            "cnt : 1955\n",
            "cnt : 1956\n",
            "cnt : 1957\n",
            "cnt : 1958\n",
            "cnt : 1959\n",
            "cnt : 1960\n",
            "cnt : 1961\n",
            "cnt : 1962\n",
            "cnt : 1963\n",
            "cnt : 1964\n",
            "cnt : 1965\n",
            "cnt : 1966\n",
            "cnt : 1967\n",
            "cnt : 1968\n",
            "cnt : 1969\n",
            "cnt : 1970\n",
            "cnt : 1971\n",
            "cnt : 1972\n",
            "cnt : 1973\n",
            "cnt : 1974\n",
            "cnt : 1975\n",
            "cnt : 1976\n",
            "cnt : 1977\n",
            "cnt : 1978\n",
            "cnt : 1979\n",
            "cnt : 1980\n",
            "cnt : 1981\n",
            "cnt : 1982\n",
            "cnt : 1983\n",
            "cnt : 1984\n",
            "cnt : 1985\n",
            "cnt : 1986\n",
            "cnt : 1987\n",
            "cnt : 1988\n",
            "cnt : 1989\n",
            "cnt : 1990\n",
            "cnt : 1991\n",
            "cnt : 1992\n",
            "cnt : 1993\n",
            "cnt : 1994\n",
            "cnt : 1995\n",
            "cnt : 1996\n",
            "cnt : 1997\n",
            "cnt : 1998\n",
            "cnt : 1999\n",
            "cnt : 2000\n",
            "cnt : 2001\n",
            "cnt : 2002\n",
            "cnt : 2003\n",
            "cnt : 2004\n",
            "cnt : 2005\n",
            "cnt : 2006\n",
            "cnt : 2007\n",
            "cnt : 2008\n",
            "cnt : 2009\n",
            "cnt : 2010\n",
            "cnt : 2011\n",
            "cnt : 2012\n",
            "cnt : 2013\n",
            "cnt : 2014\n",
            "cnt : 2015\n",
            "cnt : 2016\n",
            "cnt : 2017\n",
            "cnt : 2018\n",
            "cnt : 2019\n",
            "cnt : 2020\n",
            "cnt : 2021\n",
            "cnt : 2022\n",
            "cnt : 2023\n",
            "cnt : 2024\n",
            "cnt : 2025\n",
            "cnt : 2026\n",
            "cnt : 2027\n",
            "cnt : 2028\n",
            "cnt : 2029\n",
            "cnt : 2030\n",
            "cnt : 2031\n",
            "cnt : 2032\n",
            "cnt : 2033\n",
            "cnt : 2034\n",
            "cnt : 2035\n",
            "cnt : 2036\n",
            "cnt : 2037\n",
            "cnt : 2038\n",
            "cnt : 2039\n",
            "cnt : 2040\n",
            "cnt : 2041\n",
            "cnt : 2042\n",
            "cnt : 2043\n",
            "cnt : 2044\n",
            "cnt : 2045\n",
            "cnt : 2046\n",
            "cnt : 2047\n",
            "cnt : 2048\n",
            "cnt : 2049\n",
            "cnt : 2050\n",
            "cnt : 2051\n",
            "cnt : 2052\n",
            "cnt : 2053\n",
            "cnt : 2054\n",
            "cnt : 2055\n",
            "cnt : 2056\n",
            "cnt : 2057\n",
            "cnt : 2058\n",
            "cnt : 2059\n",
            "cnt : 2060\n",
            "cnt : 2061\n",
            "cnt : 2062\n",
            "cnt : 2063\n",
            "cnt : 2064\n",
            "cnt : 2065\n",
            "cnt : 2066\n",
            "cnt : 2067\n",
            "cnt : 2068\n",
            "cnt : 2069\n",
            "cnt : 2070\n",
            "cnt : 2071\n",
            "cnt : 2072\n",
            "cnt : 2073\n",
            "cnt : 2074\n",
            "cnt : 2075\n",
            "cnt : 2076\n",
            "cnt : 2077\n",
            "cnt : 2078\n",
            "cnt : 2079\n",
            "cnt : 2080\n",
            "cnt : 2081\n",
            "cnt : 2082\n",
            "cnt : 2083\n",
            "cnt : 2084\n",
            "cnt : 2085\n",
            "cnt : 2086\n",
            "cnt : 2087\n",
            "cnt : 2088\n",
            "cnt : 2089\n",
            "cnt : 2090\n",
            "cnt : 2091\n",
            "cnt : 2092\n",
            "cnt : 2093\n",
            "cnt : 2094\n",
            "cnt : 2095\n",
            "cnt : 2096\n",
            "cnt : 2097\n",
            "cnt : 2098\n",
            "cnt : 2099\n",
            "cnt : 2100\n",
            "cnt : 2101\n",
            "cnt : 2102\n",
            "cnt : 2103\n",
            "cnt : 2104\n",
            "cnt : 2105\n",
            "cnt : 2106\n",
            "cnt : 2107\n",
            "cnt : 2108\n",
            "cnt : 2109\n",
            "cnt : 2110\n",
            "cnt : 2111\n",
            "cnt : 2112\n",
            "cnt : 2113\n",
            "cnt : 2114\n",
            "cnt : 2115\n",
            "cnt : 2116\n",
            "cnt : 2117\n",
            "cnt : 2118\n",
            "cnt : 2119\n",
            "cnt : 2120\n",
            "cnt : 2121\n",
            "cnt : 2122\n",
            "cnt : 2123\n",
            "cnt : 2124\n",
            "cnt : 2125\n",
            "cnt : 2126\n",
            "cnt : 2127\n",
            "cnt : 2128\n",
            "cnt : 2129\n",
            "cnt : 2130\n",
            "cnt : 2131\n",
            "cnt : 2132\n",
            "cnt : 2133\n",
            "cnt : 2134\n",
            "cnt : 2135\n",
            "cnt : 2136\n",
            "cnt : 2137\n",
            "cnt : 2138\n",
            "cnt : 2139\n",
            "cnt : 2140\n",
            "cnt : 2141\n",
            "cnt : 2142\n",
            "cnt : 2143\n",
            "cnt : 2144\n",
            "cnt : 2145\n",
            "cnt : 2146\n",
            "cnt : 2147\n",
            "cnt : 2148\n",
            "cnt : 2149\n",
            "cnt : 2150\n",
            "cnt : 2151\n",
            "cnt : 2152\n",
            "cnt : 2153\n",
            "cnt : 2154\n",
            "cnt : 2155\n",
            "cnt : 2156\n",
            "cnt : 2157\n",
            "cnt : 2158\n",
            "cnt : 2159\n",
            "cnt : 2160\n",
            "cnt : 2161\n",
            "cnt : 2162\n",
            "cnt : 2163\n",
            "cnt : 2164\n",
            "cnt : 2165\n",
            "cnt : 2166\n",
            "cnt : 2167\n",
            "cnt : 2168\n",
            "cnt : 2169\n",
            "cnt : 2170\n",
            "cnt : 2171\n",
            "cnt : 2172\n",
            "cnt : 2173\n",
            "cnt : 2174\n",
            "cnt : 2175\n",
            "cnt : 2176\n",
            "cnt : 2177\n",
            "cnt : 2178\n",
            "cnt : 2179\n",
            "cnt : 2180\n",
            "cnt : 2181\n",
            "cnt : 2182\n",
            "cnt : 2183\n",
            "cnt : 2184\n",
            "cnt : 2185\n",
            "cnt : 2186\n",
            "cnt : 2187\n",
            "cnt : 2188\n",
            "cnt : 2189\n",
            "cnt : 2190\n",
            "cnt : 2191\n",
            "cnt : 2192\n",
            "cnt : 2193\n",
            "cnt : 2194\n",
            "cnt : 2195\n",
            "cnt : 2196\n",
            "cnt : 2197\n",
            "cnt : 2198\n",
            "cnt : 2199\n",
            "cnt : 2200\n",
            "cnt : 2201\n",
            "cnt : 2202\n",
            "cnt : 2203\n",
            "cnt : 2204\n",
            "cnt : 2205\n",
            "cnt : 2206\n",
            "cnt : 2207\n",
            "cnt : 2208\n",
            "cnt : 2209\n",
            "cnt : 2210\n",
            "cnt : 2211\n",
            "cnt : 2212\n",
            "cnt : 2213\n",
            "cnt : 2214\n",
            "cnt : 2215\n",
            "cnt : 2216\n",
            "cnt : 2217\n",
            "cnt : 2218\n",
            "cnt : 2219\n",
            "cnt : 2220\n",
            "cnt : 2221\n",
            "cnt : 2222\n",
            "cnt : 2223\n",
            "cnt : 2224\n",
            "cnt : 2225\n",
            "cnt : 2226\n",
            "cnt : 2227\n",
            "cnt : 2228\n",
            "cnt : 2229\n",
            "cnt : 2230\n",
            "cnt : 2231\n",
            "cnt : 2232\n",
            "cnt : 2233\n",
            "cnt : 2234\n",
            "cnt : 2235\n",
            "cnt : 2236\n",
            "cnt : 2237\n",
            "cnt : 2238\n",
            "cnt : 2239\n",
            "cnt : 2240\n",
            "cnt : 2241\n",
            "cnt : 2242\n",
            "cnt : 2243\n",
            "cnt : 2244\n",
            "cnt : 2245\n",
            "cnt : 2246\n",
            "cnt : 2247\n",
            "cnt : 2248\n",
            "cnt : 2249\n",
            "cnt : 2250\n",
            "cnt : 2251\n",
            "cnt : 2252\n",
            "cnt : 2253\n",
            "cnt : 2254\n",
            "cnt : 2255\n",
            "cnt : 2256\n",
            "cnt : 2257\n",
            "cnt : 2258\n",
            "cnt : 2259\n",
            "cnt : 2260\n",
            "cnt : 2261\n",
            "cnt : 2262\n",
            "cnt : 2263\n",
            "cnt : 2264\n",
            "cnt : 2265\n",
            "cnt : 2266\n",
            "cnt : 2267\n",
            "cnt : 2268\n",
            "cnt : 2269\n",
            "cnt : 2270\n",
            "cnt : 2271\n",
            "cnt : 2272\n",
            "cnt : 2273\n",
            "cnt : 2274\n",
            "cnt : 2275\n",
            "cnt : 2276\n",
            "cnt : 2277\n",
            "cnt : 2278\n",
            "cnt : 2279\n",
            "cnt : 2280\n",
            "cnt : 2281\n",
            "cnt : 2282\n",
            "cnt : 2283\n",
            "cnt : 2284\n",
            "cnt : 2285\n",
            "cnt : 2286\n",
            "cnt : 2287\n",
            "cnt : 2288\n",
            "cnt : 2289\n",
            "cnt : 2290\n",
            "cnt : 2291\n",
            "cnt : 2292\n",
            "cnt : 2293\n",
            "cnt : 2294\n",
            "cnt : 2295\n",
            "cnt : 2296\n",
            "cnt : 2297\n",
            "cnt : 2298\n",
            "cnt : 2299\n",
            "cnt : 2300\n",
            "cnt : 2301\n",
            "cnt : 2302\n",
            "cnt : 2303\n",
            "cnt : 2304\n",
            "cnt : 2305\n",
            "cnt : 2306\n",
            "cnt : 2307\n",
            "cnt : 2308\n",
            "cnt : 2309\n",
            "cnt : 2310\n",
            "cnt : 2311\n",
            "cnt : 2312\n",
            "cnt : 2313\n",
            "cnt : 2314\n",
            "cnt : 2315\n",
            "cnt : 2316\n",
            "cnt : 2317\n",
            "cnt : 2318\n",
            "cnt : 2319\n",
            "cnt : 2320\n",
            "cnt : 2321\n",
            "cnt : 2322\n",
            "cnt : 2323\n",
            "cnt : 2324\n",
            "cnt : 2325\n",
            "cnt : 2326\n",
            "cnt : 2327\n",
            "cnt : 2328\n",
            "cnt : 2329\n",
            "cnt : 2330\n",
            "cnt : 2331\n",
            "cnt : 2332\n",
            "cnt : 2333\n",
            "cnt : 2334\n",
            "cnt : 2335\n",
            "cnt : 2336\n",
            "cnt : 2337\n",
            "cnt : 2338\n",
            "cnt : 2339\n",
            "cnt : 2340\n",
            "cnt : 2341\n",
            "cnt : 2342\n",
            "cnt : 2343\n",
            "cnt : 2344\n",
            "cnt : 2345\n",
            "cnt : 2346\n",
            "cnt : 2347\n",
            "cnt : 2348\n",
            "cnt : 2349\n",
            "cnt : 2350\n",
            "cnt : 2351\n",
            "cnt : 2352\n",
            "cnt : 2353\n",
            "cnt : 2354\n",
            "cnt : 2355\n",
            "cnt : 2356\n",
            "cnt : 2357\n",
            "cnt : 2358\n",
            "cnt : 2359\n",
            "cnt : 2360\n",
            "cnt : 2361\n",
            "cnt : 2362\n",
            "cnt : 2363\n",
            "cnt : 2364\n",
            "cnt : 2365\n",
            "cnt : 2366\n",
            "cnt : 2367\n",
            "cnt : 2368\n",
            "cnt : 2369\n",
            "cnt : 2370\n",
            "cnt : 2371\n",
            "cnt : 2372\n",
            "cnt : 2373\n",
            "cnt : 2374\n",
            "cnt : 2375\n",
            "cnt : 2376\n",
            "cnt : 2377\n",
            "cnt : 2378\n",
            "cnt : 2379\n",
            "cnt : 2380\n",
            "cnt : 2381\n",
            "cnt : 2382\n",
            "cnt : 2383\n",
            "cnt : 2384\n",
            "cnt : 2385\n",
            "cnt : 2386\n",
            "cnt : 2387\n",
            "cnt : 2388\n",
            "cnt : 2389\n",
            "cnt : 2390\n",
            "cnt : 2391\n",
            "cnt : 2392\n",
            "cnt : 2393\n",
            "cnt : 2394\n",
            "cnt : 2395\n",
            "cnt : 2396\n",
            "cnt : 2397\n",
            "cnt : 2398\n",
            "cnt : 2399\n",
            "cnt : 2400\n",
            "cnt : 2401\n",
            "cnt : 2402\n",
            "cnt : 2403\n",
            "cnt : 2404\n",
            "cnt : 2405\n",
            "cnt : 2406\n",
            "cnt : 2407\n",
            "cnt : 2408\n",
            "cnt : 2409\n",
            "cnt : 2410\n",
            "cnt : 2411\n",
            "cnt : 2412\n",
            "cnt : 2413\n",
            "cnt : 2414\n",
            "cnt : 2415\n",
            "cnt : 2416\n",
            "cnt : 2417\n",
            "cnt : 2418\n",
            "cnt : 2419\n",
            "cnt : 2420\n",
            "cnt : 2421\n",
            "cnt : 2422\n",
            "cnt : 2423\n",
            "cnt : 2424\n",
            "cnt : 2425\n",
            "cnt : 2426\n",
            "cnt : 2427\n",
            "cnt : 2428\n",
            "cnt : 2429\n",
            "cnt : 2430\n",
            "cnt : 2431\n",
            "cnt : 2432\n",
            "cnt : 2433\n",
            "cnt : 2434\n",
            "cnt : 2435\n",
            "cnt : 2436\n",
            "cnt : 2437\n",
            "cnt : 2438\n",
            "cnt : 2439\n",
            "cnt : 2440\n",
            "cnt : 2441\n",
            "cnt : 2442\n",
            "cnt : 2443\n",
            "cnt : 2444\n",
            "cnt : 2445\n",
            "cnt : 2446\n",
            "cnt : 2447\n",
            "cnt : 2448\n",
            "cnt : 2449\n",
            "cnt : 2450\n",
            "cnt : 2451\n",
            "cnt : 2452\n",
            "cnt : 2453\n",
            "cnt : 2454\n",
            "cnt : 2455\n",
            "cnt : 2456\n",
            "cnt : 2457\n",
            "cnt : 2458\n",
            "cnt : 2459\n",
            "cnt : 2460\n",
            "cnt : 2461\n",
            "cnt : 2462\n",
            "cnt : 2463\n",
            "cnt : 2464\n",
            "cnt : 2465\n",
            "cnt : 2466\n",
            "cnt : 2467\n",
            "cnt : 2468\n",
            "cnt : 2469\n",
            "cnt : 2470\n",
            "cnt : 2471\n",
            "cnt : 2472\n",
            "cnt : 2473\n",
            "cnt : 2474\n",
            "cnt : 2475\n",
            "cnt : 2476\n",
            "cnt : 2477\n",
            "cnt : 2478\n",
            "cnt : 2479\n",
            "cnt : 2480\n",
            "cnt : 2481\n",
            "cnt : 2482\n",
            "cnt : 2483\n",
            "cnt : 2484\n",
            "cnt : 2485\n",
            "cnt : 2486\n",
            "cnt : 2487\n",
            "cnt : 2488\n",
            "cnt : 2489\n",
            "cnt : 2490\n",
            "cnt : 2491\n",
            "cnt : 2492\n",
            "cnt : 2493\n",
            "cnt : 2494\n",
            "cnt : 2495\n",
            "cnt : 2496\n",
            "cnt : 2497\n",
            "cnt : 2498\n",
            "cnt : 2499\n",
            "cnt : 2500\n",
            "cnt : 2501\n",
            "cnt : 2502\n",
            "cnt : 2503\n",
            "cnt : 2504\n",
            "cnt : 2505\n",
            "cnt : 2506\n",
            "cnt : 2507\n",
            "cnt : 2508\n",
            "cnt : 2509\n",
            "cnt : 2510\n",
            "cnt : 2511\n",
            "cnt : 2512\n",
            "cnt : 2513\n",
            "cnt : 2514\n",
            "cnt : 2515\n",
            "cnt : 2516\n",
            "cnt : 2517\n",
            "cnt : 2518\n",
            "cnt : 2519\n",
            "cnt : 2520\n",
            "cnt : 2521\n",
            "cnt : 2522\n",
            "cnt : 2523\n",
            "cnt : 2524\n",
            "cnt : 2525\n",
            "cnt : 2526\n",
            "cnt : 2527\n",
            "cnt : 2528\n",
            "cnt : 2529\n",
            "cnt : 2530\n",
            "cnt : 2531\n",
            "cnt : 2532\n",
            "cnt : 2533\n",
            "cnt : 2534\n",
            "cnt : 2535\n",
            "cnt : 2536\n",
            "cnt : 2537\n",
            "cnt : 2538\n",
            "cnt : 2539\n",
            "cnt : 2540\n",
            "cnt : 2541\n",
            "cnt : 2542\n",
            "cnt : 2543\n",
            "cnt : 2544\n",
            "cnt : 2545\n",
            "cnt : 2546\n",
            "cnt : 2547\n",
            "cnt : 2548\n",
            "cnt : 2549\n",
            "cnt : 2550\n",
            "cnt : 2551\n",
            "cnt : 2552\n",
            "cnt : 2553\n",
            "cnt : 2554\n",
            "cnt : 2555\n",
            "cnt : 2556\n",
            "cnt : 2557\n",
            "cnt : 2558\n",
            "cnt : 2559\n",
            "cnt : 2560\n",
            "cnt : 2561\n",
            "cnt : 2562\n",
            "cnt : 2563\n",
            "cnt : 2564\n",
            "cnt : 2565\n",
            "cnt : 2566\n",
            "cnt : 2567\n",
            "cnt : 2568\n",
            "cnt : 2569\n",
            "cnt : 2570\n",
            "cnt : 2571\n",
            "cnt : 2572\n",
            "cnt : 2573\n",
            "cnt : 2574\n",
            "cnt : 2575\n",
            "cnt : 2576\n",
            "cnt : 2577\n",
            "cnt : 2578\n",
            "cnt : 2579\n",
            "cnt : 2580\n",
            "cnt : 2581\n",
            "cnt : 2582\n",
            "cnt : 2583\n",
            "cnt : 2584\n",
            "cnt : 2585\n",
            "cnt : 2586\n",
            "cnt : 2587\n",
            "cnt : 2588\n",
            "cnt : 2589\n",
            "cnt : 2590\n",
            "cnt : 2591\n",
            "cnt : 2592\n",
            "cnt : 2593\n",
            "cnt : 2594\n",
            "cnt : 2595\n",
            "cnt : 2596\n",
            "cnt : 2597\n",
            "cnt : 2598\n",
            "cnt : 2599\n",
            "cnt : 2600\n",
            "cnt : 2601\n",
            "cnt : 2602\n",
            "cnt : 2603\n",
            "cnt : 2604\n",
            "cnt : 2605\n",
            "cnt : 2606\n",
            "cnt : 2607\n",
            "cnt : 2608\n",
            "cnt : 2609\n",
            "cnt : 2610\n",
            "cnt : 2611\n",
            "cnt : 2612\n",
            "cnt : 2613\n",
            "cnt : 2614\n",
            "cnt : 2615\n",
            "cnt : 2616\n",
            "cnt : 2617\n",
            "cnt : 2618\n",
            "cnt : 2619\n",
            "cnt : 2620\n",
            "cnt : 2621\n",
            "cnt : 2622\n",
            "cnt : 2623\n",
            "cnt : 2624\n",
            "cnt : 2625\n",
            "cnt : 2626\n",
            "cnt : 2627\n",
            "cnt : 2628\n",
            "cnt : 2629\n",
            "cnt : 2630\n",
            "cnt : 2631\n",
            "cnt : 2632\n",
            "cnt : 2633\n",
            "cnt : 2634\n",
            "cnt : 2635\n",
            "cnt : 2636\n",
            "cnt : 2637\n",
            "cnt : 2638\n",
            "cnt : 2639\n",
            "cnt : 2640\n",
            "cnt : 2641\n",
            "cnt : 2642\n",
            "cnt : 2643\n",
            "cnt : 2644\n",
            "cnt : 2645\n",
            "cnt : 2646\n",
            "cnt : 2647\n",
            "cnt : 2648\n",
            "cnt : 2649\n",
            "cnt : 2650\n",
            "cnt : 2651\n",
            "cnt : 2652\n",
            "cnt : 2653\n",
            "cnt : 2654\n",
            "cnt : 2655\n",
            "cnt : 2656\n",
            "cnt : 2657\n",
            "cnt : 2658\n",
            "cnt : 2659\n",
            "cnt : 2660\n",
            "cnt : 2661\n",
            "cnt : 2662\n",
            "cnt : 2663\n",
            "cnt : 2664\n",
            "cnt : 2665\n",
            "cnt : 2666\n",
            "cnt : 2667\n",
            "cnt : 2668\n",
            "cnt : 2669\n",
            "cnt : 2670\n",
            "cnt : 2671\n",
            "cnt : 2672\n",
            "cnt : 2673\n",
            "cnt : 2674\n",
            "cnt : 2675\n",
            "cnt : 2676\n",
            "cnt : 2677\n",
            "cnt : 2678\n",
            "cnt : 2679\n",
            "cnt : 2680\n",
            "cnt : 2681\n",
            "cnt : 2682\n",
            "cnt : 2683\n",
            "cnt : 2684\n",
            "cnt : 2685\n",
            "cnt : 2686\n",
            "cnt : 2687\n",
            "cnt : 2688\n",
            "cnt : 2689\n",
            "cnt : 2690\n",
            "cnt : 2691\n",
            "cnt : 2692\n",
            "cnt : 2693\n",
            "cnt : 2694\n",
            "cnt : 2695\n",
            "cnt : 2696\n",
            "cnt : 2697\n",
            "cnt : 2698\n",
            "cnt : 2699\n",
            "cnt : 2700\n",
            "cnt : 2701\n",
            "cnt : 2702\n",
            "cnt : 2703\n",
            "cnt : 2704\n",
            "cnt : 2705\n",
            "cnt : 2706\n",
            "cnt : 2707\n",
            "cnt : 2708\n",
            "cnt : 2709\n",
            "cnt : 2710\n",
            "cnt : 2711\n",
            "cnt : 2712\n",
            "cnt : 2713\n",
            "cnt : 2714\n",
            "cnt : 2715\n",
            "cnt : 2716\n",
            "cnt : 2717\n",
            "cnt : 2718\n",
            "cnt : 2719\n",
            "cnt : 2720\n",
            "cnt : 2721\n",
            "cnt : 2722\n",
            "cnt : 2723\n",
            "cnt : 2724\n",
            "cnt : 2725\n",
            "cnt : 2726\n",
            "cnt : 2727\n",
            "cnt : 2728\n",
            "cnt : 2729\n",
            "cnt : 2730\n",
            "cnt : 2731\n",
            "cnt : 2732\n",
            "cnt : 2733\n",
            "cnt : 2734\n",
            "cnt : 2735\n",
            "cnt : 2736\n",
            "cnt : 2737\n",
            "cnt : 2738\n",
            "cnt : 2739\n",
            "cnt : 2740\n",
            "cnt : 2741\n",
            "cnt : 2742\n",
            "cnt : 2743\n",
            "cnt : 2744\n",
            "cnt : 2745\n",
            "cnt : 2746\n",
            "cnt : 2747\n",
            "cnt : 2748\n",
            "cnt : 2749\n",
            "cnt : 2750\n",
            "cnt : 2751\n",
            "cnt : 2752\n",
            "cnt : 2753\n",
            "cnt : 2754\n",
            "cnt : 2755\n",
            "cnt : 2756\n",
            "cnt : 2757\n",
            "cnt : 2758\n",
            "cnt : 2759\n",
            "cnt : 2760\n",
            "cnt : 2761\n",
            "cnt : 2762\n",
            "cnt : 2763\n",
            "cnt : 2764\n",
            "cnt : 2765\n",
            "cnt : 2766\n",
            "cnt : 2767\n",
            "cnt : 2768\n",
            "cnt : 2769\n",
            "cnt : 2770\n",
            "cnt : 2771\n",
            "cnt : 2772\n",
            "cnt : 2773\n",
            "cnt : 2774\n",
            "cnt : 2775\n",
            "cnt : 2776\n",
            "cnt : 2777\n",
            "cnt : 2778\n",
            "cnt : 2779\n",
            "cnt : 2780\n",
            "cnt : 2781\n",
            "cnt : 2782\n",
            "cnt : 2783\n",
            "cnt : 2784\n",
            "cnt : 2785\n",
            "cnt : 2786\n",
            "cnt : 2787\n",
            "cnt : 2788\n",
            "cnt : 2789\n",
            "cnt : 2790\n",
            "cnt : 2791\n",
            "cnt : 2792\n",
            "cnt : 2793\n",
            "cnt : 2794\n",
            "cnt : 2795\n",
            "cnt : 2796\n",
            "cnt : 2797\n",
            "cnt : 2798\n",
            "cnt : 2799\n",
            "cnt : 2800\n",
            "cnt : 2801\n",
            "cnt : 2802\n",
            "cnt : 2803\n",
            "cnt : 2804\n",
            "cnt : 2805\n",
            "cnt : 2806\n",
            "cnt : 2807\n",
            "cnt : 2808\n",
            "cnt : 2809\n",
            "cnt : 2810\n",
            "cnt : 2811\n",
            "cnt : 2812\n",
            "cnt : 2813\n",
            "cnt : 2814\n",
            "cnt : 2815\n",
            "cnt : 2816\n",
            "cnt : 2817\n",
            "cnt : 2818\n",
            "cnt : 2819\n",
            "cnt : 2820\n",
            "cnt : 2821\n",
            "cnt : 2822\n",
            "cnt : 2823\n",
            "cnt : 2824\n",
            "cnt : 2825\n",
            "cnt : 2826\n",
            "cnt : 2827\n",
            "cnt : 2828\n",
            "cnt : 2829\n",
            "cnt : 2830\n",
            "cnt : 2831\n",
            "cnt : 2832\n",
            "cnt : 2833\n",
            "cnt : 2834\n",
            "cnt : 2835\n",
            "cnt : 2836\n",
            "cnt : 2837\n",
            "cnt : 2838\n",
            "cnt : 2839\n",
            "cnt : 2840\n",
            "cnt : 2841\n",
            "cnt : 2842\n",
            "cnt : 2843\n",
            "cnt : 2844\n",
            "cnt : 2845\n",
            "cnt : 2846\n",
            "cnt : 2847\n",
            "cnt : 2848\n",
            "cnt : 2849\n",
            "cnt : 2850\n",
            "cnt : 2851\n",
            "cnt : 2852\n",
            "cnt : 2853\n",
            "cnt : 2854\n",
            "cnt : 2855\n",
            "cnt : 2856\n",
            "cnt : 2857\n",
            "cnt : 2858\n",
            "cnt : 2859\n",
            "cnt : 2860\n",
            "cnt : 2861\n",
            "cnt : 2862\n",
            "cnt : 2863\n",
            "cnt : 2864\n",
            "cnt : 2865\n",
            "cnt : 2866\n",
            "cnt : 2867\n",
            "cnt : 2868\n",
            "cnt : 2869\n",
            "cnt : 2870\n",
            "cnt : 2871\n",
            "cnt : 2872\n",
            "cnt : 2873\n",
            "cnt : 2874\n",
            "cnt : 2875\n",
            "cnt : 2876\n",
            "cnt : 2877\n",
            "cnt : 2878\n",
            "cnt : 2879\n",
            "cnt : 2880\n",
            "cnt : 2881\n",
            "cnt : 2882\n",
            "cnt : 2883\n",
            "cnt : 2884\n",
            "cnt : 2885\n",
            "cnt : 2886\n",
            "cnt : 2887\n",
            "cnt : 2888\n",
            "cnt : 2889\n",
            "cnt : 2890\n",
            "cnt : 2891\n",
            "cnt : 2892\n",
            "cnt : 2893\n",
            "cnt : 2894\n",
            "cnt : 2895\n",
            "cnt : 2896\n",
            "cnt : 2897\n",
            "cnt : 2898\n",
            "cnt : 2899\n",
            "cnt : 2900\n",
            "cnt : 2901\n",
            "cnt : 2902\n",
            "cnt : 2903\n",
            "cnt : 2904\n",
            "cnt : 2905\n",
            "cnt : 2906\n",
            "cnt : 2907\n",
            "cnt : 2908\n",
            "cnt : 2909\n",
            "cnt : 2910\n",
            "cnt : 2911\n",
            "cnt : 2912\n",
            "cnt : 2913\n",
            "cnt : 2914\n",
            "cnt : 2915\n",
            "cnt : 2916\n",
            "cnt : 2917\n",
            "cnt : 2918\n",
            "cnt : 2919\n",
            "cnt : 2920\n",
            "cnt : 2921\n",
            "cnt : 2922\n",
            "cnt : 2923\n",
            "cnt : 2924\n",
            "cnt : 2925\n",
            "cnt : 2926\n",
            "cnt : 2927\n",
            "cnt : 2928\n",
            "cnt : 2929\n",
            "cnt : 2930\n",
            "cnt : 2931\n",
            "cnt : 2932\n",
            "cnt : 2933\n",
            "cnt : 2934\n",
            "cnt : 2935\n",
            "cnt : 2936\n",
            "cnt : 2937\n",
            "cnt : 2938\n",
            "cnt : 2939\n",
            "cnt : 2940\n",
            "cnt : 2941\n",
            "cnt : 2942\n",
            "cnt : 2943\n",
            "cnt : 2944\n",
            "cnt : 2945\n",
            "cnt : 2946\n",
            "cnt : 2947\n",
            "cnt : 2948\n",
            "cnt : 2949\n",
            "cnt : 2950\n",
            "cnt : 2951\n",
            "cnt : 2952\n",
            "cnt : 2953\n",
            "cnt : 2954\n",
            "cnt : 2955\n",
            "cnt : 2956\n",
            "cnt : 2957\n",
            "cnt : 2958\n",
            "cnt : 2959\n",
            "cnt : 2960\n",
            "cnt : 2961\n",
            "cnt : 2962\n",
            "cnt : 2963\n",
            "cnt : 2964\n",
            "cnt : 2965\n",
            "cnt : 2966\n",
            "cnt : 2967\n",
            "cnt : 2968\n",
            "cnt : 2969\n",
            "cnt : 2970\n",
            "cnt : 2971\n",
            "cnt : 2972\n",
            "cnt : 2973\n",
            "cnt : 2974\n",
            "cnt : 2975\n",
            "cnt : 2976\n",
            "cnt : 2977\n",
            "cnt : 2978\n",
            "cnt : 2979\n",
            "cnt : 2980\n",
            "cnt : 2981\n",
            "cnt : 2982\n",
            "cnt : 2983\n",
            "cnt : 2984\n",
            "cnt : 2985\n",
            "cnt : 2986\n",
            "cnt : 2987\n",
            "cnt : 2988\n",
            "cnt : 2989\n",
            "cnt : 2990\n",
            "cnt : 2991\n",
            "cnt : 2992\n",
            "cnt : 2993\n",
            "cnt : 2994\n",
            "cnt : 2995\n",
            "cnt : 2996\n",
            "cnt : 2997\n",
            "cnt : 2998\n",
            "cnt : 2999\n",
            "cnt : 3000\n",
            "cnt : 3001\n",
            "cnt : 3002\n",
            "cnt : 3003\n",
            "cnt : 3004\n",
            "cnt : 3005\n",
            "cnt : 3006\n",
            "cnt : 3007\n",
            "cnt : 3008\n",
            "cnt : 3009\n",
            "cnt : 3010\n",
            "cnt : 3011\n",
            "cnt : 3012\n",
            "cnt : 3013\n",
            "cnt : 3014\n",
            "cnt : 3015\n",
            "cnt : 3016\n",
            "cnt : 3017\n",
            "cnt : 3018\n",
            "cnt : 3019\n",
            "cnt : 3020\n",
            "cnt : 3021\n",
            "cnt : 3022\n",
            "cnt : 3023\n",
            "cnt : 3024\n",
            "cnt : 3025\n",
            "cnt : 3026\n",
            "cnt : 3027\n",
            "cnt : 3028\n",
            "cnt : 3029\n",
            "cnt : 3030\n",
            "cnt : 3031\n",
            "cnt : 3032\n",
            "cnt : 3033\n",
            "cnt : 3034\n",
            "cnt : 3035\n",
            "cnt : 3036\n",
            "cnt : 3037\n",
            "cnt : 3038\n",
            "cnt : 3039\n",
            "cnt : 3040\n",
            "cnt : 3041\n",
            "cnt : 3042\n",
            "cnt : 3043\n",
            "cnt : 3044\n",
            "cnt : 3045\n",
            "cnt : 3046\n",
            "cnt : 3047\n",
            "cnt : 3048\n",
            "cnt : 3049\n",
            "cnt : 3050\n",
            "cnt : 3051\n",
            "cnt : 3052\n",
            "cnt : 3053\n",
            "cnt : 3054\n",
            "cnt : 3055\n",
            "cnt : 3056\n",
            "cnt : 3057\n",
            "cnt : 3058\n",
            "cnt : 3059\n",
            "cnt : 3060\n",
            "cnt : 3061\n",
            "cnt : 3062\n",
            "cnt : 3063\n",
            "cnt : 3064\n",
            "cnt : 3065\n",
            "cnt : 3066\n",
            "cnt : 3067\n",
            "cnt : 3068\n",
            "cnt : 3069\n",
            "cnt : 3070\n",
            "cnt : 3071\n",
            "cnt : 3072\n",
            "cnt : 3073\n",
            "cnt : 3074\n",
            "cnt : 3075\n",
            "cnt : 3076\n",
            "cnt : 3077\n",
            "cnt : 3078\n",
            "cnt : 3079\n",
            "cnt : 3080\n",
            "cnt : 3081\n",
            "cnt : 3082\n",
            "cnt : 3083\n",
            "cnt : 3084\n",
            "cnt : 3085\n",
            "cnt : 3086\n",
            "cnt : 3087\n",
            "cnt : 3088\n",
            "cnt : 3089\n",
            "cnt : 3090\n",
            "cnt : 3091\n",
            "cnt : 3092\n",
            "cnt : 3093\n",
            "cnt : 3094\n",
            "cnt : 3095\n",
            "cnt : 3096\n",
            "cnt : 3097\n",
            "cnt : 3098\n",
            "cnt : 3099\n",
            "cnt : 3100\n",
            "cnt : 3101\n",
            "cnt : 3102\n",
            "cnt : 3103\n",
            "cnt : 3104\n",
            "cnt : 3105\n",
            "cnt : 3106\n",
            "cnt : 3107\n",
            "cnt : 3108\n",
            "cnt : 3109\n",
            "cnt : 3110\n",
            "cnt : 3111\n",
            "cnt : 3112\n",
            "cnt : 3113\n",
            "cnt : 3114\n",
            "cnt : 3115\n",
            "cnt : 3116\n",
            "cnt : 3117\n",
            "cnt : 3118\n",
            "cnt : 3119\n",
            "cnt : 3120\n",
            "cnt : 3121\n",
            "cnt : 3122\n",
            "cnt : 3123\n",
            "cnt : 3124\n",
            "cnt : 3125\n",
            "cnt : 3126\n",
            "cnt : 3127\n",
            "cnt : 3128\n",
            "cnt : 3129\n",
            "cnt : 3130\n",
            "cnt : 3131\n",
            "cnt : 3132\n",
            "cnt : 3133\n",
            "cnt : 3134\n",
            "cnt : 3135\n",
            "cnt : 3136\n",
            "cnt : 3137\n",
            "cnt : 3138\n",
            "cnt : 3139\n",
            "cnt : 3140\n",
            "cnt : 3141\n",
            "cnt : 3142\n",
            "cnt : 3143\n",
            "cnt : 3144\n",
            "cnt : 3145\n",
            "cnt : 3146\n",
            "cnt : 3147\n",
            "cnt : 3148\n",
            "cnt : 3149\n",
            "cnt : 3150\n",
            "cnt : 3151\n",
            "cnt : 3152\n",
            "cnt : 3153\n",
            "cnt : 3154\n",
            "cnt : 3155\n",
            "cnt : 3156\n",
            "cnt : 3157\n",
            "cnt : 3158\n",
            "cnt : 3159\n",
            "cnt : 3160\n",
            "cnt : 3161\n",
            "cnt : 3162\n",
            "cnt : 3163\n",
            "cnt : 3164\n",
            "cnt : 3165\n",
            "cnt : 3166\n",
            "cnt : 3167\n",
            "cnt : 3168\n",
            "cnt : 3169\n",
            "cnt : 3170\n",
            "cnt : 3171\n",
            "cnt : 3172\n",
            "cnt : 3173\n",
            "cnt : 3174\n",
            "cnt : 3175\n",
            "cnt : 3176\n",
            "cnt : 3177\n",
            "cnt : 3178\n",
            "cnt : 3179\n",
            "cnt : 3180\n",
            "cnt : 3181\n",
            "cnt : 3182\n",
            "cnt : 3183\n",
            "cnt : 3184\n",
            "cnt : 3185\n",
            "cnt : 3186\n",
            "cnt : 3187\n",
            "cnt : 3188\n",
            "cnt : 3189\n",
            "cnt : 3190\n",
            "cnt : 3191\n",
            "cnt : 3192\n",
            "cnt : 3193\n",
            "cnt : 3194\n",
            "cnt : 3195\n",
            "cnt : 3196\n",
            "cnt : 3197\n",
            "cnt : 3198\n",
            "cnt : 3199\n",
            "cnt : 3200\n",
            "cnt : 3201\n",
            "cnt : 3202\n",
            "cnt : 3203\n",
            "cnt : 3204\n",
            "cnt : 3205\n",
            "cnt : 3206\n",
            "cnt : 3207\n",
            "cnt : 3208\n",
            "cnt : 3209\n",
            "cnt : 3210\n",
            "cnt : 3211\n",
            "cnt : 3212\n",
            "cnt : 3213\n",
            "cnt : 3214\n",
            "cnt : 3215\n",
            "cnt : 3216\n",
            "cnt : 3217\n",
            "cnt : 3218\n",
            "cnt : 3219\n",
            "cnt : 3220\n",
            "cnt : 3221\n",
            "cnt : 3222\n",
            "cnt : 3223\n",
            "cnt : 3224\n",
            "cnt : 3225\n",
            "cnt : 3226\n",
            "cnt : 3227\n",
            "cnt : 3228\n",
            "cnt : 3229\n",
            "cnt : 3230\n",
            "cnt : 3231\n",
            "cnt : 3232\n",
            "cnt : 3233\n",
            "cnt : 3234\n",
            "cnt : 3235\n",
            "cnt : 3236\n",
            "cnt : 3237\n",
            "cnt : 3238\n",
            "cnt : 3239\n",
            "cnt : 3240\n",
            "cnt : 3241\n",
            "cnt : 3242\n",
            "cnt : 3243\n",
            "cnt : 3244\n",
            "cnt : 3245\n",
            "cnt : 3246\n",
            "cnt : 3247\n",
            "cnt : 3248\n",
            "cnt : 3249\n",
            "cnt : 3250\n",
            "cnt : 3251\n",
            "cnt : 3252\n",
            "cnt : 3253\n",
            "cnt : 3254\n",
            "cnt : 3255\n",
            "cnt : 3256\n",
            "cnt : 3257\n",
            "cnt : 3258\n",
            "cnt : 3259\n",
            "cnt : 3260\n",
            "cnt : 3261\n",
            "cnt : 3262\n",
            "cnt : 3263\n",
            "cnt : 3264\n",
            "cnt : 3265\n",
            "cnt : 3266\n",
            "cnt : 3267\n",
            "cnt : 3268\n",
            "cnt : 3269\n",
            "cnt : 3270\n",
            "cnt : 3271\n",
            "cnt : 3272\n",
            "cnt : 3273\n",
            "cnt : 3274\n",
            "cnt : 3275\n",
            "cnt : 3276\n",
            "cnt : 3277\n",
            "cnt : 3278\n",
            "cnt : 3279\n",
            "cnt : 3280\n",
            "cnt : 3281\n",
            "cnt : 3282\n",
            "cnt : 3283\n",
            "cnt : 3284\n",
            "cnt : 3285\n",
            "cnt : 3286\n",
            "cnt : 3287\n",
            "cnt : 3288\n",
            "cnt : 3289\n",
            "cnt : 3290\n",
            "cnt : 3291\n",
            "cnt : 3292\n",
            "cnt : 3293\n",
            "cnt : 3294\n",
            "cnt : 3295\n",
            "cnt : 3296\n",
            "cnt : 3297\n",
            "cnt : 3298\n",
            "cnt : 3299\n",
            "cnt : 3300\n",
            "cnt : 3301\n",
            "cnt : 3302\n",
            "cnt : 3303\n",
            "cnt : 3304\n",
            "cnt : 3305\n",
            "cnt : 3306\n",
            "cnt : 3307\n",
            "cnt : 3308\n",
            "cnt : 3309\n",
            "cnt : 3310\n",
            "cnt : 3311\n",
            "cnt : 3312\n",
            "cnt : 3313\n",
            "cnt : 3314\n",
            "cnt : 3315\n",
            "cnt : 3316\n",
            "cnt : 3317\n",
            "cnt : 3318\n",
            "cnt : 3319\n",
            "cnt : 3320\n",
            "cnt : 3321\n",
            "cnt : 3322\n",
            "cnt : 3323\n",
            "cnt : 3324\n",
            "cnt : 3325\n",
            "cnt : 3326\n",
            "cnt : 3327\n",
            "cnt : 3328\n",
            "cnt : 3329\n",
            "cnt : 3330\n",
            "cnt : 3331\n",
            "cnt : 3332\n",
            "cnt : 3333\n",
            "cnt : 3334\n",
            "cnt : 3335\n",
            "cnt : 3336\n",
            "cnt : 3337\n",
            "cnt : 3338\n",
            "cnt : 3339\n",
            "cnt : 3340\n",
            "cnt : 3341\n",
            "cnt : 3342\n",
            "cnt : 3343\n",
            "cnt : 3344\n",
            "cnt : 3345\n",
            "cnt : 3346\n",
            "cnt : 3347\n",
            "cnt : 3348\n",
            "cnt : 3349\n",
            "cnt : 3350\n",
            "cnt : 3351\n",
            "cnt : 3352\n",
            "cnt : 3353\n",
            "cnt : 3354\n",
            "cnt : 3355\n",
            "cnt : 3356\n",
            "cnt : 3357\n",
            "cnt : 3358\n",
            "cnt : 3359\n",
            "cnt : 3360\n",
            "cnt : 3361\n",
            "cnt : 3362\n",
            "cnt : 3363\n",
            "cnt : 3364\n",
            "cnt : 3365\n",
            "cnt : 3366\n",
            "cnt : 3367\n",
            "cnt : 3368\n",
            "cnt : 3369\n",
            "cnt : 3370\n",
            "cnt : 3371\n",
            "cnt : 3372\n",
            "cnt : 3373\n",
            "cnt : 3374\n",
            "cnt : 3375\n",
            "cnt : 3376\n",
            "cnt : 3377\n",
            "cnt : 3378\n",
            "cnt : 3379\n",
            "cnt : 3380\n",
            "cnt : 3381\n",
            "cnt : 3382\n",
            "cnt : 3383\n",
            "cnt : 3384\n",
            "cnt : 3385\n",
            "cnt : 3386\n",
            "cnt : 3387\n",
            "cnt : 3388\n",
            "cnt : 3389\n",
            "cnt : 3390\n",
            "cnt : 3391\n",
            "cnt : 3392\n",
            "cnt : 3393\n",
            "cnt : 3394\n",
            "cnt : 3395\n",
            "cnt : 3396\n",
            "cnt : 3397\n",
            "cnt : 3398\n",
            "cnt : 3399\n",
            "cnt : 3400\n",
            "cnt : 3401\n",
            "cnt : 3402\n",
            "cnt : 3403\n",
            "cnt : 3404\n",
            "cnt : 3405\n",
            "cnt : 3406\n",
            "cnt : 3407\n",
            "cnt : 3408\n",
            "cnt : 3409\n",
            "cnt : 3410\n",
            "cnt : 3411\n",
            "cnt : 3412\n",
            "cnt : 3413\n",
            "cnt : 3414\n",
            "cnt : 3415\n",
            "cnt : 3416\n",
            "cnt : 3417\n",
            "cnt : 3418\n",
            "cnt : 3419\n",
            "cnt : 3420\n",
            "cnt : 3421\n",
            "cnt : 3422\n",
            "cnt : 3423\n",
            "cnt : 3424\n",
            "cnt : 3425\n",
            "cnt : 3426\n",
            "cnt : 3427\n",
            "cnt : 3428\n",
            "cnt : 3429\n",
            "cnt : 3430\n",
            "cnt : 3431\n",
            "cnt : 3432\n",
            "cnt : 3433\n",
            "cnt : 3434\n",
            "cnt : 3435\n",
            "cnt : 3436\n",
            "cnt : 3437\n",
            "cnt : 3438\n",
            "cnt : 3439\n",
            "cnt : 3440\n",
            "cnt : 3441\n",
            "cnt : 3442\n",
            "cnt : 3443\n",
            "cnt : 3444\n",
            "cnt : 3445\n",
            "cnt : 3446\n",
            "cnt : 3447\n",
            "cnt : 3448\n",
            "cnt : 3449\n",
            "cnt : 3450\n",
            "cnt : 3451\n",
            "cnt : 3452\n",
            "cnt : 3453\n",
            "cnt : 3454\n",
            "cnt : 3455\n",
            "cnt : 3456\n",
            "cnt : 3457\n",
            "cnt : 3458\n",
            "cnt : 3459\n",
            "cnt : 3460\n",
            "cnt : 3461\n",
            "cnt : 3462\n",
            "cnt : 3463\n",
            "cnt : 3464\n",
            "cnt : 3465\n",
            "cnt : 3466\n",
            "cnt : 3467\n",
            "cnt : 3468\n",
            "cnt : 3469\n",
            "cnt : 3470\n",
            "cnt : 3471\n",
            "cnt : 3472\n",
            "cnt : 3473\n",
            "cnt : 3474\n",
            "cnt : 3475\n",
            "cnt : 3476\n",
            "cnt : 3477\n",
            "cnt : 3478\n",
            "cnt : 3479\n",
            "cnt : 3480\n",
            "cnt : 3481\n",
            "cnt : 3482\n",
            "cnt : 3483\n",
            "cnt : 3484\n",
            "cnt : 3485\n",
            "cnt : 3486\n",
            "cnt : 3487\n",
            "cnt : 3488\n",
            "cnt : 3489\n",
            "cnt : 3490\n",
            "cnt : 3491\n",
            "cnt : 3492\n",
            "cnt : 3493\n",
            "cnt : 3494\n",
            "cnt : 3495\n",
            "cnt : 3496\n",
            "cnt : 3497\n",
            "cnt : 3498\n",
            "cnt : 3499\n",
            "cnt : 3500\n",
            "cnt : 3501\n",
            "cnt : 3502\n",
            "cnt : 3503\n",
            "cnt : 3504\n",
            "cnt : 3505\n",
            "cnt : 3506\n",
            "cnt : 3507\n",
            "cnt : 3508\n",
            "cnt : 3509\n",
            "cnt : 3510\n",
            "cnt : 3511\n",
            "cnt : 3512\n",
            "cnt : 3513\n",
            "cnt : 3514\n",
            "cnt : 3515\n",
            "cnt : 3516\n",
            "cnt : 3517\n",
            "cnt : 3518\n",
            "cnt : 3519\n",
            "cnt : 3520\n",
            "cnt : 3521\n",
            "cnt : 3522\n",
            "cnt : 3523\n",
            "cnt : 3524\n",
            "cnt : 3525\n",
            "cnt : 3526\n",
            "cnt : 3527\n",
            "cnt : 3528\n",
            "cnt : 3529\n",
            "cnt : 3530\n",
            "cnt : 3531\n",
            "cnt : 3532\n",
            "cnt : 3533\n",
            "cnt : 3534\n",
            "cnt : 3535\n",
            "cnt : 3536\n",
            "cnt : 3537\n",
            "cnt : 3538\n",
            "cnt : 3539\n",
            "cnt : 3540\n",
            "cnt : 3541\n",
            "cnt : 3542\n",
            "cnt : 3543\n",
            "cnt : 3544\n",
            "cnt : 3545\n",
            "cnt : 3546\n",
            "cnt : 3547\n",
            "cnt : 3548\n",
            "cnt : 3549\n",
            "cnt : 3550\n",
            "cnt : 3551\n",
            "cnt : 3552\n",
            "cnt : 3553\n",
            "cnt : 3554\n",
            "cnt : 3555\n",
            "cnt : 3556\n",
            "cnt : 3557\n",
            "cnt : 3558\n",
            "cnt : 3559\n",
            "cnt : 3560\n",
            "cnt : 3561\n",
            "cnt : 3562\n",
            "cnt : 3563\n",
            "cnt : 3564\n",
            "cnt : 3565\n",
            "cnt : 3566\n",
            "cnt : 3567\n",
            "cnt : 3568\n",
            "cnt : 3569\n",
            "cnt : 3570\n",
            "cnt : 3571\n",
            "cnt : 3572\n",
            "cnt : 3573\n",
            "cnt : 3574\n",
            "cnt : 3575\n",
            "cnt : 3576\n",
            "cnt : 3577\n",
            "cnt : 3578\n",
            "cnt : 3579\n",
            "cnt : 3580\n",
            "cnt : 3581\n",
            "cnt : 3582\n",
            "cnt : 3583\n",
            "cnt : 3584\n",
            "cnt : 3585\n",
            "cnt : 3586\n",
            "cnt : 3587\n",
            "cnt : 3588\n",
            "cnt : 3589\n",
            "cnt : 3590\n",
            "cnt : 3591\n",
            "cnt : 3592\n",
            "cnt : 3593\n",
            "cnt : 3594\n",
            "cnt : 3595\n",
            "cnt : 3596\n",
            "cnt : 3597\n",
            "cnt : 3598\n",
            "cnt : 3599\n",
            "cnt : 3600\n",
            "cnt : 3601\n",
            "cnt : 3602\n",
            "cnt : 3603\n",
            "cnt : 3604\n",
            "cnt : 3605\n",
            "cnt : 3606\n",
            "cnt : 3607\n",
            "cnt : 3608\n",
            "cnt : 3609\n",
            "cnt : 3610\n",
            "cnt : 3611\n",
            "cnt : 3612\n",
            "cnt : 3613\n",
            "cnt : 3614\n",
            "cnt : 3615\n",
            "cnt : 3616\n",
            "cnt : 3617\n",
            "cnt : 3618\n",
            "cnt : 3619\n",
            "cnt : 3620\n",
            "cnt : 3621\n",
            "cnt : 3622\n",
            "cnt : 3623\n",
            "cnt : 3624\n",
            "cnt : 3625\n",
            "cnt : 3626\n",
            "cnt : 3627\n",
            "cnt : 3628\n",
            "cnt : 3629\n",
            "cnt : 3630\n",
            "cnt : 3631\n",
            "cnt : 3632\n",
            "cnt : 3633\n",
            "cnt : 3634\n",
            "cnt : 3635\n",
            "cnt : 3636\n",
            "cnt : 3637\n",
            "cnt : 3638\n",
            "cnt : 3639\n",
            "cnt : 3640\n",
            "cnt : 3641\n",
            "cnt : 3642\n",
            "cnt : 3643\n",
            "cnt : 3644\n",
            "cnt : 3645\n",
            "cnt : 3646\n",
            "cnt : 3647\n",
            "cnt : 3648\n",
            "cnt : 3649\n",
            "cnt : 3650\n",
            "cnt : 3651\n",
            "cnt : 3652\n",
            "cnt : 3653\n",
            "cnt : 3654\n",
            "cnt : 3655\n",
            "cnt : 3656\n",
            "cnt : 3657\n",
            "cnt : 3658\n",
            "cnt : 3659\n",
            "cnt : 3660\n",
            "cnt : 3661\n",
            "cnt : 3662\n",
            "cnt : 3663\n",
            "cnt : 3664\n",
            "cnt : 3665\n",
            "cnt : 3666\n",
            "cnt : 3667\n",
            "cnt : 3668\n",
            "cnt : 3669\n",
            "cnt : 3670\n",
            "cnt : 3671\n",
            "cnt : 3672\n",
            "cnt : 3673\n",
            "cnt : 3674\n",
            "cnt : 3675\n",
            "cnt : 3676\n",
            "cnt : 3677\n",
            "cnt : 3678\n",
            "cnt : 3679\n",
            "cnt : 3680\n",
            "cnt : 3681\n",
            "cnt : 3682\n",
            "cnt : 3683\n",
            "cnt : 3684\n",
            "cnt : 3685\n",
            "cnt : 3686\n",
            "cnt : 3687\n",
            "cnt : 3688\n",
            "cnt : 3689\n",
            "cnt : 3690\n",
            "cnt : 3691\n",
            "cnt : 3692\n",
            "cnt : 3693\n",
            "cnt : 3694\n",
            "cnt : 3695\n",
            "cnt : 3696\n",
            "cnt : 3697\n",
            "cnt : 3698\n",
            "cnt : 3699\n",
            "cnt : 3700\n",
            "cnt : 3701\n",
            "cnt : 3702\n",
            "cnt : 3703\n",
            "cnt : 3704\n",
            "cnt : 3705\n",
            "cnt : 3706\n",
            "cnt : 3707\n",
            "cnt : 3708\n",
            "cnt : 3709\n",
            "cnt : 3710\n",
            "cnt : 3711\n",
            "cnt : 3712\n",
            "cnt : 3713\n",
            "cnt : 3714\n",
            "cnt : 3715\n",
            "cnt : 3716\n",
            "cnt : 3717\n",
            "cnt : 3718\n",
            "cnt : 3719\n",
            "cnt : 3720\n",
            "cnt : 3721\n",
            "cnt : 3722\n",
            "cnt : 3723\n",
            "cnt : 3724\n",
            "cnt : 3725\n",
            "cnt : 3726\n",
            "cnt : 3727\n",
            "cnt : 3728\n",
            "cnt : 3729\n",
            "cnt : 3730\n",
            "cnt : 3731\n",
            "cnt : 3732\n",
            "cnt : 3733\n",
            "cnt : 3734\n",
            "cnt : 3735\n",
            "cnt : 3736\n",
            "cnt : 3737\n",
            "cnt : 3738\n",
            "cnt : 3739\n",
            "cnt : 3740\n",
            "cnt : 3741\n",
            "cnt : 3742\n",
            "cnt : 3743\n",
            "cnt : 3744\n",
            "cnt : 3745\n",
            "cnt : 3746\n",
            "cnt : 3747\n",
            "cnt : 3748\n",
            "cnt : 3749\n",
            "cnt : 3750\n",
            "cnt : 3751\n",
            "cnt : 3752\n",
            "cnt : 3753\n",
            "cnt : 3754\n",
            "cnt : 3755\n",
            "cnt : 3756\n",
            "cnt : 3757\n",
            "cnt : 3758\n",
            "cnt : 3759\n",
            "cnt : 3760\n",
            "cnt : 3761\n",
            "cnt : 3762\n",
            "cnt : 3763\n",
            "cnt : 3764\n",
            "cnt : 3765\n",
            "cnt : 3766\n",
            "cnt : 3767\n",
            "cnt : 3768\n",
            "cnt : 3769\n",
            "cnt : 3770\n",
            "cnt : 3771\n",
            "cnt : 3772\n",
            "cnt : 3773\n",
            "cnt : 3774\n",
            "cnt : 3775\n",
            "cnt : 3776\n",
            "cnt : 3777\n",
            "cnt : 3778\n",
            "cnt : 3779\n",
            "cnt : 3780\n",
            "cnt : 3781\n",
            "cnt : 3782\n",
            "cnt : 3783\n",
            "cnt : 3784\n",
            "cnt : 3785\n",
            "cnt : 3786\n",
            "cnt : 3787\n",
            "cnt : 3788\n",
            "cnt : 3789\n",
            "cnt : 3790\n",
            "cnt : 3791\n",
            "cnt : 3792\n",
            "cnt : 3793\n",
            "cnt : 3794\n",
            "cnt : 3795\n",
            "cnt : 3796\n",
            "cnt : 3797\n",
            "cnt : 3798\n",
            "cnt : 3799\n",
            "cnt : 3800\n",
            "cnt : 3801\n",
            "cnt : 3802\n",
            "cnt : 3803\n",
            "cnt : 3804\n",
            "cnt : 3805\n",
            "cnt : 3806\n",
            "cnt : 3807\n",
            "cnt : 3808\n",
            "cnt : 3809\n",
            "cnt : 3810\n",
            "cnt : 3811\n",
            "cnt : 3812\n",
            "cnt : 3813\n",
            "cnt : 3814\n",
            "cnt : 3815\n",
            "cnt : 3816\n",
            "cnt : 3817\n",
            "cnt : 3818\n",
            "cnt : 3819\n",
            "cnt : 3820\n",
            "cnt : 3821\n",
            "cnt : 3822\n",
            "cnt : 3823\n",
            "cnt : 3824\n",
            "cnt : 3825\n",
            "cnt : 3826\n",
            "cnt : 3827\n",
            "cnt : 3828\n",
            "cnt : 3829\n",
            "cnt : 3830\n",
            "cnt : 3831\n",
            "cnt : 3832\n",
            "cnt : 3833\n",
            "cnt : 3834\n",
            "cnt : 3835\n",
            "cnt : 3836\n",
            "cnt : 3837\n",
            "cnt : 3838\n",
            "cnt : 3839\n",
            "cnt : 3840\n",
            "cnt : 3841\n",
            "cnt : 3842\n",
            "cnt : 3843\n",
            "cnt : 3844\n",
            "cnt : 3845\n",
            "cnt : 3846\n",
            "cnt : 3847\n",
            "cnt : 3848\n",
            "cnt : 3849\n",
            "cnt : 3850\n",
            "cnt : 3851\n",
            "cnt : 3852\n",
            "cnt : 3853\n",
            "cnt : 3854\n",
            "cnt : 3855\n",
            "cnt : 3856\n",
            "cnt : 3857\n",
            "cnt : 3858\n",
            "cnt : 3859\n",
            "cnt : 3860\n",
            "cnt : 3861\n",
            "cnt : 3862\n",
            "cnt : 3863\n",
            "cnt : 3864\n",
            "cnt : 3865\n",
            "cnt : 3866\n",
            "cnt : 3867\n",
            "cnt : 3868\n",
            "cnt : 3869\n",
            "cnt : 3870\n",
            "cnt : 3871\n",
            "cnt : 3872\n",
            "cnt : 3873\n",
            "cnt : 3874\n",
            "cnt : 3875\n",
            "cnt : 3876\n",
            "cnt : 3877\n",
            "cnt : 3878\n",
            "cnt : 3879\n",
            "cnt : 3880\n",
            "cnt : 3881\n",
            "cnt : 3882\n",
            "cnt : 3883\n",
            "cnt : 3884\n",
            "cnt : 3885\n",
            "cnt : 3886\n",
            "cnt : 3887\n",
            "cnt : 3888\n",
            "cnt : 3889\n",
            "cnt : 3890\n",
            "cnt : 3891\n",
            "cnt : 3892\n",
            "cnt : 3893\n",
            "cnt : 3894\n",
            "cnt : 3895\n",
            "cnt : 3896\n",
            "cnt : 3897\n",
            "cnt : 3898\n",
            "cnt : 3899\n",
            "cnt : 3900\n",
            "cnt : 3901\n",
            "cnt : 3902\n",
            "cnt : 3903\n",
            "cnt : 3904\n",
            "cnt : 3905\n",
            "cnt : 3906\n",
            "cnt : 3907\n",
            "cnt : 3908\n",
            "cnt : 3909\n",
            "cnt : 3910\n",
            "cnt : 3911\n",
            "cnt : 3912\n",
            "cnt : 3913\n",
            "cnt : 3914\n",
            "cnt : 3915\n",
            "cnt : 3916\n",
            "cnt : 3917\n",
            "cnt : 3918\n",
            "cnt : 3919\n",
            "cnt : 3920\n",
            "cnt : 3921\n",
            "cnt : 3922\n",
            "cnt : 3923\n",
            "cnt : 3924\n",
            "cnt : 3925\n",
            "cnt : 3926\n",
            "cnt : 3927\n",
            "cnt : 3928\n",
            "cnt : 3929\n",
            "cnt : 3930\n",
            "cnt : 3931\n",
            "cnt : 3932\n",
            "cnt : 3933\n",
            "cnt : 3934\n",
            "cnt : 3935\n",
            "cnt : 3936\n",
            "cnt : 3937\n",
            "cnt : 3938\n",
            "cnt : 3939\n",
            "cnt : 3940\n",
            "cnt : 3941\n",
            "cnt : 3942\n",
            "cnt : 3943\n",
            "cnt : 3944\n",
            "cnt : 3945\n",
            "cnt : 3946\n",
            "cnt : 3947\n",
            "cnt : 3948\n",
            "cnt : 3949\n",
            "cnt : 3950\n",
            "cnt : 3951\n",
            "cnt : 3952\n",
            "cnt : 3953\n",
            "cnt : 3954\n",
            "cnt : 3955\n",
            "cnt : 3956\n",
            "cnt : 3957\n",
            "cnt : 3958\n",
            "cnt : 3959\n",
            "cnt : 3960\n",
            "cnt : 3961\n",
            "cnt : 3962\n",
            "cnt : 3963\n",
            "cnt : 3964\n",
            "cnt : 3965\n",
            "cnt : 3966\n",
            "cnt : 3967\n",
            "cnt : 3968\n",
            "cnt : 3969\n",
            "cnt : 3970\n",
            "cnt : 3971\n",
            "cnt : 3972\n",
            "cnt : 3973\n",
            "cnt : 3974\n",
            "cnt : 3975\n",
            "cnt : 3976\n",
            "cnt : 3977\n",
            "cnt : 3978\n",
            "cnt : 3979\n",
            "cnt : 3980\n",
            "cnt : 3981\n",
            "cnt : 3982\n",
            "cnt : 3983\n",
            "cnt : 3984\n",
            "cnt : 3985\n",
            "cnt : 3986\n",
            "cnt : 3987\n",
            "cnt : 3988\n",
            "cnt : 3989\n",
            "cnt : 3990\n",
            "cnt : 3991\n",
            "cnt : 3992\n",
            "cnt : 3993\n",
            "cnt : 3994\n",
            "cnt : 3995\n",
            "cnt : 3996\n",
            "cnt : 3997\n",
            "cnt : 3998\n",
            "cnt : 3999\n",
            "cnt : 4000\n",
            "cnt : 4001\n",
            "cnt : 4002\n",
            "cnt : 4003\n",
            "cnt : 4004\n",
            "cnt : 4005\n",
            "cnt : 4006\n",
            "cnt : 4007\n",
            "cnt : 4008\n",
            "cnt : 4009\n",
            "cnt : 4010\n",
            "cnt : 4011\n",
            "cnt : 4012\n",
            "cnt : 4013\n",
            "cnt : 4014\n",
            "cnt : 4015\n",
            "cnt : 4016\n",
            "cnt : 4017\n",
            "cnt : 4018\n",
            "cnt : 4019\n",
            "cnt : 4020\n",
            "cnt : 4021\n",
            "cnt : 4022\n",
            "cnt : 4023\n",
            "cnt : 4024\n",
            "cnt : 4025\n",
            "cnt : 4026\n",
            "cnt : 4027\n",
            "cnt : 4028\n",
            "cnt : 4029\n",
            "cnt : 4030\n",
            "cnt : 4031\n",
            "cnt : 4032\n",
            "cnt : 4033\n",
            "cnt : 4034\n",
            "cnt : 4035\n",
            "cnt : 4036\n",
            "cnt : 4037\n",
            "cnt : 4038\n",
            "cnt : 4039\n",
            "cnt : 4040\n",
            "cnt : 4041\n",
            "cnt : 4042\n",
            "cnt : 4043\n",
            "cnt : 4044\n",
            "cnt : 4045\n",
            "cnt : 4046\n",
            "cnt : 4047\n",
            "cnt : 4048\n",
            "cnt : 4049\n",
            "cnt : 4050\n",
            "cnt : 4051\n",
            "cnt : 4052\n",
            "cnt : 4053\n",
            "cnt : 4054\n",
            "cnt : 4055\n",
            "cnt : 4056\n",
            "cnt : 4057\n",
            "cnt : 4058\n",
            "cnt : 4059\n",
            "cnt : 4060\n",
            "cnt : 4061\n",
            "cnt : 4062\n",
            "cnt : 4063\n",
            "cnt : 4064\n",
            "cnt : 4065\n",
            "cnt : 4066\n",
            "cnt : 4067\n",
            "cnt : 4068\n",
            "cnt : 4069\n",
            "cnt : 4070\n",
            "cnt : 4071\n",
            "cnt : 4072\n",
            "cnt : 4073\n",
            "cnt : 4074\n",
            "cnt : 4075\n",
            "cnt : 4076\n",
            "cnt : 4077\n",
            "cnt : 4078\n",
            "cnt : 4079\n",
            "cnt : 4080\n",
            "cnt : 4081\n",
            "cnt : 4082\n",
            "cnt : 4083\n",
            "cnt : 4084\n",
            "cnt : 4085\n",
            "cnt : 4086\n",
            "cnt : 4087\n",
            "cnt : 4088\n",
            "cnt : 4089\n",
            "cnt : 4090\n",
            "cnt : 4091\n",
            "cnt : 4092\n",
            "cnt : 4093\n",
            "cnt : 4094\n",
            "cnt : 4095\n",
            "cnt : 4096\n",
            "cnt : 4097\n",
            "cnt : 4098\n",
            "cnt : 4099\n",
            "cnt : 4100\n",
            "cnt : 4101\n",
            "cnt : 4102\n",
            "cnt : 4103\n",
            "cnt : 4104\n",
            "cnt : 4105\n",
            "cnt : 4106\n",
            "cnt : 4107\n",
            "cnt : 4108\n",
            "cnt : 4109\n",
            "cnt : 4110\n",
            "cnt : 4111\n",
            "cnt : 4112\n",
            "cnt : 4113\n",
            "cnt : 4114\n",
            "cnt : 4115\n",
            "cnt : 4116\n",
            "cnt : 4117\n",
            "cnt : 4118\n",
            "cnt : 4119\n",
            "cnt : 4120\n",
            "cnt : 4121\n",
            "cnt : 4122\n",
            "cnt : 4123\n",
            "cnt : 4124\n",
            "cnt : 4125\n",
            "cnt : 4126\n",
            "cnt : 4127\n",
            "cnt : 4128\n",
            "cnt : 4129\n",
            "cnt : 4130\n",
            "cnt : 4131\n",
            "cnt : 4132\n",
            "cnt : 4133\n",
            "cnt : 4134\n",
            "cnt : 4135\n",
            "cnt : 4136\n",
            "cnt : 4137\n",
            "cnt : 4138\n",
            "cnt : 4139\n",
            "cnt : 4140\n",
            "cnt : 4141\n",
            "cnt : 4142\n",
            "cnt : 4143\n",
            "cnt : 4144\n",
            "cnt : 4145\n",
            "cnt : 4146\n",
            "cnt : 4147\n",
            "cnt : 4148\n",
            "cnt : 4149\n",
            "cnt : 4150\n",
            "cnt : 4151\n",
            "cnt : 4152\n",
            "cnt : 4153\n",
            "cnt : 4154\n",
            "cnt : 4155\n",
            "cnt : 4156\n",
            "cnt : 4157\n",
            "cnt : 4158\n",
            "cnt : 4159\n",
            "cnt : 4160\n",
            "cnt : 4161\n",
            "cnt : 4162\n",
            "cnt : 4163\n",
            "cnt : 4164\n",
            "cnt : 4165\n",
            "cnt : 4166\n",
            "cnt : 4167\n",
            "cnt : 4168\n",
            "cnt : 4169\n",
            "cnt : 4170\n",
            "cnt : 4171\n",
            "cnt : 4172\n",
            "cnt : 4173\n",
            "cnt : 4174\n",
            "cnt : 4175\n",
            "cnt : 4176\n",
            "cnt : 4177\n",
            "cnt : 4178\n",
            "cnt : 4179\n",
            "cnt : 4180\n",
            "cnt : 4181\n",
            "cnt : 4182\n",
            "cnt : 4183\n",
            "cnt : 4184\n",
            "cnt : 4185\n",
            "cnt : 4186\n",
            "cnt : 4187\n",
            "cnt : 4188\n",
            "cnt : 4189\n",
            "cnt : 4190\n",
            "cnt : 4191\n",
            "cnt : 4192\n",
            "cnt : 4193\n",
            "cnt : 4194\n",
            "cnt : 4195\n",
            "cnt : 4196\n",
            "cnt : 4197\n",
            "cnt : 4198\n",
            "cnt : 4199\n",
            "cnt : 4200\n",
            "cnt : 4201\n",
            "cnt : 4202\n",
            "cnt : 4203\n",
            "cnt : 4204\n",
            "cnt : 4205\n",
            "cnt : 4206\n",
            "cnt : 4207\n",
            "cnt : 4208\n",
            "cnt : 4209\n",
            "cnt : 4210\n",
            "cnt : 4211\n",
            "cnt : 4212\n",
            "cnt : 4213\n",
            "cnt : 4214\n",
            "cnt : 4215\n",
            "cnt : 4216\n",
            "cnt : 4217\n",
            "cnt : 4218\n",
            "cnt : 4219\n",
            "cnt : 4220\n",
            "cnt : 4221\n",
            "cnt : 4222\n",
            "cnt : 4223\n",
            "cnt : 4224\n",
            "cnt : 4225\n",
            "cnt : 4226\n",
            "cnt : 4227\n",
            "cnt : 4228\n",
            "cnt : 4229\n",
            "cnt : 4230\n",
            "cnt : 4231\n",
            "cnt : 4232\n",
            "cnt : 4233\n",
            "cnt : 4234\n",
            "cnt : 4235\n",
            "cnt : 4236\n",
            "cnt : 4237\n",
            "cnt : 4238\n",
            "cnt : 4239\n",
            "cnt : 4240\n",
            "cnt : 4241\n",
            "cnt : 4242\n",
            "cnt : 4243\n",
            "cnt : 4244\n",
            "cnt : 4245\n",
            "cnt : 4246\n",
            "cnt : 4247\n",
            "cnt : 4248\n",
            "cnt : 4249\n",
            "cnt : 4250\n",
            "cnt : 4251\n",
            "cnt : 4252\n",
            "cnt : 4253\n",
            "cnt : 4254\n",
            "cnt : 4255\n",
            "cnt : 4256\n",
            "cnt : 4257\n",
            "cnt : 4258\n",
            "cnt : 4259\n",
            "cnt : 4260\n",
            "cnt : 4261\n",
            "cnt : 4262\n",
            "cnt : 4263\n",
            "cnt : 4264\n",
            "cnt : 4265\n",
            "cnt : 4266\n",
            "cnt : 4267\n",
            "cnt : 4268\n",
            "cnt : 4269\n",
            "cnt : 4270\n",
            "cnt : 4271\n",
            "cnt : 4272\n",
            "cnt : 4273\n",
            "cnt : 4274\n",
            "cnt : 4275\n",
            "cnt : 4276\n",
            "cnt : 4277\n",
            "cnt : 4278\n",
            "cnt : 4279\n",
            "cnt : 4280\n",
            "cnt : 4281\n",
            "cnt : 4282\n",
            "cnt : 4283\n",
            "cnt : 4284\n",
            "cnt : 4285\n",
            "cnt : 4286\n",
            "cnt : 4287\n",
            "cnt : 4288\n",
            "cnt : 4289\n",
            "cnt : 4290\n",
            "cnt : 4291\n",
            "cnt : 4292\n",
            "cnt : 4293\n",
            "cnt : 4294\n",
            "cnt : 4295\n",
            "cnt : 4296\n",
            "cnt : 4297\n",
            "cnt : 4298\n",
            "cnt : 4299\n",
            "cnt : 4300\n",
            "cnt : 4301\n",
            "cnt : 4302\n",
            "cnt : 4303\n",
            "cnt : 4304\n",
            "cnt : 4305\n",
            "cnt : 4306\n",
            "cnt : 4307\n",
            "cnt : 4308\n",
            "cnt : 4309\n",
            "cnt : 4310\n",
            "cnt : 4311\n",
            "cnt : 4312\n",
            "cnt : 4313\n",
            "cnt : 4314\n",
            "cnt : 4315\n",
            "cnt : 4316\n",
            "cnt : 4317\n",
            "cnt : 4318\n",
            "cnt : 4319\n",
            "cnt : 4320\n",
            "cnt : 4321\n",
            "cnt : 4322\n",
            "cnt : 4323\n",
            "cnt : 4324\n",
            "cnt : 4325\n",
            "cnt : 4326\n",
            "cnt : 4327\n",
            "cnt : 4328\n",
            "cnt : 4329\n",
            "cnt : 4330\n",
            "cnt : 4331\n",
            "cnt : 4332\n",
            "cnt : 4333\n",
            "cnt : 4334\n",
            "cnt : 4335\n",
            "cnt : 4336\n",
            "cnt : 4337\n",
            "cnt : 4338\n",
            "cnt : 4339\n",
            "cnt : 4340\n",
            "cnt : 4341\n",
            "cnt : 4342\n",
            "cnt : 4343\n",
            "cnt : 4344\n",
            "cnt : 4345\n",
            "cnt : 4346\n",
            "cnt : 4347\n",
            "cnt : 4348\n",
            "cnt : 4349\n",
            "cnt : 4350\n",
            "cnt : 4351\n",
            "cnt : 4352\n",
            "cnt : 4353\n",
            "cnt : 4354\n",
            "cnt : 4355\n",
            "cnt : 4356\n",
            "cnt : 4357\n",
            "cnt : 4358\n",
            "cnt : 4359\n",
            "cnt : 4360\n",
            "cnt : 4361\n",
            "cnt : 4362\n",
            "cnt : 4363\n",
            "cnt : 4364\n",
            "cnt : 4365\n",
            "cnt : 4366\n",
            "cnt : 4367\n",
            "cnt : 4368\n",
            "cnt : 4369\n",
            "cnt : 4370\n",
            "cnt : 4371\n",
            "cnt : 4372\n",
            "cnt : 4373\n",
            "cnt : 4374\n",
            "cnt : 4375\n",
            "cnt : 4376\n",
            "cnt : 4377\n",
            "cnt : 4378\n",
            "cnt : 4379\n",
            "cnt : 4380\n",
            "cnt : 4381\n",
            "cnt : 4382\n",
            "cnt : 4383\n",
            "cnt : 4384\n",
            "cnt : 4385\n",
            "cnt : 4386\n",
            "cnt : 4387\n",
            "cnt : 4388\n",
            "cnt : 4389\n",
            "cnt : 4390\n",
            "cnt : 4391\n",
            "cnt : 4392\n",
            "cnt : 4393\n",
            "cnt : 4394\n",
            "cnt : 4395\n",
            "cnt : 4396\n",
            "cnt : 4397\n",
            "cnt : 4398\n",
            "cnt : 4399\n",
            "cnt : 4400\n",
            "cnt : 4401\n",
            "cnt : 4402\n",
            "cnt : 4403\n",
            "cnt : 4404\n",
            "cnt : 4405\n",
            "cnt : 4406\n",
            "cnt : 4407\n",
            "cnt : 4408\n",
            "cnt : 4409\n",
            "cnt : 4410\n",
            "cnt : 4411\n",
            "cnt : 4412\n",
            "cnt : 4413\n",
            "cnt : 4414\n",
            "cnt : 4415\n",
            "cnt : 4416\n",
            "cnt : 4417\n",
            "cnt : 4418\n",
            "cnt : 4419\n",
            "cnt : 4420\n",
            "cnt : 4421\n",
            "cnt : 4422\n",
            "cnt : 4423\n",
            "cnt : 4424\n",
            "cnt : 4425\n",
            "cnt : 4426\n",
            "cnt : 4427\n",
            "cnt : 4428\n",
            "cnt : 4429\n",
            "cnt : 4430\n",
            "cnt : 4431\n",
            "cnt : 4432\n",
            "cnt : 4433\n",
            "cnt : 4434\n",
            "cnt : 4435\n",
            "cnt : 4436\n",
            "cnt : 4437\n",
            "cnt : 4438\n",
            "cnt : 4439\n",
            "cnt : 4440\n",
            "cnt : 4441\n",
            "cnt : 4442\n",
            "cnt : 4443\n",
            "cnt : 4444\n",
            "cnt : 4445\n",
            "cnt : 4446\n",
            "cnt : 4447\n",
            "cnt : 4448\n",
            "cnt : 4449\n",
            "cnt : 4450\n",
            "cnt : 4451\n",
            "cnt : 4452\n",
            "cnt : 4453\n",
            "cnt : 4454\n",
            "cnt : 4455\n",
            "cnt : 4456\n",
            "cnt : 4457\n",
            "cnt : 4458\n",
            "cnt : 4459\n",
            "cnt : 4460\n",
            "cnt : 4461\n",
            "cnt : 4462\n",
            "cnt : 4463\n",
            "cnt : 4464\n",
            "cnt : 4465\n",
            "cnt : 4466\n",
            "cnt : 4467\n",
            "cnt : 4468\n",
            "cnt : 4469\n",
            "cnt : 4470\n",
            "cnt : 4471\n",
            "cnt : 4472\n",
            "cnt : 4473\n",
            "cnt : 4474\n",
            "cnt : 4475\n",
            "cnt : 4476\n",
            "cnt : 4477\n",
            "cnt : 4478\n",
            "cnt : 4479\n",
            "cnt : 4480\n",
            "cnt : 4481\n",
            "cnt : 4482\n",
            "cnt : 4483\n",
            "cnt : 4484\n",
            "cnt : 4485\n",
            "cnt : 4486\n",
            "cnt : 4487\n",
            "cnt : 4488\n",
            "cnt : 4489\n",
            "cnt : 4490\n",
            "cnt : 4491\n",
            "cnt : 4492\n",
            "cnt : 4493\n",
            "cnt : 4494\n",
            "cnt : 4495\n",
            "cnt : 4496\n",
            "cnt : 4497\n",
            "cnt : 4498\n",
            "cnt : 4499\n",
            "cnt : 4500\n",
            "cnt : 4501\n",
            "cnt : 4502\n",
            "cnt : 4503\n",
            "cnt : 4504\n",
            "cnt : 4505\n",
            "cnt : 4506\n",
            "cnt : 4507\n",
            "cnt : 4508\n",
            "cnt : 4509\n",
            "cnt : 4510\n",
            "cnt : 4511\n",
            "cnt : 4512\n",
            "cnt : 4513\n",
            "cnt : 4514\n",
            "cnt : 4515\n",
            "cnt : 4516\n",
            "cnt : 4517\n",
            "cnt : 4518\n",
            "cnt : 4519\n",
            "cnt : 4520\n",
            "cnt : 4521\n",
            "cnt : 4522\n",
            "cnt : 4523\n",
            "cnt : 4524\n",
            "cnt : 4525\n",
            "cnt : 4526\n",
            "cnt : 4527\n",
            "cnt : 4528\n",
            "cnt : 4529\n",
            "cnt : 4530\n",
            "cnt : 4531\n",
            "cnt : 4532\n",
            "cnt : 4533\n",
            "cnt : 4534\n",
            "cnt : 4535\n",
            "cnt : 4536\n",
            "cnt : 4537\n",
            "cnt : 4538\n",
            "cnt : 4539\n",
            "cnt : 4540\n",
            "cnt : 4541\n",
            "cnt : 4542\n",
            "cnt : 4543\n",
            "cnt : 4544\n",
            "cnt : 4545\n",
            "cnt : 4546\n",
            "cnt : 4547\n",
            "cnt : 4548\n",
            "cnt : 4549\n",
            "cnt : 4550\n",
            "cnt : 4551\n",
            "cnt : 4552\n",
            "cnt : 4553\n",
            "cnt : 4554\n",
            "cnt : 4555\n",
            "cnt : 4556\n",
            "cnt : 4557\n",
            "cnt : 4558\n",
            "cnt : 4559\n",
            "cnt : 4560\n",
            "cnt : 4561\n",
            "cnt : 4562\n",
            "cnt : 4563\n",
            "cnt : 4564\n",
            "cnt : 4565\n",
            "cnt : 4566\n",
            "cnt : 4567\n",
            "cnt : 4568\n",
            "cnt : 4569\n",
            "cnt : 4570\n",
            "cnt : 4571\n",
            "cnt : 4572\n",
            "cnt : 4573\n",
            "cnt : 4574\n",
            "cnt : 4575\n",
            "cnt : 4576\n",
            "cnt : 4577\n",
            "cnt : 4578\n",
            "cnt : 4579\n",
            "cnt : 4580\n",
            "cnt : 4581\n",
            "cnt : 4582\n",
            "cnt : 4583\n",
            "cnt : 4584\n",
            "cnt : 4585\n",
            "cnt : 4586\n",
            "cnt : 4587\n",
            "cnt : 4588\n",
            "cnt : 4589\n",
            "cnt : 4590\n",
            "cnt : 4591\n",
            "cnt : 4592\n",
            "cnt : 4593\n",
            "cnt : 4594\n",
            "cnt : 4595\n",
            "cnt : 4596\n",
            "cnt : 4597\n",
            "cnt : 4598\n",
            "cnt : 4599\n",
            "cnt : 4600\n",
            "cnt : 4601\n",
            "cnt : 4602\n",
            "cnt : 4603\n",
            "cnt : 4604\n",
            "cnt : 4605\n",
            "cnt : 4606\n",
            "cnt : 4607\n",
            "cnt : 4608\n",
            "cnt : 4609\n",
            "cnt : 4610\n",
            "cnt : 4611\n",
            "cnt : 4612\n",
            "cnt : 4613\n",
            "cnt : 4614\n",
            "cnt : 4615\n",
            "cnt : 4616\n",
            "cnt : 4617\n",
            "cnt : 4618\n",
            "cnt : 4619\n",
            "cnt : 4620\n",
            "cnt : 4621\n",
            "cnt : 4622\n",
            "cnt : 4623\n",
            "cnt : 4624\n",
            "cnt : 4625\n",
            "cnt : 4626\n",
            "cnt : 4627\n",
            "cnt : 4628\n",
            "cnt : 4629\n",
            "cnt : 4630\n",
            "cnt : 4631\n",
            "cnt : 4632\n",
            "cnt : 4633\n",
            "cnt : 4634\n",
            "cnt : 4635\n",
            "cnt : 4636\n",
            "cnt : 4637\n",
            "cnt : 4638\n",
            "cnt : 4639\n",
            "cnt : 4640\n",
            "cnt : 4641\n",
            "cnt : 4642\n",
            "cnt : 4643\n",
            "cnt : 4644\n",
            "cnt : 4645\n",
            "cnt : 4646\n",
            "cnt : 4647\n",
            "cnt : 4648\n",
            "cnt : 4649\n",
            "cnt : 4650\n",
            "cnt : 4651\n",
            "cnt : 4652\n",
            "cnt : 4653\n",
            "cnt : 4654\n",
            "cnt : 4655\n",
            "cnt : 4656\n",
            "cnt : 4657\n",
            "cnt : 4658\n",
            "cnt : 4659\n",
            "cnt : 4660\n",
            "cnt : 4661\n",
            "cnt : 4662\n",
            "cnt : 4663\n",
            "cnt : 4664\n",
            "cnt : 4665\n",
            "cnt : 4666\n",
            "cnt : 4667\n",
            "cnt : 4668\n",
            "cnt : 4669\n",
            "cnt : 4670\n",
            "cnt : 4671\n",
            "cnt : 4672\n",
            "cnt : 4673\n",
            "cnt : 4674\n",
            "cnt : 4675\n",
            "cnt : 4676\n",
            "cnt : 4677\n",
            "cnt : 4678\n",
            "cnt : 4679\n",
            "cnt : 4680\n",
            "cnt : 4681\n",
            "cnt : 4682\n",
            "cnt : 4683\n",
            "cnt : 4684\n",
            "cnt : 4685\n",
            "cnt : 4686\n",
            "cnt : 4687\n",
            "cnt : 4688\n",
            "cnt : 4689\n",
            "cnt : 4690\n",
            "cnt : 4691\n",
            "cnt : 4692\n",
            "cnt : 4693\n",
            "cnt : 4694\n",
            "cnt : 4695\n",
            "cnt : 4696\n",
            "cnt : 4697\n",
            "cnt : 4698\n",
            "cnt : 4699\n",
            "cnt : 4700\n",
            "cnt : 4701\n",
            "cnt : 4702\n",
            "cnt : 4703\n",
            "cnt : 4704\n",
            "cnt : 4705\n",
            "cnt : 4706\n",
            "cnt : 4707\n",
            "cnt : 4708\n",
            "cnt : 4709\n",
            "cnt : 4710\n",
            "cnt : 4711\n",
            "cnt : 4712\n",
            "cnt : 4713\n",
            "cnt : 4714\n",
            "cnt : 4715\n",
            "cnt : 4716\n",
            "cnt : 4717\n",
            "cnt : 4718\n",
            "cnt : 4719\n",
            "cnt : 4720\n",
            "cnt : 4721\n",
            "cnt : 4722\n",
            "cnt : 4723\n",
            "cnt : 4724\n",
            "cnt : 4725\n",
            "cnt : 4726\n",
            "cnt : 4727\n",
            "cnt : 4728\n",
            "cnt : 4729\n",
            "cnt : 4730\n",
            "cnt : 4731\n",
            "cnt : 4732\n",
            "cnt : 4733\n",
            "cnt : 4734\n",
            "cnt : 4735\n",
            "cnt : 4736\n",
            "cnt : 4737\n",
            "cnt : 4738\n",
            "cnt : 4739\n",
            "cnt : 4740\n",
            "cnt : 4741\n",
            "cnt : 4742\n",
            "cnt : 4743\n",
            "cnt : 4744\n",
            "cnt : 4745\n",
            "cnt : 4746\n",
            "cnt : 4747\n",
            "cnt : 4748\n",
            "cnt : 4749\n",
            "cnt : 4750\n",
            "cnt : 4751\n",
            "cnt : 4752\n",
            "cnt : 4753\n",
            "cnt : 4754\n",
            "cnt : 4755\n",
            "cnt : 4756\n",
            "cnt : 4757\n",
            "cnt : 4758\n",
            "cnt : 4759\n",
            "cnt : 4760\n",
            "cnt : 4761\n",
            "cnt : 4762\n",
            "cnt : 4763\n",
            "cnt : 4764\n",
            "cnt : 4765\n",
            "cnt : 4766\n",
            "cnt : 4767\n",
            "cnt : 4768\n",
            "cnt : 4769\n",
            "cnt : 4770\n",
            "cnt : 4771\n",
            "cnt : 4772\n",
            "cnt : 4773\n",
            "cnt : 4774\n",
            "cnt : 4775\n",
            "cnt : 4776\n",
            "cnt : 4777\n",
            "cnt : 4778\n",
            "cnt : 4779\n",
            "cnt : 4780\n",
            "cnt : 4781\n",
            "cnt : 4782\n",
            "cnt : 4783\n",
            "cnt : 4784\n",
            "cnt : 4785\n",
            "cnt : 4786\n",
            "cnt : 4787\n",
            "cnt : 4788\n",
            "cnt : 4789\n",
            "cnt : 4790\n",
            "cnt : 4791\n",
            "cnt : 4792\n",
            "cnt : 4793\n",
            "cnt : 4794\n",
            "cnt : 4795\n",
            "cnt : 4796\n",
            "cnt : 4797\n",
            "cnt : 4798\n",
            "cnt : 4799\n",
            "cnt : 4800\n",
            "cnt : 4801\n",
            "cnt : 4802\n",
            "cnt : 4803\n",
            "cnt : 4804\n",
            "cnt : 4805\n",
            "cnt : 4806\n",
            "cnt : 4807\n",
            "cnt : 4808\n",
            "cnt : 4809\n",
            "cnt : 4810\n",
            "cnt : 4811\n",
            "cnt : 4812\n",
            "cnt : 4813\n",
            "cnt : 4814\n",
            "cnt : 4815\n",
            "cnt : 4816\n",
            "cnt : 4817\n",
            "cnt : 4818\n",
            "cnt : 4819\n",
            "cnt : 4820\n",
            "cnt : 4821\n",
            "cnt : 4822\n",
            "cnt : 4823\n",
            "cnt : 4824\n",
            "cnt : 4825\n",
            "cnt : 4826\n",
            "cnt : 4827\n",
            "cnt : 4828\n",
            "cnt : 4829\n",
            "cnt : 4830\n",
            "cnt : 4831\n",
            "cnt : 4832\n",
            "cnt : 4833\n",
            "cnt : 4834\n",
            "cnt : 4835\n",
            "cnt : 4836\n",
            "cnt : 4837\n",
            "cnt : 4838\n",
            "cnt : 4839\n",
            "cnt : 4840\n",
            "cnt : 4841\n",
            "cnt : 4842\n",
            "cnt : 4843\n",
            "cnt : 4844\n",
            "cnt : 4845\n",
            "cnt : 4846\n",
            "cnt : 4847\n",
            "cnt : 4848\n",
            "cnt : 4849\n",
            "cnt : 4850\n",
            "cnt : 4851\n",
            "cnt : 4852\n",
            "cnt : 4853\n",
            "cnt : 4854\n",
            "cnt : 4855\n",
            "cnt : 4856\n",
            "cnt : 4857\n",
            "cnt : 4858\n",
            "cnt : 4859\n",
            "cnt : 4860\n",
            "cnt : 4861\n",
            "cnt : 4862\n",
            "cnt : 4863\n",
            "cnt : 4864\n",
            "cnt : 4865\n",
            "cnt : 4866\n",
            "cnt : 4867\n",
            "cnt : 4868\n",
            "cnt : 4869\n",
            "cnt : 4870\n",
            "cnt : 4871\n",
            "cnt : 4872\n",
            "cnt : 4873\n",
            "cnt : 4874\n",
            "cnt : 4875\n",
            "cnt : 4876\n",
            "cnt : 4877\n",
            "cnt : 4878\n",
            "cnt : 4879\n",
            "cnt : 4880\n",
            "cnt : 4881\n",
            "cnt : 4882\n",
            "cnt : 4883\n",
            "cnt : 4884\n",
            "cnt : 4885\n",
            "cnt : 4886\n",
            "cnt : 4887\n",
            "cnt : 4888\n",
            "cnt : 4889\n",
            "cnt : 4890\n",
            "cnt : 4891\n",
            "cnt : 4892\n",
            "cnt : 4893\n",
            "cnt : 4894\n",
            "cnt : 4895\n",
            "cnt : 4896\n",
            "cnt : 4897\n",
            "cnt : 4898\n",
            "cnt : 4899\n",
            "cnt : 4900\n",
            "cnt : 4901\n",
            "cnt : 4902\n",
            "cnt : 4903\n",
            "cnt : 4904\n",
            "cnt : 4905\n",
            "cnt : 4906\n",
            "cnt : 4907\n",
            "cnt : 4908\n",
            "cnt : 4909\n",
            "cnt : 4910\n",
            "cnt : 4911\n",
            "cnt : 4912\n",
            "cnt : 4913\n",
            "cnt : 4914\n",
            "cnt : 4915\n",
            "cnt : 4916\n",
            "cnt : 4917\n",
            "cnt : 4918\n",
            "cnt : 4919\n",
            "cnt : 4920\n",
            "cnt : 4921\n",
            "cnt : 4922\n",
            "cnt : 4923\n",
            "cnt : 4924\n",
            "cnt : 4925\n",
            "cnt : 4926\n",
            "cnt : 4927\n",
            "cnt : 4928\n",
            "cnt : 4929\n",
            "cnt : 4930\n",
            "cnt : 4931\n",
            "cnt : 4932\n",
            "cnt : 4933\n",
            "cnt : 4934\n",
            "cnt : 4935\n",
            "cnt : 4936\n",
            "cnt : 4937\n",
            "cnt : 4938\n",
            "cnt : 4939\n",
            "cnt : 4940\n",
            "cnt : 4941\n",
            "cnt : 4942\n",
            "cnt : 4943\n",
            "cnt : 4944\n",
            "cnt : 4945\n",
            "cnt : 4946\n",
            "cnt : 4947\n",
            "cnt : 4948\n",
            "cnt : 4949\n",
            "cnt : 4950\n",
            "cnt : 4951\n",
            "cnt : 4952\n",
            "cnt : 4953\n",
            "cnt : 4954\n",
            "cnt : 4955\n",
            "cnt : 4956\n",
            "cnt : 4957\n",
            "cnt : 4958\n",
            "cnt : 4959\n",
            "cnt : 4960\n",
            "cnt : 4961\n",
            "cnt : 4962\n",
            "cnt : 4963\n",
            "cnt : 4964\n",
            "cnt : 4965\n",
            "cnt : 4966\n",
            "cnt : 4967\n",
            "cnt : 4968\n",
            "cnt : 4969\n",
            "cnt : 4970\n",
            "cnt : 4971\n",
            "cnt : 4972\n",
            "cnt : 4973\n",
            "cnt : 4974\n",
            "cnt : 4975\n",
            "cnt : 4976\n",
            "cnt : 4977\n",
            "cnt : 4978\n",
            "cnt : 4979\n",
            "cnt : 4980\n",
            "cnt : 4981\n",
            "cnt : 4982\n",
            "cnt : 4983\n",
            "cnt : 4984\n",
            "cnt : 4985\n",
            "cnt : 4986\n",
            "cnt : 4987\n",
            "cnt : 4988\n",
            "cnt : 4989\n",
            "cnt : 4990\n",
            "cnt : 4991\n",
            "cnt : 4992\n",
            "cnt : 4993\n",
            "cnt : 4994\n",
            "cnt : 4995\n",
            "cnt : 4996\n",
            "cnt : 4997\n",
            "cnt : 4998\n",
            "cnt : 4999\n",
            "len(all_query_ids) : 8000\n",
            "len(all_queries) : 8000\n",
            "len(all_document_ids) : 8000\n",
            "len(all_documents) : 8000\n",
            "len(all_labels) : 8000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import sys\n",
        "\n",
        "csv.field_size_limit(sys.maxsize)\n",
        "\n",
        "\n",
        "fw1 = open(\"/content/drive/MyDrive/collectionandqueries/all_query_ids.tsv\", \"w\")\n",
        "fw2 = open(\"/content/drive/MyDrive/collectionandqueries/all_queries.tsv\", \"w\")\n",
        "fw3 = open(\"/content/drive/MyDrive/collectionandqueries/all_document_ids.tsv\", \"w\")\n",
        "fw4 = open(\"/content/drive/MyDrive/collectionandqueries/all_documents.tsv\", \"w\")\n",
        "fw5 = open(\"/content/drive/MyDrive/collectionandqueries/all_labels.tsv\", \"w\")\n",
        "\n",
        "output_file1 = csv.writer(fw1, delimiter = \"\\t\")\n",
        "output_file2 = csv.writer(fw2, delimiter = \"\\t\")\n",
        "output_file3 = csv.writer(fw3, delimiter = \"\\t\")\n",
        "output_file4 = csv.writer(fw4, delimiter = \"\\t\")\n",
        "output_file5 = csv.writer(fw5, delimiter = \"\\t\")\n",
        "\n",
        "index = 0\n",
        "\n",
        "length = len(all_query_ids)\n",
        "print('length : ' + str(length))\n",
        "\n",
        "for index in range(0, length): \n",
        "    try:\n",
        "      output_file1.writerow([all_query_ids[index]])\n",
        "      output_file2.writerow([all_queries[index]])\n",
        "      output_file3.writerow([all_document_ids[index]])\n",
        "      output_file4.writerow([all_documents[index]])\n",
        "      output_file5.writerow([all_labels[index]])\n",
        "      index = index+1\n",
        "    except Exception as e:\n",
        "      print(str(e))\n",
        "print('index : ' + str(index))      "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxwPApmj32St",
        "outputId": "2f7a0702-aa8a-4739-fabf-52d3cfca3023"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length : 8000\n",
            "index : 8000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import sys\n",
        "\n",
        "csv.field_size_limit(sys.maxsize)\n",
        "\n",
        "\n",
        "fr1 = open(\"/content/drive/MyDrive/collectionandqueries/all_query_ids.tsv\", \"r\")\n",
        "fr2 = open(\"/content/drive/MyDrive/collectionandqueries/all_queries.tsv\", \"r\")\n",
        "fr3 = open(\"/content/drive/MyDrive/collectionandqueries/all_document_ids.tsv\", \"r\")\n",
        "fr4 = open(\"/content/drive/MyDrive/collectionandqueries/all_documents.tsv\", \"r\")\n",
        "fr5 = open(\"/content/drive/MyDrive/collectionandqueries/all_labels.tsv\", \"r\")\n",
        "\n",
        "input_file1 = csv.reader(fr1, delimiter = \"\\t\")\n",
        "input_file2 = csv.reader(fr2, delimiter = \"\\t\")\n",
        "input_file3 = csv.reader(fr3, delimiter = \"\\t\")\n",
        "input_file4 = csv.reader(fr4, delimiter = \"\\t\")\n",
        "input_file5 = csv.reader(fr5, delimiter = \"\\t\")\n",
        "\n",
        "count = 0\n",
        "\n",
        "for w in input_file1: \n",
        "    count = count+1\n",
        "\n",
        "print('count1 : ' + str(count))\n",
        "\n",
        "count = 0\n",
        "\n",
        "for w in input_file2: \n",
        "    count = count+1\n",
        "\n",
        "print('count2 : ' + str(count))\n",
        "\n",
        "count = 0\n",
        "\n",
        "for w in input_file3: \n",
        "    count = count+1\n",
        "\n",
        "print('count3 : ' + str(count))\n",
        "\n",
        "count = 0\n",
        "\n",
        "for w in input_file4: \n",
        "    count = count+1\n",
        "\n",
        "print('count4 : ' + str(count))\n",
        "\n",
        "count = 0\n",
        "\n",
        "for w in input_file5: \n",
        "    count = count+1\n",
        "\n",
        "print('count5 : ' + str(count))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYQlx5GO6vQC",
        "outputId": "3b58c1d2-4fea-409c-8fb0-2ceb8e7eae6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count1 : 8000\n",
            "count2 : 8000\n",
            "count3 : 8000\n",
            "count4 : 8000\n",
            "count5 : 8000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "import os\n",
        "\n",
        "pos_neg_ration = 4\n",
        "\n",
        "# Maximal number of training samples we want to use\n",
        "#max_train_samples = 5e4\n",
        "max_train_samples = 25e3\n",
        "\n",
        "### Now we read the MS Marco dataset\n",
        "data_folder = '/content/drive/MyDrive/collectionandqueries/'\n",
        "os.makedirs(data_folder, exist_ok=True)\n",
        "\n",
        "\n",
        "#### Read the corpus files, that contain all the passages. Store them in the corpus dict\n",
        "corpus = {}\n",
        "collection_filepath = os.path.join(data_folder, 'collection.tsv')\n",
        "if not os.path.exists(collection_filepath):\n",
        "    print('collection.tsv not found')\n",
        "\n",
        "with open(collection_filepath, 'r', encoding='utf8') as fIn:\n",
        "    for line in fIn:\n",
        "        pid, passage = line.strip().split(\"\\t\")\n",
        "        corpus[pid] = passage\n",
        "print('len(corpus.keys() : ' + str(len(corpus.keys())))\n",
        "\n",
        "### Read the train queries, store in queries dict\n",
        "queries = {}\n",
        "queries_filepath = os.path.join(data_folder, 'queries.train.tsv')\n",
        "if not os.path.exists(queries_filepath):\n",
        "    print('queries.train.tsv not found')\n",
        "\n",
        "with open(queries_filepath, 'r', encoding='utf8') as fIn:\n",
        "    for line in fIn:\n",
        "        qid, query = line.strip().split(\"\\t\")\n",
        "        queries[qid] = query\n",
        "\n",
        "print('len(queries.keys() : ' + str(len(queries.keys())))\n",
        "\n",
        "### Now we create our training & dev data\n",
        "all_query_ids = []\n",
        "all_queries = []\n",
        "all_document_ids = [] \n",
        "all_labels = []\n",
        "all_documents = []\n",
        "\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "train_samples = []\n",
        "dev_samples = {}\n",
        "\n",
        "# We use 200 random queries from the train set for evaluation during training\n",
        "# Each query has at least one relevant and up to 200 irrelevant (negative) passages\n",
        "num_dev_queries = 200\n",
        "num_max_dev_negatives = 200\n",
        "\n",
        "# msmarco-qidpidtriples.rnd-shuf.train-eval.tsv.gz and msmarco-qidpidtriples.rnd-shuf.train.tsv.gz is a randomly\n",
        "# shuffled version of qidpidtriples.train.full.2.tsv.gz from the MS Marco website\n",
        "# We extracted in the train-eval split 500 random queries that can be used for evaluation during training\n",
        "train_eval_filepath = os.path.join(data_folder, 'msmarco-qidpidtriples.rnd-shuf.train-eval.tsv')\n",
        "if not os.path.exists(train_eval_filepath):\n",
        "    print('msmarco-qidpidtriples.rnd-shuf.train-eval.tsv not found')\n",
        "\n",
        "with open(train_eval_filepath, 'r', encoding='utf8') as fIn:\n",
        "    for line in fIn:\n",
        "        qid, pos_id, neg_id = line.strip().split()\n",
        "\n",
        "        if qid not in dev_samples and len(dev_samples) < num_dev_queries:\n",
        "            dev_samples[qid] = {'query': queries[qid], 'positive': set(), 'negative': set()}\n",
        "\n",
        "        if qid in dev_samples:\n",
        "            dev_samples[qid]['positive'].add(corpus[pos_id])\n",
        "            all_query_ids.append(qid)\n",
        "            all_queries.append(queries[qid])\n",
        "            all_document_ids.append(pos_id)\n",
        "            all_documents.append(corpus([pos_id]))\n",
        "            all_labels.append(1)\n",
        "            \n",
        "\n",
        "            if len(dev_samples[qid]['negative']) < num_max_dev_negatives:\n",
        "                dev_samples[qid]['negative'].add(corpus[neg_id])\n",
        "                all_query_ids.append(qid)\n",
        "                all_queries.append(queries[qid])\n",
        "                all_document_ids.append(neg_id)\n",
        "                all_documents.append(corpus([neg_id]))\n",
        "                all_labels.append(0)\n",
        "                \n",
        "\n",
        "print('len(dev_samples.keys()) : ' + str(len(dev_samples.keys())))\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "\n",
        "# Read our training file\n",
        "train_filepath = os.path.join(data_folder, 'qidpidtriples-subset.train-200K.tsv')\n",
        "if not os.path.exists(train_filepath):\n",
        "    print('qidpidtriples-subset.train-200K.tsv not found')\n",
        "\n",
        "cnt = 0\n",
        "with open(train_filepath, 'r', encoding='utf8') as fIn:\n",
        "    for line in fIn:\n",
        "        qid, pos_id, neg_id = line.strip().split()\n",
        "        #print('cnt : ' + str(cnt))\n",
        "        query = queries[qid]\n",
        "        if (cnt % (pos_neg_ration+1)) == 0:\n",
        "            #print('positive')\n",
        "            passage = corpus[pos_id]\n",
        "            label = 1\n",
        "            all_query_ids.append(qid)\n",
        "            all_queries.append(query)\n",
        "            all_document_ids.append(pos_id)\n",
        "            all_documents.append(passage)\n",
        "            all_labels.append(label)\n",
        "            bm25_passages = bm25.get_top_n(query, original_documents, n=3)\n",
        "            for bm25_passage in bm25_passages:\n",
        "              all_query_ids.append(qid)\n",
        "              all_queries.append(query)\n",
        "              all_document_ids.append(pos_id)\n",
        "              all_documents.append(bm25_passage)\n",
        "              all_labels.append(label)\n",
        "        else:\n",
        "            #print('negative')\n",
        "            passage = corpus[neg_id]\n",
        "            label = 0\n",
        "            all_query_ids.append(qid)\n",
        "            all_queries.append(queries[qid])\n",
        "            all_document_ids.append(neg_id)\n",
        "            all_documents.append(passage)\n",
        "            all_labels.append(label)\n",
        "\n",
        "        #train_samples.append(InputExample(texts=[query, passage], label=label))\n",
        "        cnt += 1\n",
        "\n",
        "        if cnt >= max_train_samples:\n",
        "            break\n",
        "print('len(all_query_ids) : ' + str(len(all_query_ids)))\n",
        "print('len(all_queries) : ' + str(len(all_queries)))\n",
        "print('len(all_document_ids) : ' + str(len(all_document_ids)))\n",
        "print('len(all_documents) : ' + str(len(all_documents)))\n",
        "print('len(all_labels) : ' + str(len(all_labels)))"
      ],
      "metadata": {
        "id": "6AM32-scsIDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_queries, val_queries, train_docs, val_docs, train_labels, val_labels = train_test_split(\n",
        "    all_queries, \n",
        "    all_documents, \n",
        "    all_labels, \n",
        "    test_size=.2\n",
        ")"
      ],
      "metadata": {
        "id": "fTHh7O00SdzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJrhN5Y7oUve",
        "outputId": "66e1c6cc-845d-4b9b-de1a-e84672f504d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (1.3.5)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2022.6)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (1.21.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "vmY-gly2oZk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive/', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcXcdyNNoh6F",
        "outputId": "aedffc75-2afa-44a9-ec22-097553214409"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizerFast\n",
        "\n",
        "model_name = \"google/bert_uncased_L-4_H-512_A-8\"\n",
        "tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
        "\n",
        "train_encodings = tokenizer(train_queries, train_docs, truncation=True, padding='max_length', max_length=128)\n",
        "val_encodings = tokenizer(val_queries, val_docs, truncation=True, padding='max_length', max_length=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "91890ff6b2c54a519272d9902b6db2a7",
            "a00ccb4f22604643b59347d91c9ce603",
            "f8e356d8f4fc41d3881ed99986e76413",
            "302039702de8487aa15e09b9e8a6aa44",
            "c0f70243974947d28f5db021a075daf8",
            "158955bf7a2a472692e2b94c4622d191",
            "2f79f4836ee94e2da0cae601471b64be",
            "7cd78c5fa7234b66a5e47f606ea74ad8",
            "fa8f513f1d894f868238c9c54eb5321b",
            "366b9d58894a4876a80e8c71bdac87cd",
            "7389db67ac434362a78a7324a7013540",
            "a4375929584c45d985c8d9575acb647f",
            "1113fc0ae4134c30be0a1574b0b97487",
            "5c7ebb3ea3f04e4182dde84e44c975a4",
            "2d28b260693d4ad28d7bec55d1f90415",
            "90bee7fbf52b43e6959b58f5f304bf1c",
            "67e0dd78b4fa4b198dde0837f3343375",
            "7877fc239bc346059efc46d4eedced1d",
            "5e72799d96ef4c86bf10ebf3ab2dc78b",
            "67f08704007c4d7db753c45b7a7329c8",
            "00814a4a1ba845159f3665bd4a6e7e0a",
            "efa592a2ab894ba3a4666ce8210e72ce"
          ]
        },
        "id": "J4NsXw96Smzv",
        "outputId": "7a83ed57-e3b3-4beb-a9d9-7b09c3dc0ed0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "91890ff6b2c54a519272d9902b6db2a7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/383 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a4375929584c45d985c8d9575acb647f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "class OurDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = OurDataset(train_encodings, train_labels)\n",
        "val_dataset = OurDataset(val_encodings, val_labels)\n"
      ],
      "metadata": {
        "id": "figoBfkcTKHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158,
          "referenced_widgets": [
            "71a028ad70f344f78de2970e80fcc0bc",
            "98c3a7a0dfd94f6fbcadf01ba8e89afd",
            "37709841d0b64bc39335ef7c5d685d8d",
            "857927423f23472f814abc596854e4de",
            "720949646d5c41cd83a8f9291cbff09f",
            "f839805d55f343ad998f8e59975b899f",
            "2de2e374bb0d4205a55ccd810128372e",
            "c5375b914b1b4f339eafe792bad4eec3",
            "a6ff25f62e714e1cbd926b48f3c901c0",
            "6f391c39f71749c9939399f822242a5b",
            "b00e868ad5e54a0aac13a0f53ea18100"
          ]
        },
        "id": "bdl2aweGTRMY",
        "outputId": "9bf268db-0f94-4bba-ebc9-8c06c868e4ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/116M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "71a028ad70f344f78de2970e80fcc0bc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google/bert_uncased_L-4_H-512_A-8 were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-4_H-512_A-8 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.base_model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "T0kwV5FATcCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install evaluate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-9idx3mgTj_F",
        "outputId": "36f9f28a-01f0-4f91-da12-1759eb709445"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 8.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from evaluate) (4.64.1)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (2022.11.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from evaluate) (1.3.5)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 30.3 MB/s \n",
            "\u001b[?25hCollecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from evaluate) (21.3)\n",
            "Collecting datasets>=2.0.0\n",
            "  Downloading datasets-2.7.1-py3-none-any.whl (451 kB)\n",
            "\u001b[K     |████████████████████████████████| 451 kB 74.8 MB/s \n",
            "\u001b[?25hCollecting xxhash\n",
            "  Downloading xxhash-3.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 75.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.3.6)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.11.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from evaluate) (1.21.6)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (3.8.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.1.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.1.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->evaluate) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (2022.9.24)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 81.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->evaluate) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->evaluate) (1.15.0)\n",
            "Installing collected packages: urllib3, xxhash, responses, multiprocess, datasets, evaluate\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed datasets-2.7.1 evaluate-0.4.0 multiprocess-0.70.14 responses-0.18.0 urllib3-1.25.11 xxhash-3.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install trectools"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8xZHczDo3fd",
        "outputId": "55dd839a-8aee-4ddf-a60b-9306621f8a91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting trectools\n",
            "  Downloading trectools-0.0.49.tar.gz (28 kB)\n",
            "Requirement already satisfied: pandas>=0.15.0 in /usr/local/lib/python3.8/dist-packages (from trectools) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from trectools) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.15 in /usr/local/lib/python3.8/dist-packages (from trectools) (1.0.2)\n",
            "Requirement already satisfied: scipy>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from trectools) (1.7.3)\n",
            "Collecting sarge>=0.1.1\n",
            "  Downloading sarge-0.1.7.post1-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.8/dist-packages (from trectools) (4.9.1)\n",
            "Requirement already satisfied: bs4>=0.0.0.1 in /usr/local/lib/python3.8/dist-packages (from trectools) (0.0.1)\n",
            "Requirement already satisfied: matplotlib>=1.5 in /usr/local/lib/python3.8/dist-packages (from trectools) (3.2.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from bs4>=0.0.0.1->trectools) (4.6.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.5->trectools) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.5->trectools) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.5->trectools) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.5->trectools) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.15.0->trectools) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib>=1.5->trectools) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.15->trectools) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.15->trectools) (1.2.0)\n",
            "Building wheels for collected packages: trectools\n",
            "  Building wheel for trectools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for trectools: filename=trectools-0.0.49-py3-none-any.whl size=27140 sha256=cac2897548db07af7159a2f2daad9c670966cfb5a932b1dd3a19724d6802837f\n",
            "  Stored in directory: /root/.cache/pip/wheels/6a/cd/17/9a6b28af70445d948c97018b43b9181acd2fdd23e115ee2055\n",
            "Successfully built trectools\n",
            "Installing collected packages: sarge, trectools\n",
            "Successfully installed sarge-0.1.7.post1 trectools-0.0.49\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "from sklearn.metrics import ndcg_score\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "import evaluate\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def my_compute_metrics_ndcg(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    print ('predictions : ' + str(predictions))\n",
        "    predictions2 = tf.nn.log_softmax(predictions, axis=-1)\n",
        "    #print(classification_report(labels, predictions))\n",
        "    return ndcg_score(predictions2, labels)\n",
        "\"\"\"\n",
        "\n",
        "def my_compute_metrics_precision(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    metric = evaluate.load(\"precision\")\n",
        "    #print('predictions : ' + str(predictions))\n",
        "    #print('labels : ' + str(labels))\n",
        "    #if task != \"stsb\":\n",
        "    predictions = np.argmax(predictions, axis=-1)\n",
        "    #else:\n",
        "    #predictions = predictions[:]\n",
        "    print(classification_report(labels, predictions))\n",
        "    return metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "\n",
        "# You can define your custom compute_metrics function. It takes an `EvalPrediction` object (a namedtuple with a\n",
        "# predictions and label_ids field) and has to return a dictionary string to float.\n",
        "def compute_metrics2(pred):\n",
        "    \"\"\"\n",
        "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
        "    preds = np.argmax(preds, axis=1)\n",
        "    return metric.compute(predictions=preds, references=p.label_ids)   \n",
        "    \"\"\"\n",
        "    print('pred : ' + str(pred))\n",
        "    # Get the metric function\n",
        "    trec_eval = evaluate.load(\"trec_eval\")\n",
        "    qrel = {}\n",
        "    qids, seen, i = [], {}, 0\n",
        "    for q in val_queries:\n",
        "      if q in seen:\n",
        "        qids.append(seen[q])\n",
        "      else:\n",
        "        seen[q] = i\n",
        "        qids.append(i)\n",
        "        i+=1\n",
        "    qrel={\n",
        "      \"query\": qids,\n",
        "      \"q0\": val_queries,\n",
        "      \"docid\": val_docs,\n",
        "      \"rel\": val_labels\n",
        "    }\n",
        "    run = {\n",
        "      \"query\": qids,\n",
        "      \"q0\": val_queries,\n",
        "      \"docid\": val_docs,\n",
        "      \"rank\": pred[1].tolist(),\n",
        "      \"score\": [max(l) for l in pred[0].tolist()],\n",
        "      \"system\": [\"test\" for i in qids]\n",
        "    }    \n",
        "    results = trec_eval.compute(references=[qrel], predictions=[run]) \n",
        "    return results\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    evaluation_strategy=\"epoch\",     # Evaluation is done at the end of each epoch.\n",
        "    num_train_epochs=20,              # total number of training epochs\n",
        "    per_device_train_batch_size=16,  # batch size per device during training\n",
        "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
        "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    learning_rate=0.00005,\n",
        "    save_total_limit=1,              # limit the total amount of checkpoints. Deletes the older checkpoints.    \n",
        ")\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,                         # the instantiated Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=val_dataset,             # evaluation dataset\n",
        "    compute_metrics = compute_metrics2\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "L5eKH7e_2cNJ",
        "outputId": "c70ba5f0-e5c1-4156-9cff-58ee93c2fecd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 6400\n",
            "  Num Epochs = 20\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 8000\n",
            "  Number of trainable parameters = 1026\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='8000' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [8000/8000 04:09, Epoch 20/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Runid</th>\n",
              "      <th>Num Ret</th>\n",
              "      <th>Num Rel</th>\n",
              "      <th>Num Rel Ret</th>\n",
              "      <th>Num Q</th>\n",
              "      <th>Map</th>\n",
              "      <th>Gm Map</th>\n",
              "      <th>Bpref</th>\n",
              "      <th>Rprec</th>\n",
              "      <th>Recip Rank</th>\n",
              "      <th>P@5</th>\n",
              "      <th>P@10</th>\n",
              "      <th>P@15</th>\n",
              "      <th>P@20</th>\n",
              "      <th>P@30</th>\n",
              "      <th>P@100</th>\n",
              "      <th>P@200</th>\n",
              "      <th>P@500</th>\n",
              "      <th>P@1000</th>\n",
              "      <th>Ndcg@5</th>\n",
              "      <th>Ndcg@10</th>\n",
              "      <th>Ndcg@15</th>\n",
              "      <th>Ndcg@20</th>\n",
              "      <th>Ndcg@30</th>\n",
              "      <th>Ndcg@100</th>\n",
              "      <th>Ndcg@200</th>\n",
              "      <th>Ndcg@500</th>\n",
              "      <th>Ndcg@1000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.324710</td>\n",
              "      <td>test</td>\n",
              "      <td>1600</td>\n",
              "      <td>804</td>\n",
              "      <td>804</td>\n",
              "      <td>1376</td>\n",
              "      <td>0.422824</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000242</td>\n",
              "      <td>0.422723</td>\n",
              "      <td>0.422965</td>\n",
              "      <td>0.116860</td>\n",
              "      <td>0.058430</td>\n",
              "      <td>0.038953</td>\n",
              "      <td>0.029215</td>\n",
              "      <td>0.019477</td>\n",
              "      <td>0.005843</td>\n",
              "      <td>0.002922</td>\n",
              "      <td>0.001169</td>\n",
              "      <td>0.000584</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.363700</td>\n",
              "      <td>0.325363</td>\n",
              "      <td>test</td>\n",
              "      <td>1600</td>\n",
              "      <td>804</td>\n",
              "      <td>804</td>\n",
              "      <td>1376</td>\n",
              "      <td>0.422824</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000242</td>\n",
              "      <td>0.422723</td>\n",
              "      <td>0.422965</td>\n",
              "      <td>0.116860</td>\n",
              "      <td>0.058430</td>\n",
              "      <td>0.038953</td>\n",
              "      <td>0.029215</td>\n",
              "      <td>0.019477</td>\n",
              "      <td>0.005843</td>\n",
              "      <td>0.002922</td>\n",
              "      <td>0.001169</td>\n",
              "      <td>0.000584</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.366500</td>\n",
              "      <td>0.322516</td>\n",
              "      <td>test</td>\n",
              "      <td>1600</td>\n",
              "      <td>804</td>\n",
              "      <td>804</td>\n",
              "      <td>1376</td>\n",
              "      <td>0.422824</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000242</td>\n",
              "      <td>0.422723</td>\n",
              "      <td>0.422965</td>\n",
              "      <td>0.116860</td>\n",
              "      <td>0.058430</td>\n",
              "      <td>0.038953</td>\n",
              "      <td>0.029215</td>\n",
              "      <td>0.019477</td>\n",
              "      <td>0.005843</td>\n",
              "      <td>0.002922</td>\n",
              "      <td>0.001169</td>\n",
              "      <td>0.000584</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.380400</td>\n",
              "      <td>0.321213</td>\n",
              "      <td>test</td>\n",
              "      <td>1600</td>\n",
              "      <td>804</td>\n",
              "      <td>804</td>\n",
              "      <td>1376</td>\n",
              "      <td>0.422824</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000242</td>\n",
              "      <td>0.422723</td>\n",
              "      <td>0.422965</td>\n",
              "      <td>0.116860</td>\n",
              "      <td>0.058430</td>\n",
              "      <td>0.038953</td>\n",
              "      <td>0.029215</td>\n",
              "      <td>0.019477</td>\n",
              "      <td>0.005843</td>\n",
              "      <td>0.002922</td>\n",
              "      <td>0.001169</td>\n",
              "      <td>0.000584</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.368500</td>\n",
              "      <td>0.324815</td>\n",
              "      <td>test</td>\n",
              "      <td>1600</td>\n",
              "      <td>804</td>\n",
              "      <td>804</td>\n",
              "      <td>1376</td>\n",
              "      <td>0.422824</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000242</td>\n",
              "      <td>0.422723</td>\n",
              "      <td>0.422965</td>\n",
              "      <td>0.116860</td>\n",
              "      <td>0.058430</td>\n",
              "      <td>0.038953</td>\n",
              "      <td>0.029215</td>\n",
              "      <td>0.019477</td>\n",
              "      <td>0.005843</td>\n",
              "      <td>0.002922</td>\n",
              "      <td>0.001169</td>\n",
              "      <td>0.000584</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.368500</td>\n",
              "      <td>0.320435</td>\n",
              "      <td>test</td>\n",
              "      <td>1600</td>\n",
              "      <td>804</td>\n",
              "      <td>804</td>\n",
              "      <td>1376</td>\n",
              "      <td>0.422824</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000242</td>\n",
              "      <td>0.422723</td>\n",
              "      <td>0.422965</td>\n",
              "      <td>0.116860</td>\n",
              "      <td>0.058430</td>\n",
              "      <td>0.038953</td>\n",
              "      <td>0.029215</td>\n",
              "      <td>0.019477</td>\n",
              "      <td>0.005843</td>\n",
              "      <td>0.002922</td>\n",
              "      <td>0.001169</td>\n",
              "      <td>0.000584</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.375400</td>\n",
              "      <td>0.321186</td>\n",
              "      <td>test</td>\n",
              "      <td>1600</td>\n",
              "      <td>804</td>\n",
              "      <td>804</td>\n",
              "      <td>1376</td>\n",
              "      <td>0.422824</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000242</td>\n",
              "      <td>0.422723</td>\n",
              "      <td>0.422965</td>\n",
              "      <td>0.116860</td>\n",
              "      <td>0.058430</td>\n",
              "      <td>0.038953</td>\n",
              "      <td>0.029215</td>\n",
              "      <td>0.019477</td>\n",
              "      <td>0.005843</td>\n",
              "      <td>0.002922</td>\n",
              "      <td>0.001169</td>\n",
              "      <td>0.000584</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.380700</td>\n",
              "      <td>0.318820</td>\n",
              "      <td>test</td>\n",
              "      <td>1600</td>\n",
              "      <td>804</td>\n",
              "      <td>804</td>\n",
              "      <td>1376</td>\n",
              "      <td>0.422824</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000242</td>\n",
              "      <td>0.422723</td>\n",
              "      <td>0.422965</td>\n",
              "      <td>0.116860</td>\n",
              "      <td>0.058430</td>\n",
              "      <td>0.038953</td>\n",
              "      <td>0.029215</td>\n",
              "      <td>0.019477</td>\n",
              "      <td>0.005843</td>\n",
              "      <td>0.002922</td>\n",
              "      <td>0.001169</td>\n",
              "      <td>0.000584</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.381900</td>\n",
              "      <td>0.320785</td>\n",
              "      <td>test</td>\n",
              "      <td>1600</td>\n",
              "      <td>804</td>\n",
              "      <td>804</td>\n",
              "      <td>1376</td>\n",
              "      <td>0.422824</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000242</td>\n",
              "      <td>0.422723</td>\n",
              "      <td>0.422965</td>\n",
              "      <td>0.116860</td>\n",
              "      <td>0.058430</td>\n",
              "      <td>0.038953</td>\n",
              "      <td>0.029215</td>\n",
              "      <td>0.019477</td>\n",
              "      <td>0.005843</td>\n",
              "      <td>0.002922</td>\n",
              "      <td>0.001169</td>\n",
              "      <td>0.000584</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.371300</td>\n",
              "      <td>0.320345</td>\n",
              "      <td>test</td>\n",
              "      <td>1600</td>\n",
              "      <td>804</td>\n",
              "      <td>804</td>\n",
              "      <td>1376</td>\n",
              "      <td>0.422824</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000242</td>\n",
              "      <td>0.422723</td>\n",
              "      <td>0.422965</td>\n",
              "      <td>0.116860</td>\n",
              "      <td>0.058430</td>\n",
              "      <td>0.038953</td>\n",
              "      <td>0.029215</td>\n",
              "      <td>0.019477</td>\n",
              "      <td>0.005843</td>\n",
              "      <td>0.002922</td>\n",
              "      <td>0.001169</td>\n",
              "      <td>0.000584</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.371300</td>\n",
              "      <td>0.321372</td>\n",
              "      <td>test</td>\n",
              "      <td>1600</td>\n",
              "      <td>804</td>\n",
              "      <td>804</td>\n",
              "      <td>1376</td>\n",
              "      <td>0.422824</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000242</td>\n",
              "      <td>0.422723</td>\n",
              "      <td>0.422965</td>\n",
              "      <td>0.116860</td>\n",
              "      <td>0.058430</td>\n",
              "      <td>0.038953</td>\n",
              "      <td>0.029215</td>\n",
              "      <td>0.019477</td>\n",
              "      <td>0.005843</td>\n",
              "      <td>0.002922</td>\n",
              "      <td>0.001169</td>\n",
              "      <td>0.000584</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.371800</td>\n",
              "      <td>0.320163</td>\n",
              "      <td>test</td>\n",
              "      <td>1600</td>\n",
              "      <td>804</td>\n",
              "      <td>804</td>\n",
              "      <td>1376</td>\n",
              "      <td>0.422824</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000242</td>\n",
              "      <td>0.422723</td>\n",
              "      <td>0.422965</td>\n",
              "      <td>0.116860</td>\n",
              "      <td>0.058430</td>\n",
              "      <td>0.038953</td>\n",
              "      <td>0.029215</td>\n",
              "      <td>0.019477</td>\n",
              "      <td>0.005843</td>\n",
              "      <td>0.002922</td>\n",
              "      <td>0.001169</td>\n",
              "      <td>0.000584</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.321942</td>\n",
              "      <td>test</td>\n",
              "      <td>1600</td>\n",
              "      <td>804</td>\n",
              "      <td>804</td>\n",
              "      <td>1376</td>\n",
              "      <td>0.422824</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000242</td>\n",
              "      <td>0.422723</td>\n",
              "      <td>0.422965</td>\n",
              "      <td>0.116860</td>\n",
              "      <td>0.058430</td>\n",
              "      <td>0.038953</td>\n",
              "      <td>0.029215</td>\n",
              "      <td>0.019477</td>\n",
              "      <td>0.005843</td>\n",
              "      <td>0.002922</td>\n",
              "      <td>0.001169</td>\n",
              "      <td>0.000584</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.371600</td>\n",
              "      <td>0.319057</td>\n",
              "      <td>test</td>\n",
              "      <td>1600</td>\n",
              "      <td>804</td>\n",
              "      <td>804</td>\n",
              "      <td>1376</td>\n",
              "      <td>0.422824</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000242</td>\n",
              "      <td>0.422723</td>\n",
              "      <td>0.422965</td>\n",
              "      <td>0.116860</td>\n",
              "      <td>0.058430</td>\n",
              "      <td>0.038953</td>\n",
              "      <td>0.029215</td>\n",
              "      <td>0.019477</td>\n",
              "      <td>0.005843</td>\n",
              "      <td>0.002922</td>\n",
              "      <td>0.001169</td>\n",
              "      <td>0.000584</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.372700</td>\n",
              "      <td>0.320343</td>\n",
              "      <td>test</td>\n",
              "      <td>1600</td>\n",
              "      <td>804</td>\n",
              "      <td>804</td>\n",
              "      <td>1376</td>\n",
              "      <td>0.422824</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000242</td>\n",
              "      <td>0.422723</td>\n",
              "      <td>0.422965</td>\n",
              "      <td>0.116860</td>\n",
              "      <td>0.058430</td>\n",
              "      <td>0.038953</td>\n",
              "      <td>0.029215</td>\n",
              "      <td>0.019477</td>\n",
              "      <td>0.005843</td>\n",
              "      <td>0.002922</td>\n",
              "      <td>0.001169</td>\n",
              "      <td>0.000584</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.372700</td>\n",
              "      <td>0.318553</td>\n",
              "      <td>test</td>\n",
              "      <td>1600</td>\n",
              "      <td>804</td>\n",
              "      <td>804</td>\n",
              "      <td>1376</td>\n",
              "      <td>0.422824</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000242</td>\n",
              "      <td>0.422723</td>\n",
              "      <td>0.422965</td>\n",
              "      <td>0.116860</td>\n",
              "      <td>0.058430</td>\n",
              "      <td>0.038953</td>\n",
              "      <td>0.029215</td>\n",
              "      <td>0.019477</td>\n",
              "      <td>0.005843</td>\n",
              "      <td>0.002922</td>\n",
              "      <td>0.001169</td>\n",
              "      <td>0.000584</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.372900</td>\n",
              "      <td>0.319526</td>\n",
              "      <td>test</td>\n",
              "      <td>1600</td>\n",
              "      <td>804</td>\n",
              "      <td>804</td>\n",
              "      <td>1376</td>\n",
              "      <td>0.422824</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000242</td>\n",
              "      <td>0.422723</td>\n",
              "      <td>0.422965</td>\n",
              "      <td>0.116860</td>\n",
              "      <td>0.058430</td>\n",
              "      <td>0.038953</td>\n",
              "      <td>0.029215</td>\n",
              "      <td>0.019477</td>\n",
              "      <td>0.005843</td>\n",
              "      <td>0.002922</td>\n",
              "      <td>0.001169</td>\n",
              "      <td>0.000584</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.364900</td>\n",
              "      <td>0.320190</td>\n",
              "      <td>test</td>\n",
              "      <td>1600</td>\n",
              "      <td>804</td>\n",
              "      <td>804</td>\n",
              "      <td>1376</td>\n",
              "      <td>0.422824</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000242</td>\n",
              "      <td>0.422723</td>\n",
              "      <td>0.422965</td>\n",
              "      <td>0.116860</td>\n",
              "      <td>0.058430</td>\n",
              "      <td>0.038953</td>\n",
              "      <td>0.029215</td>\n",
              "      <td>0.019477</td>\n",
              "      <td>0.005843</td>\n",
              "      <td>0.002922</td>\n",
              "      <td>0.001169</td>\n",
              "      <td>0.000584</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.376300</td>\n",
              "      <td>0.320363</td>\n",
              "      <td>test</td>\n",
              "      <td>1600</td>\n",
              "      <td>804</td>\n",
              "      <td>804</td>\n",
              "      <td>1376</td>\n",
              "      <td>0.422824</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000242</td>\n",
              "      <td>0.422723</td>\n",
              "      <td>0.422965</td>\n",
              "      <td>0.116860</td>\n",
              "      <td>0.058430</td>\n",
              "      <td>0.038953</td>\n",
              "      <td>0.029215</td>\n",
              "      <td>0.019477</td>\n",
              "      <td>0.005843</td>\n",
              "      <td>0.002922</td>\n",
              "      <td>0.001169</td>\n",
              "      <td>0.000584</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.375200</td>\n",
              "      <td>0.320326</td>\n",
              "      <td>test</td>\n",
              "      <td>1600</td>\n",
              "      <td>804</td>\n",
              "      <td>804</td>\n",
              "      <td>1376</td>\n",
              "      <td>0.422824</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000242</td>\n",
              "      <td>0.422723</td>\n",
              "      <td>0.422965</td>\n",
              "      <td>0.116860</td>\n",
              "      <td>0.058430</td>\n",
              "      <td>0.038953</td>\n",
              "      <td>0.029215</td>\n",
              "      <td>0.019477</td>\n",
              "      <td>0.005843</td>\n",
              "      <td>0.002922</td>\n",
              "      <td>0.001169</td>\n",
              "      <td>0.000584</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f5b100d3370>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to ./results/checkpoint-500\n",
            "Configuration saved in ./results/checkpoint-500/config.json\n",
            "Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f5b06366f10>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to ./results/checkpoint-1000\n",
            "Configuration saved in ./results/checkpoint-1000/config.json\n",
            "Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-500] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f5aedf060a0>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to ./results/checkpoint-1500\n",
            "Configuration saved in ./results/checkpoint-1500/config.json\n",
            "Model weights saved in ./results/checkpoint-1500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-1000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f5aecf86e50>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to ./results/checkpoint-2000\n",
            "Configuration saved in ./results/checkpoint-2000/config.json\n",
            "Model weights saved in ./results/checkpoint-2000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-1500] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f5aecc71130>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f5b0dc44f70>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to ./results/checkpoint-2500\n",
            "Configuration saved in ./results/checkpoint-2500/config.json\n",
            "Model weights saved in ./results/checkpoint-2500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-2000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f5bf9a30ee0>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to ./results/checkpoint-3000\n",
            "Configuration saved in ./results/checkpoint-3000/config.json\n",
            "Model weights saved in ./results/checkpoint-3000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-2500] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f5aecc71910>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to ./results/checkpoint-3500\n",
            "Configuration saved in ./results/checkpoint-3500/config.json\n",
            "Model weights saved in ./results/checkpoint-3500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-3000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f5b102a5640>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to ./results/checkpoint-4000\n",
            "Configuration saved in ./results/checkpoint-4000/config.json\n",
            "Model weights saved in ./results/checkpoint-4000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-3500] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f5aecc94ee0>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f5b102a5640>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to ./results/checkpoint-4500\n",
            "Configuration saved in ./results/checkpoint-4500/config.json\n",
            "Model weights saved in ./results/checkpoint-4500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-4000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f5b0dc44f10>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to ./results/checkpoint-5000\n",
            "Configuration saved in ./results/checkpoint-5000/config.json\n",
            "Model weights saved in ./results/checkpoint-5000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-4500] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f5b100d3370>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to ./results/checkpoint-5500\n",
            "Configuration saved in ./results/checkpoint-5500/config.json\n",
            "Model weights saved in ./results/checkpoint-5500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-5000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f5b1007afa0>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to ./results/checkpoint-6000\n",
            "Configuration saved in ./results/checkpoint-6000/config.json\n",
            "Model weights saved in ./results/checkpoint-6000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-5500] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f5b100d3370>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/trectools/trec_eval.py:491: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selection[label] = (selection[\"rel\"]) * selection[\"discount\"]\n",
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f5b10610f40>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to ./results/checkpoint-6500\n",
            "Configuration saved in ./results/checkpoint-6500/config.json\n",
            "Model weights saved in ./results/checkpoint-6500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-6000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f5b100d3370>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to ./results/checkpoint-7000\n",
            "Configuration saved in ./results/checkpoint-7000/config.json\n",
            "Model weights saved in ./results/checkpoint-7000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-6500] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f5b10610f40>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to ./results/checkpoint-7500\n",
            "Configuration saved in ./results/checkpoint-7500/config.json\n",
            "Model weights saved in ./results/checkpoint-7500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-7000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f5b102a5640>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to ./results/checkpoint-8000\n",
            "Configuration saved in ./results/checkpoint-8000/config.json\n",
            "Model weights saved in ./results/checkpoint-8000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-7500] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f5b1062e7f0>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=8000, training_loss=0.37305016326904294, metrics={'train_runtime': 249.9179, 'train_samples_per_second': 512.168, 'train_steps_per_second': 32.011, 'total_flos': 1265589485568000.0, 'train_loss': 0.37305016326904294, 'epoch': 20.0})"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "from sklearn.metrics import ndcg_score\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "import evaluate\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def my_compute_metrics_ndcg(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    print ('predictions : ' + str(predictions))\n",
        "    predictions2 = tf.nn.log_softmax(predictions, axis=-1)\n",
        "    #print(classification_report(labels, predictions))\n",
        "    return ndcg_score(predictions2, labels)\n",
        "\"\"\"\n",
        "\n",
        "def my_compute_metrics_precision(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    metric = evaluate.load(\"precision\")\n",
        "    #print('predictions : ' + str(predictions))\n",
        "    #print('labels : ' + str(labels))\n",
        "    #if task != \"stsb\":\n",
        "    predictions = np.argmax(predictions, axis=-1)\n",
        "    #else:\n",
        "    #predictions = predictions[:]\n",
        "    print(classification_report(labels, predictions))\n",
        "    return metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "\n",
        "# You can define your custom compute_metrics function. It takes an `EvalPrediction` object (a namedtuple with a\n",
        "# predictions and label_ids field) and has to return a dictionary string to float.\n",
        "def compute_metrics2(pred):\n",
        "    \"\"\"\n",
        "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
        "    preds = np.argmax(preds, axis=1)\n",
        "    return metric.compute(predictions=preds, references=p.label_ids)   \n",
        "    \"\"\"\n",
        "    print('pred : ' + str(pred))\n",
        "    # Get the metric function\n",
        "    trec_eval = evaluate.load(\"trec_eval\")\n",
        "    qrel = {}\n",
        "    qids, seen, i = [], {}, 0\n",
        "    for q in val_queries:\n",
        "      if q in seen:\n",
        "        qids.append(seen[q])\n",
        "      else:\n",
        "        seen[q] = i\n",
        "        qids.append(i)\n",
        "        i+=1\n",
        "    qrel={\n",
        "      \"query\": qids,\n",
        "      \"q0\": val_queries,\n",
        "      \"docid\": val_docs,\n",
        "      \"rel\": val_labels\n",
        "    }\n",
        "    run = {\n",
        "      \"query\": qids,\n",
        "      \"q0\": val_queries,\n",
        "      \"docid\": val_docs,\n",
        "      \"rank\": pred[1].tolist(),\n",
        "      \"score\": [max(l) for l in pred[0].tolist()],\n",
        "      \"system\": [\"test\" for i in qids]\n",
        "    }    \n",
        "    results = trec_eval.compute(references=[qrel], predictions=[run]) \n",
        "    return results\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    evaluation_strategy=\"epoch\",     # Evaluation is done at the end of each epoch.\n",
        "    num_train_epochs=20,              # total number of training epochs\n",
        "    per_device_train_batch_size=16,  # batch size per device during training\n",
        "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
        "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    learning_rate=0.05,\n",
        "    save_total_limit=1,              # limit the total amount of checkpoints. Deletes the older checkpoints.    \n",
        ")\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,                         # the instantiated Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=val_dataset,             # evaluation dataset\n",
        "    compute_metrics = compute_metrics2\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BzTifVGu2fs0",
        "outputId": "10f886cd-722b-4293-d3f8-9d7e23bf562e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 6400\n",
            "  Num Epochs = 20\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 8000\n",
            "  Number of trainable parameters = 1026\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2922' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2922/8000 01:28 < 02:33, 33.18 it/s, Epoch 7.30/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Runid</th>\n",
              "      <th>Num Ret</th>\n",
              "      <th>Num Rel</th>\n",
              "      <th>Num Rel Ret</th>\n",
              "      <th>Num Q</th>\n",
              "      <th>Map</th>\n",
              "      <th>Gm Map</th>\n",
              "      <th>Bpref</th>\n",
              "      <th>Rprec</th>\n",
              "      <th>Recip Rank</th>\n",
              "      <th>P@5</th>\n",
              "      <th>P@10</th>\n",
              "      <th>P@15</th>\n",
              "      <th>P@20</th>\n",
              "      <th>P@30</th>\n",
              "      <th>P@100</th>\n",
              "      <th>P@200</th>\n",
              "      <th>P@500</th>\n",
              "      <th>P@1000</th>\n",
              "      <th>Ndcg@5</th>\n",
              "      <th>Ndcg@10</th>\n",
              "      <th>Ndcg@15</th>\n",
              "      <th>Ndcg@20</th>\n",
              "      <th>Ndcg@30</th>\n",
              "      <th>Ndcg@100</th>\n",
              "      <th>Ndcg@200</th>\n",
              "      <th>Ndcg@500</th>\n",
              "      <th>Ndcg@1000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.745925</td>\n",
              "      <td>test</td>\n",
              "      <td>1600</td>\n",
              "      <td>804</td>\n",
              "      <td>804</td>\n",
              "      <td>1376</td>\n",
              "      <td>0.422824</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000242</td>\n",
              "      <td>0.422723</td>\n",
              "      <td>0.422965</td>\n",
              "      <td>0.116860</td>\n",
              "      <td>0.058430</td>\n",
              "      <td>0.038953</td>\n",
              "      <td>0.029215</td>\n",
              "      <td>0.019477</td>\n",
              "      <td>0.005843</td>\n",
              "      <td>0.002922</td>\n",
              "      <td>0.001169</td>\n",
              "      <td>0.000584</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.796600</td>\n",
              "      <td>0.800960</td>\n",
              "      <td>test</td>\n",
              "      <td>1600</td>\n",
              "      <td>804</td>\n",
              "      <td>804</td>\n",
              "      <td>1376</td>\n",
              "      <td>0.422703</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.422723</td>\n",
              "      <td>0.422602</td>\n",
              "      <td>0.116860</td>\n",
              "      <td>0.058430</td>\n",
              "      <td>0.038953</td>\n",
              "      <td>0.029215</td>\n",
              "      <td>0.019477</td>\n",
              "      <td>0.005843</td>\n",
              "      <td>0.002922</td>\n",
              "      <td>0.001169</td>\n",
              "      <td>0.000584</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.425600</td>\n",
              "      <td>0.959374</td>\n",
              "      <td>test</td>\n",
              "      <td>1600</td>\n",
              "      <td>804</td>\n",
              "      <td>804</td>\n",
              "      <td>1376</td>\n",
              "      <td>0.422905</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000484</td>\n",
              "      <td>0.422723</td>\n",
              "      <td>0.422965</td>\n",
              "      <td>0.116860</td>\n",
              "      <td>0.058430</td>\n",
              "      <td>0.038953</td>\n",
              "      <td>0.029215</td>\n",
              "      <td>0.019477</td>\n",
              "      <td>0.005843</td>\n",
              "      <td>0.002922</td>\n",
              "      <td>0.001169</td>\n",
              "      <td>0.000584</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.565300</td>\n",
              "      <td>2.131054</td>\n",
              "      <td>test</td>\n",
              "      <td>1600</td>\n",
              "      <td>804</td>\n",
              "      <td>804</td>\n",
              "      <td>1376</td>\n",
              "      <td>0.422703</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.422723</td>\n",
              "      <td>0.422602</td>\n",
              "      <td>0.116860</td>\n",
              "      <td>0.058430</td>\n",
              "      <td>0.038953</td>\n",
              "      <td>0.029215</td>\n",
              "      <td>0.019477</td>\n",
              "      <td>0.005843</td>\n",
              "      <td>0.002922</td>\n",
              "      <td>0.001169</td>\n",
              "      <td>0.000584</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.401600</td>\n",
              "      <td>0.763128</td>\n",
              "      <td>test</td>\n",
              "      <td>1600</td>\n",
              "      <td>804</td>\n",
              "      <td>804</td>\n",
              "      <td>1376</td>\n",
              "      <td>0.422703</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.422723</td>\n",
              "      <td>0.422602</td>\n",
              "      <td>0.116860</td>\n",
              "      <td>0.058430</td>\n",
              "      <td>0.038953</td>\n",
              "      <td>0.029215</td>\n",
              "      <td>0.019477</td>\n",
              "      <td>0.005843</td>\n",
              "      <td>0.002922</td>\n",
              "      <td>0.001169</td>\n",
              "      <td>0.000584</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.401600</td>\n",
              "      <td>1.056038</td>\n",
              "      <td>test</td>\n",
              "      <td>1600</td>\n",
              "      <td>804</td>\n",
              "      <td>804</td>\n",
              "      <td>1376</td>\n",
              "      <td>0.422703</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.422723</td>\n",
              "      <td>0.422602</td>\n",
              "      <td>0.116860</td>\n",
              "      <td>0.058430</td>\n",
              "      <td>0.038953</td>\n",
              "      <td>0.029215</td>\n",
              "      <td>0.019477</td>\n",
              "      <td>0.005843</td>\n",
              "      <td>0.002922</td>\n",
              "      <td>0.001169</td>\n",
              "      <td>0.000584</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.346100</td>\n",
              "      <td>0.529254</td>\n",
              "      <td>test</td>\n",
              "      <td>1600</td>\n",
              "      <td>804</td>\n",
              "      <td>804</td>\n",
              "      <td>1376</td>\n",
              "      <td>0.422703</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.422723</td>\n",
              "      <td>0.422602</td>\n",
              "      <td>0.116860</td>\n",
              "      <td>0.058430</td>\n",
              "      <td>0.038953</td>\n",
              "      <td>0.029215</td>\n",
              "      <td>0.019477</td>\n",
              "      <td>0.005843</td>\n",
              "      <td>0.002922</td>\n",
              "      <td>0.001169</td>\n",
              "      <td>0.000584</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f5aec971880>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to ./results/checkpoint-500\n",
            "Configuration saved in ./results/checkpoint-500/config.json\n",
            "Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-8000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f5aecdbe430>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to ./results/checkpoint-1000\n",
            "Configuration saved in ./results/checkpoint-1000/config.json\n",
            "Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-500] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f5aec971880>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to ./results/checkpoint-1500\n",
            "Configuration saved in ./results/checkpoint-1500/config.json\n",
            "Model weights saved in ./results/checkpoint-1500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-1000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f5aecc68ca0>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to ./results/checkpoint-2000\n",
            "Configuration saved in ./results/checkpoint-2000/config.json\n",
            "Model weights saved in ./results/checkpoint-2000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-1500] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f5aecc487c0>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f5aecc68ca0>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to ./results/checkpoint-2500\n",
            "Configuration saved in ./results/checkpoint-2500/config.json\n",
            "Model weights saved in ./results/checkpoint-2500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-2000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f5b06310dc0>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-31ce4b1b7287>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     87\u001b[0m )\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m         )\n\u001b[0;32m-> 1527\u001b[0;31m         return inner_training_loop(\n\u001b[0m\u001b[1;32m   1528\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1775\u001b[0m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1777\u001b[0;31m                 if (\n\u001b[0m\u001b[1;32m   1778\u001b[0m                     \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging_nan_inf_filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1779\u001b[0m                     \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_torch_tpu_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "from sklearn.metrics import ndcg_score\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "import evaluate\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def my_compute_metrics_ndcg(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    print ('predictions : ' + str(predictions))\n",
        "    predictions2 = tf.nn.log_softmax(predictions, axis=-1)\n",
        "    #print(classification_report(labels, predictions))\n",
        "    return ndcg_score(predictions2, labels)\n",
        "\"\"\"\n",
        "\n",
        "def my_compute_metrics_precision(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    metric = evaluate.load(\"precision\")\n",
        "    #print('predictions : ' + str(predictions))\n",
        "    #print('labels : ' + str(labels))\n",
        "    #if task != \"stsb\":\n",
        "    predictions = np.argmax(predictions, axis=-1)\n",
        "    #else:\n",
        "    #predictions = predictions[:]\n",
        "    print(classification_report(labels, predictions))\n",
        "    return metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "\n",
        "# You can define your custom compute_metrics function. It takes an `EvalPrediction` object (a namedtuple with a\n",
        "# predictions and label_ids field) and has to return a dictionary string to float.\n",
        "def compute_metrics2(pred):\n",
        "    \"\"\"\n",
        "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
        "    preds = np.argmax(preds, axis=1)\n",
        "    return metric.compute(predictions=preds, references=p.label_ids)   \n",
        "    \"\"\"\n",
        "    print('pred : ' + str(pred))\n",
        "    # Get the metric function\n",
        "    trec_eval = evaluate.load(\"trec_eval\")\n",
        "    qrel = {}\n",
        "    qids, seen, i = [], {}, 0\n",
        "    for q in val_queries:\n",
        "      if q in seen:\n",
        "        qids.append(seen[q])\n",
        "      else:\n",
        "        seen[q] = i\n",
        "        qids.append(i)\n",
        "        i+=1\n",
        "    qrel={\n",
        "      \"query\": qids,\n",
        "      \"q0\": val_queries,\n",
        "      \"docid\": val_docs,\n",
        "      \"rel\": val_labels\n",
        "    }\n",
        "    run = {\n",
        "      \"query\": qids,\n",
        "      \"q0\": val_queries,\n",
        "      \"docid\": val_docs,\n",
        "      \"rank\": pred[1].tolist(),\n",
        "      \"score\": [max(l) for l in pred[0].tolist()],\n",
        "      \"system\": [\"test\" for i in qids]\n",
        "    }    \n",
        "    results = trec_eval.compute(references=[qrel], predictions=[run]) \n",
        "    return results\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    evaluation_strategy=\"epoch\",     # Evaluation is done at the end of each epoch.\n",
        "    num_train_epochs=20,              # total number of training epochs\n",
        "    per_device_train_batch_size=16,  # batch size per device during training\n",
        "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
        "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    learning_rate=0.005,\n",
        "    save_total_limit=1,              # limit the total amount of checkpoints. Deletes the older checkpoints.    \n",
        ")\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,                         # the instantiated Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=val_dataset,             # evaluation dataset\n",
        "    compute_metrics = compute_metrics2\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gdswcw3O3GLB",
        "outputId": "aa07641b-2751-4dd7-d947-405ff2ef19b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 6400\n",
            "  Num Epochs = 20\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 8000\n",
            "  Number of trainable parameters = 1026\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='8000' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [8000/8000 04:14, Epoch 20/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Runid</th>\n",
              "      <th>Num Ret</th>\n",
              "      <th>Num Rel</th>\n",
              "      <th>Num Rel Ret</th>\n",
              "      <th>Num Q</th>\n",
              "      <th>Map</th>\n",
              "      <th>Gm Map</th>\n",
              "      <th>Bpref</th>\n",
              "      <th>Rprec</th>\n",
              "      <th>Recip Rank</th>\n",
              "      <th>P@5</th>\n",
              "      <th>P@10</th>\n",
              "      <th>P@15</th>\n",
              "      <th>P@20</th>\n",
              "      <th>P@30</th>\n",
              "      <th>P@100</th>\n",
              "      <th>P@200</th>\n",
              "      <th>P@500</th>\n",
              "      <th>P@1000</th>\n",
              "      <th>Ndcg@5</th>\n",
              "      <th>Ndcg@10</th>\n",
              "      <th>Ndcg@15</th>\n",
              "      <th>Ndcg@20</th>\n",
              "      <th>Ndcg@30</th>\n",
              "      <th>Ndcg@100</th>\n",
              "      <th>Ndcg@200</th>\n",
              "      <th>Ndcg@500</th>\n",
              "      <th>Ndcg@1000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.565839</td>\n",
              "      <td>test</td>\n",
              "      <td>1600</td>\n",
              "      <td>804</td>\n",
              "      <td>804</td>\n",
              "      <td>1376</td>\n",
              "      <td>0.422703</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.422723</td>\n",
              "      <td>0.422602</td>\n",
              "      <td>0.116860</td>\n",
              "      <td>0.058430</td>\n",
              "      <td>0.038953</td>\n",
              "      <td>0.029215</td>\n",
              "      <td>0.019477</td>\n",
              "      <td>0.005843</td>\n",
              "      <td>0.002922</td>\n",
              "      <td>0.001169</td>\n",
              "      <td>0.000584</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.788800</td>\n",
              "      <td>0.364319</td>\n",
              "      <td>test</td>\n",
              "      <td>1600</td>\n",
              "      <td>804</td>\n",
              "      <td>804</td>\n",
              "      <td>1376</td>\n",
              "      <td>0.422703</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.422723</td>\n",
              "      <td>0.422602</td>\n",
              "      <td>0.116860</td>\n",
              "      <td>0.058430</td>\n",
              "      <td>0.038953</td>\n",
              "      <td>0.029215</td>\n",
              "      <td>0.019477</td>\n",
              "      <td>0.005843</td>\n",
              "      <td>0.002922</td>\n",
              "      <td>0.001169</td>\n",
              "      <td>0.000584</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.598100</td>\n",
              "      <td>0.401869</td>\n",
              "      <td>test</td>\n",
              "      <td>1600</td>\n",
              "      <td>804</td>\n",
              "      <td>804</td>\n",
              "      <td>1376</td>\n",
              "      <td>0.422703</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.422723</td>\n",
              "      <td>0.422602</td>\n",
              "      <td>0.116860</td>\n",
              "      <td>0.058430</td>\n",
              "      <td>0.038953</td>\n",
              "      <td>0.029215</td>\n",
              "      <td>0.019477</td>\n",
              "      <td>0.005843</td>\n",
              "      <td>0.002922</td>\n",
              "      <td>0.001169</td>\n",
              "      <td>0.000584</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.540900</td>\n",
              "      <td>0.322347</td>\n",
              "      <td>test</td>\n",
              "      <td>1600</td>\n",
              "      <td>804</td>\n",
              "      <td>804</td>\n",
              "      <td>1376</td>\n",
              "      <td>0.422703</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.422723</td>\n",
              "      <td>0.422602</td>\n",
              "      <td>0.116860</td>\n",
              "      <td>0.058430</td>\n",
              "      <td>0.038953</td>\n",
              "      <td>0.029215</td>\n",
              "      <td>0.019477</td>\n",
              "      <td>0.005843</td>\n",
              "      <td>0.002922</td>\n",
              "      <td>0.001169</td>\n",
              "      <td>0.000584</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.470000</td>\n",
              "      <td>0.346175</td>\n",
              "      <td>test</td>\n",
              "      <td>1600</td>\n",
              "      <td>804</td>\n",
              "      <td>804</td>\n",
              "      <td>1376</td>\n",
              "      <td>0.422703</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.422723</td>\n",
              "      <td>0.422602</td>\n",
              "      <td>0.116860</td>\n",
              "      <td>0.058430</td>\n",
              "      <td>0.038953</td>\n",
              "      <td>0.029215</td>\n",
              "      <td>0.019477</td>\n",
              "      <td>0.005843</td>\n",
              "      <td>0.002922</td>\n",
              "      <td>0.001169</td>\n",
              "      <td>0.000584</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.470000</td>\n",
              "      <td>0.322259</td>\n",
              "      <td>test</td>\n",
              "      <td>1600</td>\n",
              "      <td>804</td>\n",
              "      <td>804</td>\n",
              "      <td>1376</td>\n",
              "      <td>0.422703</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.422723</td>\n",
              "      <td>0.422602</td>\n",
              "      <td>0.116860</td>\n",
              "      <td>0.058430</td>\n",
              "      <td>0.038953</td>\n",
              "      <td>0.029215</td>\n",
              "      <td>0.019477</td>\n",
              "      <td>0.005843</td>\n",
              "      <td>0.002922</td>\n",
              "      <td>0.001169</td>\n",
              "      <td>0.000584</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.448700</td>\n",
              "      <td>0.389723</td>\n",
              "      <td>test</td>\n",
              "      <td>1600</td>\n",
              "      <td>804</td>\n",
              "      <td>804</td>\n",
              "      <td>1376</td>\n",
              "      <td>0.422703</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.422723</td>\n",
              "      <td>0.422602</td>\n",
              "      <td>0.116860</td>\n",
              "      <td>0.058430</td>\n",
              "      <td>0.038953</td>\n",
              "      <td>0.029215</td>\n",
              "      <td>0.019477</td>\n",
              "      <td>0.005843</td>\n",
              "      <td>0.002922</td>\n",
              "      <td>0.001169</td>\n",
              "      <td>0.000584</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.446400</td>\n",
              "      <td>0.339509</td>\n",
              "      <td>test</td>\n",
              "      <td>1600</td>\n",
              "      <td>804</td>\n",
              "      <td>804</td>\n",
              "      <td>1376</td>\n",
              "      <td>0.422703</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.422723</td>\n",
              "      <td>0.422602</td>\n",
              "      <td>0.116860</td>\n",
              "      <td>0.058430</td>\n",
              "      <td>0.038953</td>\n",
              "      <td>0.029215</td>\n",
              "      <td>0.019477</td>\n",
              "      <td>0.005843</td>\n",
              "      <td>0.002922</td>\n",
              "      <td>0.001169</td>\n",
              "      <td>0.000584</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.442600</td>\n",
              "      <td>0.323274</td>\n",
              "      <td>test</td>\n",
              "      <td>1600</td>\n",
              "      <td>804</td>\n",
              "      <td>804</td>\n",
              "      <td>1376</td>\n",
              "      <td>0.422703</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.422723</td>\n",
              "      <td>0.422602</td>\n",
              "      <td>0.116860</td>\n",
              "      <td>0.058430</td>\n",
              "      <td>0.038953</td>\n",
              "      <td>0.029215</td>\n",
              "      <td>0.019477</td>\n",
              "      <td>0.005843</td>\n",
              "      <td>0.002922</td>\n",
              "      <td>0.001169</td>\n",
              "      <td>0.000584</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.417900</td>\n",
              "      <td>0.367438</td>\n",
              "      <td>test</td>\n",
              "      <td>1600</td>\n",
              "      <td>804</td>\n",
              "      <td>804</td>\n",
              "      <td>1376</td>\n",
              "      <td>0.422703</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.422723</td>\n",
              "      <td>0.422602</td>\n",
              "      <td>0.116860</td>\n",
              "      <td>0.058430</td>\n",
              "      <td>0.038953</td>\n",
              "      <td>0.029215</td>\n",
              "      <td>0.019477</td>\n",
              "      <td>0.005843</td>\n",
              "      <td>0.002922</td>\n",
              "      <td>0.001169</td>\n",
              "      <td>0.000584</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.417900</td>\n",
              "      <td>0.317531</td>\n",
              "      <td>test</td>\n",
              "      <td>1600</td>\n",
              "      <td>804</td>\n",
              "      <td>804</td>\n",
              "      <td>1376</td>\n",
              "      <td>0.422703</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.422723</td>\n",
              "      <td>0.422602</td>\n",
              "      <td>0.116860</td>\n",
              "      <td>0.058430</td>\n",
              "      <td>0.038953</td>\n",
              "      <td>0.029215</td>\n",
              "      <td>0.019477</td>\n",
              "      <td>0.005843</td>\n",
              "      <td>0.002922</td>\n",
              "      <td>0.001169</td>\n",
              "      <td>0.000584</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.407900</td>\n",
              "      <td>0.316228</td>\n",
              "      <td>test</td>\n",
              "      <td>1600</td>\n",
              "      <td>804</td>\n",
              "      <td>804</td>\n",
              "      <td>1376</td>\n",
              "      <td>0.422703</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.422723</td>\n",
              "      <td>0.422602</td>\n",
              "      <td>0.116860</td>\n",
              "      <td>0.058430</td>\n",
              "      <td>0.038953</td>\n",
              "      <td>0.029215</td>\n",
              "      <td>0.019477</td>\n",
              "      <td>0.005843</td>\n",
              "      <td>0.002922</td>\n",
              "      <td>0.001169</td>\n",
              "      <td>0.000584</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.413100</td>\n",
              "      <td>0.322827</td>\n",
              "      <td>test</td>\n",
              "      <td>1600</td>\n",
              "      <td>804</td>\n",
              "      <td>804</td>\n",
              "      <td>1376</td>\n",
              "      <td>0.422703</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.422723</td>\n",
              "      <td>0.422602</td>\n",
              "      <td>0.116860</td>\n",
              "      <td>0.058430</td>\n",
              "      <td>0.038953</td>\n",
              "      <td>0.029215</td>\n",
              "      <td>0.019477</td>\n",
              "      <td>0.005843</td>\n",
              "      <td>0.002922</td>\n",
              "      <td>0.001169</td>\n",
              "      <td>0.000584</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.392400</td>\n",
              "      <td>0.316206</td>\n",
              "      <td>test</td>\n",
              "      <td>1600</td>\n",
              "      <td>804</td>\n",
              "      <td>804</td>\n",
              "      <td>1376</td>\n",
              "      <td>0.422703</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.422723</td>\n",
              "      <td>0.422602</td>\n",
              "      <td>0.116860</td>\n",
              "      <td>0.058430</td>\n",
              "      <td>0.038953</td>\n",
              "      <td>0.029215</td>\n",
              "      <td>0.019477</td>\n",
              "      <td>0.005843</td>\n",
              "      <td>0.002922</td>\n",
              "      <td>0.001169</td>\n",
              "      <td>0.000584</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.383800</td>\n",
              "      <td>0.306075</td>\n",
              "      <td>test</td>\n",
              "      <td>1600</td>\n",
              "      <td>804</td>\n",
              "      <td>804</td>\n",
              "      <td>1376</td>\n",
              "      <td>0.422703</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.422723</td>\n",
              "      <td>0.422602</td>\n",
              "      <td>0.116860</td>\n",
              "      <td>0.058430</td>\n",
              "      <td>0.038953</td>\n",
              "      <td>0.029215</td>\n",
              "      <td>0.019477</td>\n",
              "      <td>0.005843</td>\n",
              "      <td>0.002922</td>\n",
              "      <td>0.001169</td>\n",
              "      <td>0.000584</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.383800</td>\n",
              "      <td>0.312566</td>\n",
              "      <td>test</td>\n",
              "      <td>1600</td>\n",
              "      <td>804</td>\n",
              "      <td>804</td>\n",
              "      <td>1376</td>\n",
              "      <td>0.422703</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.422723</td>\n",
              "      <td>0.422602</td>\n",
              "      <td>0.116860</td>\n",
              "      <td>0.058430</td>\n",
              "      <td>0.038953</td>\n",
              "      <td>0.029215</td>\n",
              "      <td>0.019477</td>\n",
              "      <td>0.005843</td>\n",
              "      <td>0.002922</td>\n",
              "      <td>0.001169</td>\n",
              "      <td>0.000584</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.390400</td>\n",
              "      <td>0.312923</td>\n",
              "      <td>test</td>\n",
              "      <td>1600</td>\n",
              "      <td>804</td>\n",
              "      <td>804</td>\n",
              "      <td>1376</td>\n",
              "      <td>0.422703</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.422723</td>\n",
              "      <td>0.422602</td>\n",
              "      <td>0.116860</td>\n",
              "      <td>0.058430</td>\n",
              "      <td>0.038953</td>\n",
              "      <td>0.029215</td>\n",
              "      <td>0.019477</td>\n",
              "      <td>0.005843</td>\n",
              "      <td>0.002922</td>\n",
              "      <td>0.001169</td>\n",
              "      <td>0.000584</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.371300</td>\n",
              "      <td>0.309428</td>\n",
              "      <td>test</td>\n",
              "      <td>1600</td>\n",
              "      <td>804</td>\n",
              "      <td>804</td>\n",
              "      <td>1376</td>\n",
              "      <td>0.422703</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.422723</td>\n",
              "      <td>0.422602</td>\n",
              "      <td>0.116860</td>\n",
              "      <td>0.058430</td>\n",
              "      <td>0.038953</td>\n",
              "      <td>0.029215</td>\n",
              "      <td>0.019477</td>\n",
              "      <td>0.005843</td>\n",
              "      <td>0.002922</td>\n",
              "      <td>0.001169</td>\n",
              "      <td>0.000584</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.377400</td>\n",
              "      <td>0.304811</td>\n",
              "      <td>test</td>\n",
              "      <td>1600</td>\n",
              "      <td>804</td>\n",
              "      <td>804</td>\n",
              "      <td>1376</td>\n",
              "      <td>0.422703</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.422723</td>\n",
              "      <td>0.422602</td>\n",
              "      <td>0.116860</td>\n",
              "      <td>0.058430</td>\n",
              "      <td>0.038953</td>\n",
              "      <td>0.029215</td>\n",
              "      <td>0.019477</td>\n",
              "      <td>0.005843</td>\n",
              "      <td>0.002922</td>\n",
              "      <td>0.001169</td>\n",
              "      <td>0.000584</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.373700</td>\n",
              "      <td>0.302947</td>\n",
              "      <td>test</td>\n",
              "      <td>1600</td>\n",
              "      <td>804</td>\n",
              "      <td>804</td>\n",
              "      <td>1376</td>\n",
              "      <td>0.422703</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.422723</td>\n",
              "      <td>0.422602</td>\n",
              "      <td>0.116860</td>\n",
              "      <td>0.058430</td>\n",
              "      <td>0.038953</td>\n",
              "      <td>0.029215</td>\n",
              "      <td>0.019477</td>\n",
              "      <td>0.005843</td>\n",
              "      <td>0.002922</td>\n",
              "      <td>0.001169</td>\n",
              "      <td>0.000584</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "      <td>0.422941</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f5b100caf70>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to ./results/checkpoint-500\n",
            "Configuration saved in ./results/checkpoint-500/config.json\n",
            "Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-2500] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f5b1007ea00>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to ./results/checkpoint-1000\n",
            "Configuration saved in ./results/checkpoint-1000/config.json\n",
            "Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-500] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f5aeceba1f0>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to ./results/checkpoint-1500\n",
            "Configuration saved in ./results/checkpoint-1500/config.json\n",
            "Model weights saved in ./results/checkpoint-1500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-1000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f5aec9fccd0>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to ./results/checkpoint-2000\n",
            "Configuration saved in ./results/checkpoint-2000/config.json\n",
            "Model weights saved in ./results/checkpoint-2000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-1500] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f5aecb9d460>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f5ccaf005b0>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to ./results/checkpoint-2500\n",
            "Configuration saved in ./results/checkpoint-2500/config.json\n",
            "Model weights saved in ./results/checkpoint-2500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-2000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f5b1007e100>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to ./results/checkpoint-3000\n",
            "Configuration saved in ./results/checkpoint-3000/config.json\n",
            "Model weights saved in ./results/checkpoint-3000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-2500] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f5ccaf005b0>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to ./results/checkpoint-3500\n",
            "Configuration saved in ./results/checkpoint-3500/config.json\n",
            "Model weights saved in ./results/checkpoint-3500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-3000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f5aecc79af0>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to ./results/checkpoint-4000\n",
            "Configuration saved in ./results/checkpoint-4000/config.json\n",
            "Model weights saved in ./results/checkpoint-4000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-3500] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f5b06310ee0>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f5b06310d60>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to ./results/checkpoint-4500\n",
            "Configuration saved in ./results/checkpoint-4500/config.json\n",
            "Model weights saved in ./results/checkpoint-4500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-4000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f5b06310ee0>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/trectools/trec_eval.py:491: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selection[label] = (selection[\"rel\"]) * selection[\"discount\"]\n",
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to ./results/checkpoint-5000\n",
            "Configuration saved in ./results/checkpoint-5000/config.json\n",
            "Model weights saved in ./results/checkpoint-5000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-4500] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f5b06310d60>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to ./results/checkpoint-5500\n",
            "Configuration saved in ./results/checkpoint-5500/config.json\n",
            "Model weights saved in ./results/checkpoint-5500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-5000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f5b06310ee0>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to ./results/checkpoint-6000\n",
            "Configuration saved in ./results/checkpoint-6000/config.json\n",
            "Model weights saved in ./results/checkpoint-6000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-5500] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f5b0dc59fa0>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f5aecc4c850>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to ./results/checkpoint-6500\n",
            "Configuration saved in ./results/checkpoint-6500/config.json\n",
            "Model weights saved in ./results/checkpoint-6500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-6000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f5aec7bd340>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to ./results/checkpoint-7000\n",
            "Configuration saved in ./results/checkpoint-7000/config.json\n",
            "Model weights saved in ./results/checkpoint-7000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-6500] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f5aed069970>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to ./results/checkpoint-7500\n",
            "Configuration saved in ./results/checkpoint-7500/config.json\n",
            "Model weights saved in ./results/checkpoint-7500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-7000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f5aec7afe50>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to ./results/checkpoint-8000\n",
            "Configuration saved in ./results/checkpoint-8000/config.json\n",
            "Model weights saved in ./results/checkpoint-8000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-7500] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7f5b10667fa0>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=8000, training_loss=0.4539603137969971, metrics={'train_runtime': 254.1064, 'train_samples_per_second': 503.726, 'train_steps_per_second': 31.483, 'total_flos': 1265589485568000.0, 'train_loss': 0.4539603137969971, 'epoch': 20.0})"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9c4YyJLM2cQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jJauQuuK2cS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HFYlE7tgSlmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vyn9fXZFSlo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z47OAFgjSltc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import csv\n",
        "import pandas as pd\n",
        "\n",
        "csv.field_size_limit(sys.maxsize)\n",
        "\n",
        "fr = open(\"/content/drive/MyDrive/collectionandqueries/qrels.train.tsv\", \"r\")\n",
        "\n",
        "input_file = csv.reader(fr, delimiter = \"\\t\")\n",
        "\n",
        "query_ids = []\n",
        "queries = []\n",
        "document_ids = [] \n",
        "labels = []\n",
        "documents = []\n",
        "\n",
        "count = 0\n",
        "max_count = 5000\n",
        "index = 0\n",
        "\n",
        "for query_id, qo, document_id, relevance in input_file:\n",
        "    if document_id in qrels_doc_ids.keys() and query_id in final_query_ids.keys():  \n",
        "      query_ids.append(query_id)\n",
        "      queries.append(final_query_ids[query_id])\n",
        "      document_ids.append(document_id)\n",
        "      documents.append(qrels_docs[document_id])\n",
        "      labels.append(int(relevance))\n",
        "      count = count + 1\n",
        "      if (count >= max_count):\n",
        "        break\n",
        "print('len(qrels_query_ids) : ' + str(len(query_ids)))\n",
        "print('len(queries) : ' + str(len(queries)))\n",
        "print('len(document_ids) : ' + str(len(document_ids)))\n",
        "print('len(documents) : ' + str(len(documents)))\n",
        "print('len(labels) : ' + str(len(labels)))\n",
        "print('count : ' + str(count))"
      ],
      "metadata": {
        "id": "XWWb9G7xi4p-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tpIqa77-V3ol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9dTMHqXhV3rb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2f702LijV3ua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8QdNz1OTV4Ey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-pretrained-bert"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwKof0zeR0V8",
        "outputId": "d122aa10-1b88-4be4-bdfa-74b2d0c25bdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch-pretrained-bert\n",
            "  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n",
            "\u001b[K     |████████████████████████████████| 123 kB 3.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from pytorch-pretrained-bert) (4.64.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from pytorch-pretrained-bert) (1.21.6)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.26.26-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 15.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from pytorch-pretrained-bert) (1.13.0+cu116)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from pytorch-pretrained-bert) (2022.6.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (4.4.0)\n",
            "Collecting botocore<1.30.0,>=1.29.26\n",
            "  Downloading botocore-1.29.26-py3-none-any.whl (10.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.2 MB 280 kB/s \n",
            "\u001b[?25hCollecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 3.0 MB/s \n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.8/dist-packages (from botocore<1.30.0,>=1.29.26->boto3->pytorch-pretrained-bert) (2.8.2)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.13-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 52.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.26->boto3->pytorch-pretrained-bert) (1.15.0)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 37.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->pytorch-pretrained-bert) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->pytorch-pretrained-bert) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed boto3-1.26.26 botocore-1.29.26 jmespath-1.0.1 pytorch-pretrained-bert-0.6.2 s3transfer-0.6.0 urllib3-1.25.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from pytorch_pretrained_bert import BertTokenizer\n",
        "\n",
        "# Load pre-trained model tokenizer (vocabulary)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IN-De3zV-ch",
        "outputId": "bd2adfab-4a29-4cc0-f098-6d9f3f25c322"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 231508/231508 [00:01<00:00, 151326.99B/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"vocabulary.txt\", 'w') as f:\n",
        "    \n",
        "    # For each token...\n",
        "    for token in tokenizer.vocab.keys():\n",
        "        \n",
        "        # Write it out and escape any unicode characters.            \n",
        "        f.write(token + '\\n')\n"
      ],
      "metadata": {
        "id": "q7zNfyJnWRoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (10,5)\n",
        "\n",
        "# Measure the length of every token in the vocab.\n",
        "token_lengths = [len(token) for token in tokenizer.vocab.keys()]\n",
        "\n",
        "# Plot the number of tokens of each length.\n",
        "sns.countplot(token_lengths)\n",
        "plt.title('Vocab Token Lengths')\n",
        "plt.xlabel('Token Length')\n",
        "plt.ylabel('# of Tokens')\n",
        "\n",
        "print('Maximum token length:', max(token_lengths))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "viTuH_WoXnqY",
        "outputId": "d187e3e4-262c-4e84-e234-f1fa75b32fa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum token length: 18\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1TVA1AOqav57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8OFElThFawBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vjAY_eexawEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CjZhGTpS40o4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "brirupdw40r2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SdRtbBA340u9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o_J65IBt40x8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qVrZja0I4031"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jqHvMDKU406k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wR-CXo4S41C4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bfqISLPI41F4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6WmjvtWP41JB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6e4AMnsf41L5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I_n8VZA641PR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLteqoiOawG9",
        "outputId": "ca77c5e6-566f-4b2e-8a89-a48fa9259d75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 10.2 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 81.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 62.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer,AutoModel, PreTrainedModel,PretrainedConfig\n",
        "from typing import Dict\n",
        "import torch\n",
        "\n",
        "class ColBERTConfig(PretrainedConfig):\n",
        "    model_type = \"ColBERT\"\n",
        "    bert_model: str\n",
        "    compression_dim: int = 768\n",
        "    dropout: float = 0.0\n",
        "    return_vecs: bool = False\n",
        "    trainable: bool = True\n",
        "\n",
        "class ColBERT(PreTrainedModel):\n",
        "    \"\"\"\n",
        "    ColBERT model from: https://arxiv.org/pdf/2004.12832.pdf\n",
        "    We use a dot-product instead of cosine per term (slightly better)\n",
        "    \"\"\"\n",
        "    config_class = ColBERTConfig\n",
        "    base_model_prefix = \"bert_model\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 cfg) -> None:\n",
        "        super().__init__(cfg)\n",
        "        \n",
        "        self.bert_model = AutoModel.from_pretrained(cfg.bert_model)\n",
        "\n",
        "        for p in self.bert_model.parameters():\n",
        "            p.requires_grad = cfg.trainable\n",
        "\n",
        "        self.compressor = torch.nn.Linear(self.bert_model.config.hidden_size, cfg.compression_dim)\n",
        "\n",
        "    def forward(self,\n",
        "                query: Dict[str, torch.LongTensor],\n",
        "                document: Dict[str, torch.LongTensor]):\n",
        "\n",
        "        query_vecs = self.forward_representation(query)\n",
        "        document_vecs = self.forward_representation(document)\n",
        "\n",
        "        score = self.forward_aggregation(query_vecs,document_vecs,query[\"attention_mask\"],document[\"attention_mask\"])\n",
        "        return score\n",
        "\n",
        "    def forward_representation(self,\n",
        "                               tokens,\n",
        "                               sequence_type=None) -> torch.Tensor:\n",
        "        \n",
        "        vecs = self.bert_model(**tokens)[0] # assuming a distilbert model here\n",
        "        vecs = self.compressor(vecs)\n",
        "\n",
        "        # if encoding only, zero-out the mask values so we can compress storage\n",
        "        if sequence_type == \"doc_encode\" or sequence_type == \"query_encode\": \n",
        "            vecs = vecs * tokens[\"tokens\"][\"mask\"].unsqueeze(-1)\n",
        "\n",
        "        return vecs\n",
        "\n",
        "    def forward_aggregation(self,query_vecs, document_vecs,query_mask,document_mask):\n",
        "        \n",
        "        # create initial term-x-term scores (dot-product)\n",
        "        score = torch.bmm(query_vecs, document_vecs.transpose(2,1))\n",
        "\n",
        "        # mask out padding on the doc dimension (mask by -1000, because max should not select those, setting it to 0 might select them)\n",
        "        exp_mask = document_mask.bool().unsqueeze(1).expand(-1,score.shape[1],-1)\n",
        "        score[~exp_mask] = - 10000\n",
        "\n",
        "        # max pooling over document dimension\n",
        "        score = score.max(-1).values\n",
        "\n",
        "        # mask out paddding query values\n",
        "        score[~(query_mask.bool())] = 0\n",
        "\n",
        "        # sum over query values\n",
        "        score = score.sum(-1)\n",
        "\n",
        "        return score\n",
        "\n",
        "#\n",
        "# init the model & tokenizer (using the distilbert tokenizer)\n",
        "#\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\") \n",
        "model = ColBERT.from_pretrained(\"sebastian-hofstaetter/colbert-distilbert-margin_mse-T2-msmarco\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315,
          "referenced_widgets": [
            "d286f79ed8ae479dbc98e1ed1c59f47a",
            "a365d4dfabb64bdea8cd220945213a36",
            "e44a559288254026837cdb1681d4cad1",
            "1ba3c4387a77463c88765de16ba2a8e0",
            "997503bac1c2446f9f3cfdb711aa33c7",
            "110fd9ac470f4f37ab8db2eba7786899",
            "e13b1a5dfc1c4cdb8914b2097056c7c1",
            "d66dc87e563849978362149e1eec1189",
            "ce9e93898b6a47aa8f6205dc12855000",
            "3f7c71bcfbf74983acef4450f706ca6b",
            "86089fade5284cf4a8ccf35d58830600",
            "725ead6763d34f06906e99cbd25d36f0",
            "858b2620103345f1a7405cf0677853c0",
            "a27f4abf5e9a47deb03162fcd8b49564",
            "4e1c1548393a4a759dcce1ed56f8b8db",
            "cb8caf34451a46ba8eb55a6551377496",
            "9859a32d4ee2431e8dc9def3c91bb7ef",
            "0f1b8604df6d4c0dbdb9c0cef38b18df",
            "c840954a29004569b4fd3ba4e1bd9115",
            "ed44b6bca49e4ac4b19d64d28379005b",
            "22b22d6749b643cdaab5b4ba9e9515db",
            "403d972f7fdf4b99affff48ff44d8143",
            "3fe462a7778a44f884f19b56a79e66a4",
            "171c87e133e14742b636f6f6bab32e24",
            "4c1e70fddd3641c4a0fd7845228373b2",
            "396212cfbdd44c72a9b70658ea66c8df",
            "86c21a534d444d76b090d2d90eb577d1",
            "a02ed4f4e03a494c98ada9f7c6a05c15",
            "ff04160d7fa746b696919f7d587cb5b4",
            "8f084b3aa1bf4781ac981e7721824579",
            "2f102b7fb43544bea08f0e0c0a83a45d",
            "836a5eb054ad4388959d064c63e289e1",
            "96ebbd28f7f748daa30ff6ca0b654925",
            "eaebc00e48634c8281a51e4eca46517b",
            "081340ac3a884001855a3767eda5df53",
            "fd594e2d21e647ee9103cee45162b16b",
            "8a3ba10a5d654f6c9c52ed113d455645",
            "acdcef4c7eb0410f89e1e7136dd648dd",
            "9385ce0f002947ed9c892cfad0c6306a",
            "c3ad62e74daa4e0cb7f5f906305722b5",
            "0684c2841deb4857945915ff370e93b6",
            "4fa23f07ff5b4253a97c52979015ed9d",
            "ba6c633560554b23bf6960b82b6f78cb",
            "1221b3f2a3af490da181a5fc53f80aee",
            "f78b551af525452ea87194962198a3a1",
            "bfb45335414c4e2193961151df81e4eb",
            "8ee11febe5884763ba0058a594dd774f",
            "63499531b0c84a299531c991242d8c86",
            "337cf14e8a8f4d4096a66bb936302d4d",
            "e0384ae31b294015a8c7b3afa02280a4",
            "a8dac09b81e546919bcdab6aedeb6208",
            "2af92d2d9a564141bb2c904b7334a25c",
            "107bdd65a3f7437e889ea9b4cda65733",
            "9e8d11dc2a0b42b9a6c869c3b75829ee",
            "daff7805473342299b22190f6be951d7",
            "a9b7e17be6bb495088c44568afddd26a",
            "0e41d50dd71647568275489dcf75b953",
            "0cd4579b6a71411a9bbb8f61ffe7d40f",
            "3f6577417bd744ef836866d0e76fc9cd",
            "f9507591af564d82a0a7de69ce935a1f",
            "033cc8a942ad4cecb985c6f664e5fa08",
            "2826d0789b2248f9b9ea4cb80095f31f",
            "ecafd60720c2477ead9f0fc28035c8ca",
            "8809303a3fbf4d16845db03f82b9478a",
            "ca1026c3d5c8459fa74f965973b0c2c0",
            "25028d1c58664c25a9ca21945ae307e0",
            "6c8a3b9cd8a043b78e778e44879042f1",
            "84fce744e7964f61b293b07b61b231e8",
            "b454276be0c4440dba986f86c64c6f18",
            "5db8ff18ee1640b3ac51f07136a3550f",
            "5b5530e85a5b434e9ec23f4109fa67c0",
            "e39c1d29ebe745d0bb3d39c31c84c441",
            "7136bae3740443c4ab7ffa14267ba153",
            "5c656e8ee0c4459d869a6c0665acb354",
            "c685715ebc7c46358aa570d4eb70fcbb",
            "92d77b1bda9d426f89c84afcc2844b55",
            "9ea97cf32c0947feaaa184462662c310"
          ]
        },
        "id": "f-xqbT-a19a2",
        "outputId": "ae427c50-f9bf-4de3-f166-b13726da19c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d286f79ed8ae479dbc98e1ed1c59f47a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "725ead6763d34f06906e99cbd25d36f0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3fe462a7778a44f884f19b56a79e66a4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eaebc00e48634c8281a51e4eca46517b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/193 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f78b551af525452ea87194962198a3a1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a9b7e17be6bb495088c44568afddd26a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c8a3b9cd8a043b78e778e44879042f1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_projector.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# our relevant example\n",
        "passage1_input = tokenizer(\"We are very happy to show you the 🤗 Transformers library for pre-trained language models. We are helping the community work together towards the goal of advancing NLP 🔥.\",return_tensors=\"pt\")\n",
        "# a non-relevant example\n",
        "passage2_input = tokenizer(\"Hmm I don't like this new movie about transformers that i got from my local library. Those transformers are robots?\",return_tensors=\"pt\")\n",
        "\n",
        "# the user query -> which should give us a better score for the first passage\n",
        "query_input = tokenizer(\"what is the transformers library\")\n",
        "# adding the mask augmentation, we used 8 as the fixed number for training regardless of batch-size\n",
        "# it has a somewhat (although not huge) positive impact on effectiveness, we hypothesize that might be due to the increased\n",
        "# capacity of the query encoding, not so much because of the [MASK] pre-training, but who knows :)\n",
        "query_input.input_ids += [103] * 8 # [MASK]\n",
        "query_input.attention_mask += [1] * 8\n",
        "query_input[\"input_ids\"] = torch.LongTensor(query_input.input_ids).unsqueeze(0)\n",
        "query_input[\"attention_mask\"] = torch.LongTensor(query_input.attention_mask).unsqueeze(0)\n",
        "\n",
        "#print(\"Passage 1 Tokenized:\",passage1_input)\n",
        "#print(\"Passage 2 Tokenized:\",passage2_input)\n",
        "#print(\"Query Tokenized:\",query_input)\n",
        "\n",
        "# note how we call the bert model for pairs, can be changed to: forward_representation and forward_aggregation\n",
        "score_for_p1 = model.forward(query_input,passage1_input).squeeze(0)\n",
        "score_for_p2 = model.forward(query_input,passage2_input).squeeze(0)\n",
        "\n",
        "print(\"---\")\n",
        "print(\"Score passage 1 <-> query: \",float(score_for_p1))\n",
        "print(\"Score passage 2 <-> query: \",float(score_for_p2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMHa9tvH3TUC",
        "outputId": "e5ac1064-da28-47d0-ba93-3ce2c9a6f354"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---\n",
            "Score passage 1 <-> query:  106.46385192871094\n",
            "Score passage 2 <-> query:  99.99707794189453\n"
          ]
        }
      ]
    }
  ]
}