{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SpQp4eDUxqgQ"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RodJ9omsyv30",
        "outputId": "beba1c27-a103-45e2-92bb-40a9582a8b34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive/', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o26EM4yBzMEG",
        "outputId": "a28cb1b3-310c-43e3-d9eb-bd99dea6a163"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: rank_bm25 in /usr/local/lib/python3.8/dist-packages (0.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from rank_bm25) (1.21.6)\n"
          ]
        }
      ],
      "source": [
        "pip install rank_bm25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "emwsqn4hzO7U"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"/content/drive/MyDrive/collectionandqueries/BM25\", 'rb') as f:\n",
        "    # The protocol version used is detected automatically, so we do not\n",
        "    # have to specify it.\n",
        "    bm25 = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFYelXtQHsRD",
        "outputId": "4add6926-7404-4e49-c4bf-c50c2c63fb0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting bertopic\n",
            "  Downloading bertopic-0.12.0-py2.py3-none-any.whl (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 7.4 MB/s \n",
            "\u001b[?25hCollecting umap-learn>=0.5.0\n",
            "  Downloading umap-learn-0.5.3.tar.gz (88 kB)\n",
            "\u001b[K     |████████████████████████████████| 88 kB 9.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: plotly>=4.7.0 in /usr/local/lib/python3.8/dist-packages (from bertopic) (5.5.0)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.8/dist-packages (from bertopic) (1.3.5)\n",
            "Collecting pyyaml<6.0\n",
            "  Downloading PyYAML-5.4.1-cp38-cp38-manylinux1_x86_64.whl (662 kB)\n",
            "\u001b[K     |████████████████████████████████| 662 kB 67.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.41.1 in /usr/local/lib/python3.8/dist-packages (from bertopic) (4.64.1)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.8/dist-packages (from bertopic) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2.post1 in /usr/local/lib/python3.8/dist-packages (from bertopic) (1.0.2)\n",
            "Collecting hdbscan>=0.8.28\n",
            "  Downloading hdbscan-0.8.29.tar.gz (5.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.2 MB 64.0 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sentence-transformers>=0.4.1\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[K     |████████████████████████████████| 85 kB 6.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.8/dist-packages (from hdbscan>=0.8.28->bertopic) (1.2.0)\n",
            "Requirement already satisfied: cython>=0.27 in /usr/local/lib/python3.8/dist-packages (from hdbscan>=0.8.28->bertopic) (0.29.32)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.8/dist-packages (from hdbscan>=0.8.28->bertopic) (1.7.3)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.1.5->bertopic) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.1.5->bertopic) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from plotly>=4.7.0->bertopic) (1.15.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from plotly>=4.7.0->bertopic) (8.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.22.2.post1->bertopic) (3.1.0)\n",
            "Collecting transformers<5.0.0,>=4.6.0\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 71.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from sentence-transformers>=0.4.1->bertopic) (1.13.0+cu116)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (from sentence-transformers>=0.4.1->bertopic) (0.14.0+cu116)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (from sentence-transformers>=0.4.1->bertopic) (3.7)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 50.3 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub>=0.4.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 76.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (4.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (3.0.9)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 69.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (2022.6.2)\n",
            "Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.8/dist-packages (from umap-learn>=0.5.0->bertopic) (0.56.4)\n",
            "Collecting pynndescent>=0.5\n",
            "  Downloading pynndescent-0.5.8.tar.gz (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 65.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from numba>=0.49->umap-learn>=0.5.0->bertopic) (4.13.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba>=0.49->umap-learn>=0.5.0->bertopic) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba>=0.49->umap-learn>=0.5.0->bertopic) (57.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->numba>=0.49->umap-learn>=0.5.0->bertopic) (3.11.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk->sentence-transformers>=0.4.1->bertopic) (7.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (1.24.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision->sentence-transformers>=0.4.1->bertopic) (7.1.2)\n",
            "Building wheels for collected packages: hdbscan, sentence-transformers, umap-learn, pynndescent\n",
            "  Building wheel for hdbscan (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hdbscan: filename=hdbscan-0.8.29-cp38-cp38-linux_x86_64.whl size=2700860 sha256=7ba25d0a6e92cc01256e720bc84664dfd009ae5bbfc33dac01dedca5ef9b6c43\n",
            "  Stored in directory: /root/.cache/pip/wheels/76/06/48/527e038689c581cc9e519c73840efdc7473805149e55bd7ffd\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125938 sha256=96e917733d6ce699ae4ca7fe0715dd2935259fcc751e52145faca32b4ed4b019\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/6f/8c/d88aec621f3f542d26fac0342bef5e693335d125f4e54aeffe\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.3-py3-none-any.whl size=82829 sha256=a9d6bafa8038395f852331dbc50f1921c9d7dd7c904c86b22d496ef3462824b9\n",
            "  Stored in directory: /root/.cache/pip/wheels/a9/3a/67/06a8950e053725912e6a8c42c4a3a241410f6487b8402542ea\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynndescent: filename=pynndescent-0.5.8-py3-none-any.whl size=55513 sha256=4110c8bbe4db9b2e6eaf3549f9713be872c6438e19a3b16a70ac5bf2bc94c0c0\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/63/3a/29954bca1a27ba100ed8c27973a78cb71b43dc67aed62e80c3\n",
            "Successfully built hdbscan sentence-transformers umap-learn pynndescent\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers, sentencepiece, pynndescent, umap-learn, sentence-transformers, hdbscan, bertopic\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0\n",
            "    Uninstalling PyYAML-6.0:\n",
            "      Successfully uninstalled PyYAML-6.0\n",
            "Successfully installed bertopic-0.12.0 hdbscan-0.8.29 huggingface-hub-0.11.1 pynndescent-0.5.8 pyyaml-5.4.1 sentence-transformers-2.2.2 sentencepiece-0.1.97 tokenizers-0.13.2 transformers-4.25.1 umap-learn-0.5.3\n"
          ]
        }
      ],
      "source": [
        "pip install bertopic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "GAnZwaLkIGzO"
      },
      "outputs": [],
      "source": [
        "from bertopic import BERTopic\n",
        "BERT_model_FINAL = BERTopic.load(\"/content/drive/MyDrive/collectionandqueries/20KDocs/qrels_BERT_model_FINAL_preprocessed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "648jVb8lILJ5"
      },
      "outputs": [],
      "source": [
        "from math import log, sqrt\n",
        "ALPHA = 1\n",
        "BETA = 0.75\n",
        "GAMMA = 0.15\n",
        "\n",
        "def generateInvertedIndex(invertedIndex, doc):\n",
        "        line = doc\n",
        "        text = line.strip().split()\n",
        "        for word in text:\n",
        "            if word not in invertedIndex.keys():\n",
        "                invertedIndex[word] = 1\n",
        "            else:\n",
        "                invertedIndex[word] += 1\n",
        "\n",
        "def queryFrequency(query):\n",
        "    queryFreq = {}\n",
        "    for term in query.split():\n",
        "        if term in queryFreq.keys():\n",
        "            queryFreq[term] += 1\n",
        "        else:\n",
        "            queryFreq[term] = 1\n",
        "    return queryFreq\n",
        "\n",
        "def calculateDocsCount(doc, docIndex):\n",
        "    line = doc\n",
        "    text = line.strip().split()\n",
        "    for term in text:\n",
        "      if term in docIndex.keys():\n",
        "        docIndex[term] += 1\n",
        "      else:\n",
        "        docIndex[term] = 1\n",
        "\n",
        "def findDocs(all_docs):\n",
        "    relIndex = {}\n",
        "    k = len(all_docs)\n",
        "    for i in range(0, k):\n",
        "      doc = all_docs[i]\n",
        "      calculateDocsCount(doc, relIndex)\n",
        "    return relIndex\n",
        "\n",
        "def findRelDocMagnitude(docIndex):\n",
        "    mag = 0\n",
        "    for term in docIndex:\n",
        "        mag += float(docIndex[term]**2)\n",
        "        mag = float(sqrt(mag))\n",
        "    return mag\n",
        "\n",
        "def findRocchioScore(term, queryFreq, relDocMag, relIndex):\n",
        "    if(term not in queryFreq.keys()):\n",
        "      queryFreq[term] = 0\n",
        "    if(term not in relIndex.keys()):\n",
        "      relIndex[term] = 0  \n",
        "    rocchioScore = ALPHA * queryFreq[term] + (BETA/relDocMag) * relIndex[term] \n",
        "    return rocchioScore\n",
        "\n",
        "\n",
        "def findNewQuery(query, all_docs):\n",
        "    invertedIndex = {}\n",
        "    for doc in all_docs:\n",
        "      generateInvertedIndex(invertedIndex, doc) \n",
        "    queryFreq = queryFrequency(query)\n",
        "    relIndex = findDocs(all_docs)\n",
        "    relDocMag = findRelDocMagnitude(relIndex)\n",
        "    updatedQuery = {}\n",
        "    newQuery = query\n",
        "    for term in invertedIndex.keys():\n",
        "        updatedQuery[term] = findRocchioScore(term, queryFreq, relDocMag, relIndex)\n",
        "    sortedUpdatedQuery = sorted(updatedQuery.items(), key=lambda x:x[1], reverse=True)\n",
        "    if len(sortedUpdatedQuery)<5:\n",
        "        loopRange = len(sortedUpdatedQuery)\n",
        "    else:\n",
        "        loopRange = 5\n",
        "    for i in range(loopRange):\n",
        "        term,frequency = sortedUpdatedQuery[i]\n",
        "        if term not in query:\n",
        "            newQuery +=  \" \"\n",
        "            newQuery +=  term\n",
        "    return newQuery"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJrjbRN3woOa"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import sys\n",
        "\n",
        "csv.field_size_limit(sys.maxsize)\n",
        "\n",
        "\n",
        "fr6 = open(\"/content/drive/MyDrive/collectionandqueries/all_query_ids.tsv\", \"r\")\n",
        "fr7 = open(\"/content/drive/MyDrive/collectionandqueries/all_queries.tsv\", \"r\")\n",
        "fr8 = open(\"/content/drive/MyDrive/collectionandqueries/all_document_ids.tsv\", \"r\")\n",
        "fr9 = open(\"/content/drive/MyDrive/collectionandqueries/all_documents.tsv\", \"r\")\n",
        "fr10 = open(\"/content/drive/MyDrive/collectionandqueries/all_labels.tsv\", \"r\")\n",
        "\n",
        "input_file1 = csv.reader(fr1, delimiter = \"\\t\")\n",
        "input_file2 = csv.reader(fr2, delimiter = \"\\t\")\n",
        "input_file3 = csv.reader(fr3, delimiter = \"\\t\")\n",
        "input_file4 = csv.reader(fr4, delimiter = \"\\t\")\n",
        "input_file5 = csv.reader(fr5, delimiter = \"\\t\")\n",
        "\n",
        "all_query_ids2 = []\n",
        "all_queries2 = []\n",
        "all_document_ids2 = []\n",
        "all_documents2 = []\n",
        "all_labels2 = []\n",
        "\n",
        "for w in input_file1: \n",
        "    #print('w : ' + str(w[0]))\n",
        "    all_query_ids2.append(w[0])\n",
        "\n",
        "for w in input_file2: \n",
        "    all_queries2.append(w[0])\n",
        "\n",
        "for w in input_file3: \n",
        "    all_document_ids2.append(w[0])\n",
        "\n",
        "for w in input_file4: \n",
        "    all_documents2.append(w[0])\n",
        "\n",
        "for w in input_file5: \n",
        "    all_labels2.append(w[0]) \n",
        "\n",
        "print('len(all_query_ids2) : ' + str(len(all_query_ids2)))\n",
        "print('len(all_queries2) : ' + str(len(all_queries2)))\n",
        "print('len(all_document_ids2) : ' + str(len(all_document_ids2)))\n",
        "print('len(all_documents2) : ' + str(len(all_documents2)))\n",
        "print('len(all_labels2) : ' + str(len(all_labels2)))\n",
        "\n",
        "all_query_ids = []\n",
        "all_queries = []\n",
        "all_document_ids = []\n",
        "all_documents = []\n",
        "all_labels = []\n",
        "\n",
        "length = len(all_query_ids2)\n",
        "index = 0\n",
        "\n",
        "for index in range(0, length): \n",
        "    #print('index : ' + str(index))\n",
        "    all_query_ids.append(all_query_ids2[index])\n",
        "    all_queries.append(all_queries2[index])\n",
        "    all_document_ids.append(all_document_ids2[index])\n",
        "    all_documents.append(all_documents2[index])\n",
        "    all_labels.append(int(all_labels2[index]))\n",
        "    \"\"\"\n",
        "    print('all_query_ids2[index] : ' + all_query_ids2[index])\n",
        "    print('all_queries2[index] : ' + all_queries2[index])\n",
        "    print('all_document_ids2[index] : ' + all_document_ids2[index])\n",
        "    print('all_documents2[index] : ' + all_documents2[index])\n",
        "    print('all_labels2[index] : ' + all_labels2[index])\n",
        "    \"\"\"\n",
        "    \n",
        "    if(int(all_labels2[index])) == 1:\n",
        "      cur_query = all_queries2[index]\n",
        "      print('cur_query : ' + cur_query)\n",
        "      topics_res, similarity = BERT_model_FINAL.find_topics(cur_query, top_n=2) \n",
        "      for j in range(0, 2):\n",
        "        all_topic_docs = BERT_model_FINAL.get_representative_docs(topics_res[j])\n",
        "        newQuery = findNewQuery(cur_query, all_topic_docs)\n",
        "        print('newQuery : ' + newQuery)\n",
        "        all_query_ids.append(all_query_ids2[index])\n",
        "        all_queries.append(newQuery)\n",
        "        all_document_ids.append(all_document_ids2[index])\n",
        "        all_documents.append(all_documents2[index])\n",
        "        all_labels.append(int(all_labels2[index]))\n",
        "\n",
        "print('len(all_query_ids) : ' + str(len(all_query_ids)))\n",
        "print('len(all_queries) : ' + str(len(all_queries)))\n",
        "print('len(all_document_ids) : ' + str(len(all_document_ids)))\n",
        "print('len(all_documents) : ' + str(len(all_documents)))\n",
        "print('len(all_labels) : ' + str(len(all_labels)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-IACyjXy0mx",
        "outputId": "9280eeb8-3bf9-40f4-c9f3-ff39c96f8921"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "len(corpus.keys() : 8841823\n",
            "len(queries.keys() : 808731\n",
            "len(original_query_ids) : 50000\n",
            "len(original_queries) : 50000\n",
            "len(original_document_ids) : 50000\n",
            "len(original_documents) : 50000\n",
            "len(original_labels) : 50000\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "pos_neg_ration = 4\n",
        "\n",
        "# Maximal number of training samples we want to use\n",
        "max_train_samples = 5e4\n",
        "\n",
        "\n",
        "### Now we read the MS Marco dataset\n",
        "data_folder = '/content/drive/MyDrive/collectionandqueries/'\n",
        "os.makedirs(data_folder, exist_ok=True)\n",
        "\n",
        "\n",
        "#### Read the corpus files, that contain all the passages. Store them in the corpus dict\n",
        "corpus = {}\n",
        "collection_filepath = os.path.join(data_folder, 'collection.tsv')\n",
        "if not os.path.exists(collection_filepath):\n",
        "    print('collection.tsv not found')\n",
        "\n",
        "with open(collection_filepath, 'r', encoding='utf8') as fIn:\n",
        "    for line in fIn:\n",
        "        pid, passage = line.strip().split(\"\\t\")\n",
        "        corpus[pid] = passage\n",
        "print('len(corpus.keys() : ' + str(len(corpus.keys())))\n",
        "\n",
        "### Read the train queries, store in queries dict\n",
        "queries = {}\n",
        "queries_filepath = os.path.join(data_folder, 'queries.train.tsv')\n",
        "if not os.path.exists(queries_filepath):\n",
        "    print('queries.train.tsv not found')\n",
        "\n",
        "with open(queries_filepath, 'r', encoding='utf8') as fIn:\n",
        "    for line in fIn:\n",
        "        qid, query = line.strip().split(\"\\t\")\n",
        "        queries[qid] = query\n",
        "\n",
        "print('len(queries.keys() : ' + str(len(queries.keys())))\n",
        "\n",
        "### Now we create our training & dev data\n",
        "original_query_ids = []\n",
        "original_queries = []\n",
        "original_document_ids = [] \n",
        "original_labels = []\n",
        "original_documents = []\n",
        "\n",
        "\"\"\"\n",
        "train_samples = []\n",
        "dev_samples = {}\n",
        "\n",
        "# We use 200 random queries from the train set for evaluation during training\n",
        "# Each query has at least one relevant and up to 200 irrelevant (negative) passages\n",
        "num_dev_queries = 200\n",
        "num_max_dev_negatives = 200\n",
        "\n",
        "# msmarco-qidpidtriples.rnd-shuf.train-eval.tsv.gz and msmarco-qidpidtriples.rnd-shuf.train.tsv.gz is a randomly\n",
        "# shuffled version of qidpidtriples.train.full.2.tsv.gz from the MS Marco website\n",
        "# We extracted in the train-eval split 500 random queries that can be used for evaluation during training\n",
        "train_eval_filepath = os.path.join(data_folder, 'msmarco-qidpidtriples.rnd-shuf.train-eval.tsv')\n",
        "if not os.path.exists(train_eval_filepath):\n",
        "    print('msmarco-qidpidtriples.rnd-shuf.train-eval.tsv not found')\n",
        "\n",
        "with open(train_eval_filepath, 'r', encoding='utf8') as fIn:\n",
        "    for line in fIn:\n",
        "        qid, pos_id, neg_id = line.strip().split()\n",
        "\n",
        "        if qid not in dev_samples and len(dev_samples) < num_dev_queries:\n",
        "            dev_samples[qid] = {'query': queries[qid], 'positive': set(), 'negative': set()}\n",
        "\n",
        "        if qid in dev_samples:\n",
        "            dev_samples[qid]['positive'].add(corpus[pos_id])\n",
        "            all_query_ids.append(qid)\n",
        "            all_queries.append(queries[qid])\n",
        "            all_document_ids.append(pos_id)\n",
        "            all_documents.append(corpus([pos_id]))\n",
        "            all_labels.append(1)\n",
        "            \n",
        "\n",
        "            if len(dev_samples[qid]['negative']) < num_max_dev_negatives:\n",
        "                dev_samples[qid]['negative'].add(corpus[neg_id])\n",
        "                all_query_ids.append(qid)\n",
        "                all_queries.append(queries[qid])\n",
        "                all_document_ids.append(neg_id)\n",
        "                all_documents.append(corpus([neg_id]))\n",
        "                all_labels.append(0)\n",
        "                \n",
        "\n",
        "print('len(dev_samples.keys()) : ' + str(len(dev_samples.keys())))\n",
        "\"\"\"\n",
        "\n",
        "# Read our training file\n",
        "train_filepath = os.path.join(data_folder, 'qidpidtriples-subset.train-200K.tsv')\n",
        "if not os.path.exists(train_filepath):\n",
        "    print('qidpidtriples-subset.train-200K.tsv not found')\n",
        "\n",
        "cnt = 0\n",
        "with open(train_filepath, 'r', encoding='utf8') as fIn:\n",
        "    for line in fIn:\n",
        "        qid, pos_id, neg_id = line.strip().split()\n",
        "\n",
        "        query = queries[qid]\n",
        "        if (cnt % (pos_neg_ration+1)) == 0:\n",
        "            passage = corpus[pos_id]\n",
        "            label = 1\n",
        "            original_query_ids.append(qid)\n",
        "            original_queries.append(query)\n",
        "            original_document_ids.append(pos_id)\n",
        "            original_documents.append(passage)\n",
        "            original_labels.append(label)\n",
        "        else:\n",
        "            passage = corpus[neg_id]\n",
        "            label = 0\n",
        "            original_query_ids.append(qid)\n",
        "            original_queries.append(queries[qid])\n",
        "            original_document_ids.append(neg_id)\n",
        "            original_documents.append(passage)\n",
        "            original_labels.append(label)\n",
        "\n",
        "        #train_samples.append(InputExample(texts=[query, passage], label=label))\n",
        "        cnt += 1\n",
        "\n",
        "        if cnt >= max_train_samples:\n",
        "            break\n",
        "print('len(original_query_ids) : ' + str(len(original_query_ids)))\n",
        "print('len(original_queries) : ' + str(len(original_queries)))\n",
        "print('len(original_document_ids) : ' + str(len(original_document_ids)))\n",
        "print('len(original_documents) : ' + str(len(original_documents)))\n",
        "print('len(original_labels) : ' + str(len(original_labels)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DS7MmoX0zXhQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "pos_neg_ration = 4\n",
        "\n",
        "# Maximal number of training samples we want to use\n",
        "#max_train_samples = 5e4\n",
        "max_train_samples = 5e3\n",
        "\n",
        "### Now we read the MS Marco dataset\n",
        "data_folder = '/content/drive/MyDrive/collectionandqueries/'\n",
        "os.makedirs(data_folder, exist_ok=True)\n",
        "\n",
        "\n",
        "#### Read the corpus files, that contain all the passages. Store them in the corpus dict\n",
        "corpus = {}\n",
        "collection_filepath = os.path.join(data_folder, 'collection.tsv')\n",
        "if not os.path.exists(collection_filepath):\n",
        "    print('collection.tsv not found')\n",
        "\n",
        "with open(collection_filepath, 'r', encoding='utf8') as fIn:\n",
        "    for line in fIn:\n",
        "        pid, passage = line.strip().split(\"\\t\")\n",
        "        corpus[pid] = passage\n",
        "print('len(corpus.keys() : ' + str(len(corpus.keys())))\n",
        "\n",
        "### Read the train queries, store in queries dict\n",
        "queries = {}\n",
        "queries_filepath = os.path.join(data_folder, 'queries.train.tsv')\n",
        "if not os.path.exists(queries_filepath):\n",
        "    print('queries.train.tsv not found')\n",
        "\n",
        "with open(queries_filepath, 'r', encoding='utf8') as fIn:\n",
        "    for line in fIn:\n",
        "        qid, query = line.strip().split(\"\\t\")\n",
        "        queries[qid] = query\n",
        "\n",
        "print('len(queries.keys() : ' + str(len(queries.keys())))\n",
        "\n",
        "### Now we create our training & dev data\n",
        "all_query_ids = []\n",
        "all_queries = []\n",
        "all_document_ids = [] \n",
        "all_labels = []\n",
        "all_documents = []\n",
        "\n",
        "\"\"\"\n",
        "train_samples = []\n",
        "dev_samples = {}\n",
        "\n",
        "# We use 200 random queries from the train set for evaluation during training\n",
        "# Each query has at least one relevant and up to 200 irrelevant (negative) passages\n",
        "num_dev_queries = 200\n",
        "num_max_dev_negatives = 200\n",
        "\n",
        "# msmarco-qidpidtriples.rnd-shuf.train-eval.tsv.gz and msmarco-qidpidtriples.rnd-shuf.train.tsv.gz is a randomly\n",
        "# shuffled version of qidpidtriples.train.full.2.tsv.gz from the MS Marco website\n",
        "# We extracted in the train-eval split 500 random queries that can be used for evaluation during training\n",
        "train_eval_filepath = os.path.join(data_folder, 'msmarco-qidpidtriples.rnd-shuf.train-eval.tsv')\n",
        "if not os.path.exists(train_eval_filepath):\n",
        "    print('msmarco-qidpidtriples.rnd-shuf.train-eval.tsv not found')\n",
        "\n",
        "with open(train_eval_filepath, 'r', encoding='utf8') as fIn:\n",
        "    for line in fIn:\n",
        "        qid, pos_id, neg_id = line.strip().split()\n",
        "\n",
        "        if qid not in dev_samples and len(dev_samples) < num_dev_queries:\n",
        "            dev_samples[qid] = {'query': queries[qid], 'positive': set(), 'negative': set()}\n",
        "\n",
        "        if qid in dev_samples:\n",
        "            dev_samples[qid]['positive'].add(corpus[pos_id])\n",
        "            all_query_ids.append(qid)\n",
        "            all_queries.append(queries[qid])\n",
        "            all_document_ids.append(pos_id)\n",
        "            all_documents.append(corpus([pos_id]))\n",
        "            all_labels.append(1)\n",
        "            \n",
        "\n",
        "            if len(dev_samples[qid]['negative']) < num_max_dev_negatives:\n",
        "                dev_samples[qid]['negative'].add(corpus[neg_id])\n",
        "                all_query_ids.append(qid)\n",
        "                all_queries.append(queries[qid])\n",
        "                all_document_ids.append(neg_id)\n",
        "                all_documents.append(corpus([neg_id]))\n",
        "                all_labels.append(0)\n",
        "                \n",
        "\n",
        "print('len(dev_samples.keys()) : ' + str(len(dev_samples.keys())))\n",
        "\"\"\"\n",
        "\n",
        "# Read our training file\n",
        "train_filepath = os.path.join(data_folder, 'qidpidtriples-subset.train-200K.tsv')\n",
        "if not os.path.exists(train_filepath):\n",
        "    print('qidpidtriples-subset.train-200K.tsv not found')\n",
        "\n",
        "cnt = 0\n",
        "with open(train_filepath, 'r', encoding='utf8') as fIn:\n",
        "    for line in fIn:\n",
        "        qid, pos_id, neg_id = line.strip().split()\n",
        "        print('cnt : ' + str(cnt))\n",
        "        query = queries[qid]\n",
        "        if (cnt % (pos_neg_ration+1)) == 0:\n",
        "            #print('positive')\n",
        "            passage = corpus[pos_id]\n",
        "            label = 1\n",
        "            all_query_ids.append(qid)\n",
        "            all_queries.append(query)\n",
        "            all_document_ids.append(pos_id)\n",
        "            all_documents.append(passage)\n",
        "            all_labels.append(label)\n",
        "            bm25_passages = bm25.get_top_n(query, original_documents, n=3)\n",
        "            for bm25_passage in bm25_passages:\n",
        "              all_query_ids.append(qid)\n",
        "              all_queries.append(query)\n",
        "              all_document_ids.append(pos_id)\n",
        "              all_documents.append(bm25_passage)\n",
        "              all_labels.append(label)\n",
        "        else:\n",
        "            #print('negative')\n",
        "            passage = corpus[neg_id]\n",
        "            label = 0\n",
        "            all_query_ids.append(qid)\n",
        "            all_queries.append(queries[qid])\n",
        "            all_document_ids.append(neg_id)\n",
        "            all_documents.append(passage)\n",
        "            all_labels.append(label)\n",
        "\n",
        "        #train_samples.append(InputExample(texts=[query, passage], label=label))\n",
        "        cnt += 1\n",
        "\n",
        "        if cnt >= max_train_samples:\n",
        "            break\n",
        "print('len(all_query_ids) : ' + str(len(all_query_ids)))\n",
        "print('len(all_queries) : ' + str(len(all_queries)))\n",
        "print('len(all_document_ids) : ' + str(len(all_document_ids)))\n",
        "print('len(all_documents) : ' + str(len(all_documents)))\n",
        "print('len(all_labels) : ' + str(len(all_labels)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "gJL9ZMfLCg6P",
        "outputId": "20865491-9a18-47ac-d650-5c22cf00b32d"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2a7d41a69162>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mfr1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/collectionandqueries/all_query_ids.tsv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mfr2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/collectionandqueries/all_queries.tsv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mfr3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/collectionandqueries/all_document_ids.tsv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/collectionandqueries/all_query_ids.tsv'"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import sys\n",
        "\n",
        "csv.field_size_limit(sys.maxsize)\n",
        "\n",
        "\n",
        "fr1 = open(\"/content/drive/MyDrive/collectionandqueries/all_query_ids.tsv\", \"r\")\n",
        "fr2 = open(\"/content/drive/MyDrive/collectionandqueries/all_queries.tsv\", \"r\")\n",
        "fr3 = open(\"/content/drive/MyDrive/collectionandqueries/all_document_ids.tsv\", \"r\")\n",
        "fr4 = open(\"/content/drive/MyDrive/collectionandqueries/all_documents.tsv\", \"r\")\n",
        "fr5 = open(\"/content/drive/MyDrive/collectionandqueries/all_labels.tsv\", \"r\")\n",
        "\n",
        "input_file1 = csv.reader(fr1, delimiter = \"\\t\")\n",
        "input_file2 = csv.reader(fr2, delimiter = \"\\t\")\n",
        "input_file3 = csv.reader(fr3, delimiter = \"\\t\")\n",
        "input_file4 = csv.reader(fr4, delimiter = \"\\t\")\n",
        "input_file5 = csv.reader(fr5, delimiter = \"\\t\")\n",
        "\n",
        "all_query_ids2 = []\n",
        "all_queries2 = []\n",
        "all_document_ids2 = []\n",
        "all_documents2 = []\n",
        "all_labels2 = []\n",
        "\n",
        "for w in input_file1: \n",
        "    #print('w : ' + str(w[0]))\n",
        "    all_query_ids2.append(w[0])\n",
        "\n",
        "for w in input_file2: \n",
        "    all_queries2.append(w[0])\n",
        "\n",
        "for w in input_file3: \n",
        "    all_document_ids2.append(w[0])\n",
        "\n",
        "for w in input_file4: \n",
        "    all_documents2.append(w[0])\n",
        "\n",
        "for w in input_file5: \n",
        "    all_labels2.append(w[0]) \n",
        "\n",
        "print('len(all_query_ids2) : ' + str(len(all_query_ids2)))\n",
        "print('len(all_queries2) : ' + str(len(all_queries2)))\n",
        "print('len(all_document_ids2) : ' + str(len(all_document_ids2)))\n",
        "print('len(all_documents2) : ' + str(len(all_documents2)))\n",
        "print('len(all_labels2) : ' + str(len(all_labels2)))\n",
        "\n",
        "all_query_ids = []\n",
        "all_queries = []\n",
        "all_document_ids = []\n",
        "all_documents = []\n",
        "all_labels = []\n",
        "\n",
        "length = len(all_query_ids2)\n",
        "index = 0\n",
        "\n",
        "for index in range(0, length): \n",
        "    #print('index : ' + str(index))\n",
        "    all_query_ids.append(all_query_ids2[index])\n",
        "    all_queries.append(all_queries2[index])\n",
        "    all_document_ids.append(all_document_ids2[index])\n",
        "    all_documents.append(all_documents2[index])\n",
        "    all_labels.append(int(all_labels2[index]))\n",
        "    \"\"\"\n",
        "    print('all_query_ids2[index] : ' + all_query_ids2[index])\n",
        "    print('all_queries2[index] : ' + all_queries2[index])\n",
        "    print('all_document_ids2[index] : ' + all_document_ids2[index])\n",
        "    print('all_documents2[index] : ' + all_documents2[index])\n",
        "    print('all_labels2[index] : ' + all_labels2[index])\n",
        "    \"\"\"\n",
        "    \n",
        "    if(int(all_labels2[index])) == 1:\n",
        "      cur_query = all_queries2[index]\n",
        "      #print('cur_query : ' + cur_query)\n",
        "      topics_res, similarity = BERT_model_FINAL.find_topics(cur_query, top_n=2) \n",
        "      for j in range(0, 2):\n",
        "        all_topic_docs = BERT_model_FINAL.get_representative_docs(topics_res[j])\n",
        "        newQuery = findNewQuery(cur_query, all_topic_docs)\n",
        "        #print('newQuery : ' + newQuery)\n",
        "        all_query_ids.append(all_query_ids2[index])\n",
        "        all_queries.append(newQuery)\n",
        "        all_document_ids.append(all_document_ids2[index])\n",
        "        all_documents.append(all_documents2[index])\n",
        "        all_labels.append(int(all_labels2[index]))\n",
        "\n",
        "print('len(all_query_ids) : ' + str(len(all_query_ids)))\n",
        "print('len(all_queries) : ' + str(len(all_queries)))\n",
        "print('len(all_document_ids) : ' + str(len(all_document_ids)))\n",
        "print('len(all_documents) : ' + str(len(all_documents)))\n",
        "print('len(all_labels) : ' + str(len(all_labels)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4lud1_0Dq6Z"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "--1p9vVLzq4m"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_queries, val_queries, train_docs, val_docs, train_labels, val_labels = train_test_split(\n",
        "    all_queries, \n",
        "    all_documents, \n",
        "    all_labels, \n",
        "    test_size=.2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ircTn5eGzrdc",
        "outputId": "f24e3380-2179-442b-f196-ff6d9bdde52d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (1.3.5)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6fHaawNzwFb",
        "outputId": "41646207-3898-4513-f9fa-1845a005c7aa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--google--bert_uncased_L-4_H-512_A-8/snapshots/606e4d55252882ac25ba1f1d1a182075830f5a90/vocab.txt\n",
            "loading file tokenizer.json from cache at None\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at None\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--bert_uncased_L-4_H-512_A-8/snapshots/606e4d55252882ac25ba1f1d1a182075830f5a90/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"google/bert_uncased_L-4_H-512_A-8\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 512,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 2048,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 8,\n",
            "  \"num_hidden_layers\": 4,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--bert_uncased_L-4_H-512_A-8/snapshots/606e4d55252882ac25ba1f1d1a182075830f5a90/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"google/bert_uncased_L-4_H-512_A-8\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 512,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 2048,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 8,\n",
            "  \"num_hidden_layers\": 4,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizerFast\n",
        "\n",
        "model_name = \"google/bert_uncased_L-4_H-512_A-8\"\n",
        "tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
        "\n",
        "train_encodings = tokenizer(train_queries, train_docs, truncation=True, padding='max_length', max_length=128)\n",
        "val_encodings = tokenizer(val_queries, val_docs, truncation=True, padding='max_length', max_length=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "Vl1oowEezwoT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "class OurDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = OurDataset(train_encodings, train_labels)\n",
        "val_dataset = OurDataset(val_encodings, val_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WbRC4kGzyyd",
        "outputId": "0b2ed55b-5e8a-4baf-ae71-5aa67a0b6e9d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--bert_uncased_L-4_H-512_A-8/snapshots/606e4d55252882ac25ba1f1d1a182075830f5a90/config.json\n",
            "Model config BertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 512,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 2048,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 8,\n",
            "  \"num_hidden_layers\": 4,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--google--bert_uncased_L-4_H-512_A-8/snapshots/606e4d55252882ac25ba1f1d1a182075830f5a90/pytorch_model.bin\n",
            "Some weights of the model checkpoint at google/bert_uncased_L-4_H-512_A-8 were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-4_H-512_A-8 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "MAY5VjGIz0pW"
      },
      "outputs": [],
      "source": [
        "for param in model.base_model.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5TZsYE0z3P6",
        "outputId": "b77be091-a83f-4255-8133-1e89d4b4f8d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.8/dist-packages (0.4.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.18.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from evaluate) (3.1.0)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (2.7.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from evaluate) (1.21.6)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.11.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from evaluate) (1.3.5)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.3.6)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.70.14)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (2022.11.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from evaluate) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from evaluate) (4.64.1)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (5.4.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (3.8.3)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.1.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->evaluate) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (2022.9.24)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->evaluate) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->evaluate) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "pip install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_01wC7iFz5UJ",
        "outputId": "74ffa527-e641-4d80-9f37-75f1ab7b4058"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: trectools in /usr/local/lib/python3.8/dist-packages (0.0.49)\n",
            "Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.8/dist-packages (from trectools) (4.9.1)\n",
            "Requirement already satisfied: scikit-learn>=0.15 in /usr/local/lib/python3.8/dist-packages (from trectools) (1.0.2)\n",
            "Requirement already satisfied: bs4>=0.0.0.1 in /usr/local/lib/python3.8/dist-packages (from trectools) (0.0.1)\n",
            "Requirement already satisfied: numpy>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from trectools) (1.21.6)\n",
            "Requirement already satisfied: sarge>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from trectools) (0.1.7.post1)\n",
            "Requirement already satisfied: pandas>=0.15.0 in /usr/local/lib/python3.8/dist-packages (from trectools) (1.3.5)\n",
            "Requirement already satisfied: matplotlib>=1.5 in /usr/local/lib/python3.8/dist-packages (from trectools) (3.2.2)\n",
            "Requirement already satisfied: scipy>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from trectools) (1.7.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from bs4>=0.0.0.1->trectools) (4.6.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.5->trectools) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.5->trectools) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.5->trectools) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.5->trectools) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.15.0->trectools) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib>=1.5->trectools) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.15->trectools) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.15->trectools) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "pip install trectools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 903,
          "referenced_widgets": [
            "edb1a3a1f56243ceaf572a0642a5edf8",
            "d4c65e0a7d484fa09a469a693a3ca8d3",
            "e3b15587437d4748baa53d790422daf7",
            "149d527b097749a19144d6650bda81a1",
            "a02d8840ce8645b1b194521e9f318488",
            "159e972280a94f478457d70c3d1cfb49",
            "231e397745474ef4b74df4a83c00807e",
            "3d60327b801a4faebf4ca42c46a977fb",
            "8ee0c7020eb94ce39b391f7f16f9feba",
            "3b1e96b2543c4405bf1fe3fea2fc0126",
            "b4d22251c6864e2cacc67a17e39d66eb"
          ]
        },
        "id": "Joutd41Jz7PW",
        "outputId": "a57b131f-e700-42ce-df3d-ab7c1d401ad9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "***** Running training *****\n",
            "  Num examples = 12800\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 1600\n",
            "  Number of trainable parameters = 1026\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1600' max='1600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1600/1600 34:18, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Runid</th>\n",
              "      <th>Num Ret</th>\n",
              "      <th>Num Rel</th>\n",
              "      <th>Num Rel Ret</th>\n",
              "      <th>Num Q</th>\n",
              "      <th>Map</th>\n",
              "      <th>Gm Map</th>\n",
              "      <th>Bpref</th>\n",
              "      <th>Rprec</th>\n",
              "      <th>Recip Rank</th>\n",
              "      <th>P@5</th>\n",
              "      <th>P@10</th>\n",
              "      <th>P@15</th>\n",
              "      <th>P@20</th>\n",
              "      <th>P@30</th>\n",
              "      <th>P@100</th>\n",
              "      <th>P@200</th>\n",
              "      <th>P@500</th>\n",
              "      <th>P@1000</th>\n",
              "      <th>Ndcg@5</th>\n",
              "      <th>Ndcg@10</th>\n",
              "      <th>Ndcg@15</th>\n",
              "      <th>Ndcg@20</th>\n",
              "      <th>Ndcg@30</th>\n",
              "      <th>Ndcg@100</th>\n",
              "      <th>Ndcg@200</th>\n",
              "      <th>Ndcg@500</th>\n",
              "      <th>Ndcg@1000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.379200</td>\n",
              "      <td>0.279177</td>\n",
              "      <td>test</td>\n",
              "      <td>3200</td>\n",
              "      <td>2389</td>\n",
              "      <td>2389</td>\n",
              "      <td>2574</td>\n",
              "      <td>0.686092</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.001166</td>\n",
              "      <td>0.686092</td>\n",
              "      <td>0.686092</td>\n",
              "      <td>0.185625</td>\n",
              "      <td>0.092813</td>\n",
              "      <td>0.061875</td>\n",
              "      <td>0.046406</td>\n",
              "      <td>0.030938</td>\n",
              "      <td>0.009281</td>\n",
              "      <td>0.004641</td>\n",
              "      <td>0.001856</td>\n",
              "      <td>0.000928</td>\n",
              "      <td>0.685805</td>\n",
              "      <td>0.685805</td>\n",
              "      <td>0.685805</td>\n",
              "      <td>0.685805</td>\n",
              "      <td>0.685805</td>\n",
              "      <td>0.685805</td>\n",
              "      <td>0.685805</td>\n",
              "      <td>0.685805</td>\n",
              "      <td>0.685805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.309300</td>\n",
              "      <td>0.241448</td>\n",
              "      <td>test</td>\n",
              "      <td>3200</td>\n",
              "      <td>2389</td>\n",
              "      <td>2389</td>\n",
              "      <td>2574</td>\n",
              "      <td>0.685897</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000777</td>\n",
              "      <td>0.685703</td>\n",
              "      <td>0.685897</td>\n",
              "      <td>0.185625</td>\n",
              "      <td>0.092813</td>\n",
              "      <td>0.061875</td>\n",
              "      <td>0.046406</td>\n",
              "      <td>0.030938</td>\n",
              "      <td>0.009281</td>\n",
              "      <td>0.004641</td>\n",
              "      <td>0.001856</td>\n",
              "      <td>0.000928</td>\n",
              "      <td>0.685805</td>\n",
              "      <td>0.685805</td>\n",
              "      <td>0.685805</td>\n",
              "      <td>0.685805</td>\n",
              "      <td>0.685805</td>\n",
              "      <td>0.685805</td>\n",
              "      <td>0.685805</td>\n",
              "      <td>0.685805</td>\n",
              "      <td>0.685805</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to ./results/checkpoint-500\n",
            "Configuration saved in ./results/checkpoint-500/config.json\n",
            "Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3200\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7fb0ee5d1c10>\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "edb1a3a1f56243ceaf572a0642a5edf8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/5.51k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to ./results/checkpoint-1000\n",
            "Configuration saved in ./results/checkpoint-1000/config.json\n",
            "Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-500] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-1500\n",
            "Configuration saved in ./results/checkpoint-1500/config.json\n",
            "Model weights saved in ./results/checkpoint-1500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-1000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3200\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7fb0e98b38e0>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1600, training_loss=0.3467003762722015, metrics={'train_runtime': 2059.9403, 'train_samples_per_second': 12.428, 'train_steps_per_second': 0.777, 'total_flos': 253117897113600.0, 'train_loss': 0.3467003762722015, 'epoch': 2.0})"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "from sklearn.metrics import ndcg_score\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "import evaluate\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def my_compute_metrics_ndcg(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    print ('predictions : ' + str(predictions))\n",
        "    predictions2 = tf.nn.log_softmax(predictions, axis=-1)\n",
        "    #print(classification_report(labels, predictions))\n",
        "    return ndcg_score(predictions2, labels)\n",
        "\"\"\"\n",
        "\n",
        "def my_compute_metrics_precision(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    metric = evaluate.load(\"precision\")\n",
        "    #print('predictions : ' + str(predictions))\n",
        "    #print('labels : ' + str(labels))\n",
        "    #if task != \"stsb\":\n",
        "    predictions = np.argmax(predictions, axis=-1)\n",
        "    #else:\n",
        "    #predictions = predictions[:]\n",
        "    print(classification_report(labels, predictions))\n",
        "    return metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "\n",
        "# You can define your custom compute_metrics function. It takes an `EvalPrediction` object (a namedtuple with a\n",
        "# predictions and label_ids field) and has to return a dictionary string to float.\n",
        "def compute_metrics2(pred):\n",
        "    \"\"\"\n",
        "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
        "    preds = np.argmax(preds, axis=1)\n",
        "    return metric.compute(predictions=preds, references=p.label_ids)   \n",
        "    \"\"\"\n",
        "    print('pred : ' + str(pred))\n",
        "    # Get the metric function\n",
        "    trec_eval = evaluate.load(\"trec_eval\")\n",
        "    qrel = {}\n",
        "    qids, seen, i = [], {}, 0\n",
        "    for q in val_queries:\n",
        "      if q in seen:\n",
        "        qids.append(seen[q])\n",
        "      else:\n",
        "        seen[q] = i\n",
        "        qids.append(i)\n",
        "        i+=1\n",
        "    qrel={\n",
        "      \"query\": qids,\n",
        "      \"q0\": val_queries,\n",
        "      \"docid\": val_docs,\n",
        "      \"rel\": val_labels\n",
        "    }\n",
        "    run = {\n",
        "      \"query\": qids,\n",
        "      \"q0\": val_queries,\n",
        "      \"docid\": val_docs,\n",
        "      \"rank\": pred[1].tolist(),\n",
        "      \"score\": [max(l) for l in pred[0].tolist()],\n",
        "      \"system\": [\"test\" for i in qids]\n",
        "    }    \n",
        "    results = trec_eval.compute(references=[qrel], predictions=[run]) \n",
        "    return results\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    evaluation_strategy=\"epoch\",     # Evaluation is done at the end of each epoch.\n",
        "    num_train_epochs=2,              # total number of training epochs\n",
        "    per_device_train_batch_size=16,  # batch size per device during training\n",
        "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
        "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    learning_rate=0.005,\n",
        "    save_total_limit=1,              # limit the total amount of checkpoints. Deletes the older checkpoints.    \n",
        ")\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,                         # the instantiated Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=val_dataset,             # evaluation dataset\n",
        "    compute_metrics = compute_metrics2\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iy6Ovft2d5Sg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "heP56ldDd5iZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPFvQWPDd5k1",
        "outputId": "83adfc5c-e956-4ed2-eb3e-ceaadaa1ae9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "len(all_query_ids2) : 8000\n",
            "len(all_queries2) : 8000\n",
            "len(all_document_ids2) : 8000\n",
            "len(all_documents2) : 8000\n",
            "len(all_labels2) : 8000\n",
            "len(all_query_ids) : 16000\n",
            "len(all_queries) : 16000\n",
            "len(all_document_ids) : 16000\n",
            "len(all_documents) : 16000\n",
            "len(all_labels) : 16000\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import sys\n",
        "\n",
        "csv.field_size_limit(sys.maxsize)\n",
        "\n",
        "\n",
        "fr1 = open(\"/content/drive/MyDrive/collectionandqueries/all_query_ids.tsv\", \"r\")\n",
        "fr2 = open(\"/content/drive/MyDrive/collectionandqueries/all_queries.tsv\", \"r\")\n",
        "fr3 = open(\"/content/drive/MyDrive/collectionandqueries/all_document_ids.tsv\", \"r\")\n",
        "fr4 = open(\"/content/drive/MyDrive/collectionandqueries/all_documents.tsv\", \"r\")\n",
        "fr5 = open(\"/content/drive/MyDrive/collectionandqueries/all_labels.tsv\", \"r\")\n",
        "\n",
        "input_file1 = csv.reader(fr1, delimiter = \"\\t\")\n",
        "input_file2 = csv.reader(fr2, delimiter = \"\\t\")\n",
        "input_file3 = csv.reader(fr3, delimiter = \"\\t\")\n",
        "input_file4 = csv.reader(fr4, delimiter = \"\\t\")\n",
        "input_file5 = csv.reader(fr5, delimiter = \"\\t\")\n",
        "\n",
        "all_query_ids2 = []\n",
        "all_queries2 = []\n",
        "all_document_ids2 = []\n",
        "all_documents2 = []\n",
        "all_labels2 = []\n",
        "\n",
        "for w in input_file1: \n",
        "    #print('w : ' + str(w[0]))\n",
        "    all_query_ids2.append(w[0])\n",
        "\n",
        "for w in input_file2: \n",
        "    all_queries2.append(w[0])\n",
        "\n",
        "for w in input_file3: \n",
        "    all_document_ids2.append(w[0])\n",
        "\n",
        "for w in input_file4: \n",
        "    all_documents2.append(w[0])\n",
        "\n",
        "for w in input_file5: \n",
        "    all_labels2.append(w[0]) \n",
        "\n",
        "print('len(all_query_ids2) : ' + str(len(all_query_ids2)))\n",
        "print('len(all_queries2) : ' + str(len(all_queries2)))\n",
        "print('len(all_document_ids2) : ' + str(len(all_document_ids2)))\n",
        "print('len(all_documents2) : ' + str(len(all_documents2)))\n",
        "print('len(all_labels2) : ' + str(len(all_labels2)))\n",
        "\n",
        "all_query_ids = []\n",
        "all_queries = []\n",
        "all_document_ids = []\n",
        "all_documents = []\n",
        "all_labels = []\n",
        "\n",
        "length = len(all_query_ids2)\n",
        "index = 0\n",
        "\n",
        "for index in range(0, length): \n",
        "    #print('index : ' + str(index))\n",
        "    all_query_ids.append(all_query_ids2[index])\n",
        "    all_queries.append(all_queries2[index])\n",
        "    all_document_ids.append(all_document_ids2[index])\n",
        "    all_documents.append(all_documents2[index])\n",
        "    all_labels.append(int(all_labels2[index]))\n",
        "    \"\"\"\n",
        "    print('all_query_ids2[index] : ' + all_query_ids2[index])\n",
        "    print('all_queries2[index] : ' + all_queries2[index])\n",
        "    print('all_document_ids2[index] : ' + all_document_ids2[index])\n",
        "    print('all_documents2[index] : ' + all_documents2[index])\n",
        "    print('all_labels2[index] : ' + all_labels2[index])\n",
        "    \"\"\"\n",
        "    \n",
        "    if(int(all_labels2[index])) == 1:\n",
        "      cur_query = all_queries2[index]\n",
        "      #print('cur_query : ' + cur_query)\n",
        "      topics_res, similarity = BERT_model_FINAL.find_topics(cur_query, top_n=2) \n",
        "      for j in range(0, 2):\n",
        "        all_topic_docs = BERT_model_FINAL.get_representative_docs(topics_res[j])\n",
        "        newQuery = findNewQuery(cur_query, all_topic_docs)\n",
        "        #print('newQuery : ' + newQuery)\n",
        "        all_query_ids.append(all_query_ids2[index])\n",
        "        all_queries.append(cur_query)\n",
        "        all_document_ids.append(all_document_ids2[index])\n",
        "        all_documents.append(all_documents2[index])\n",
        "        all_labels.append(int(all_labels2[index]))\n",
        "\n",
        "print('len(all_query_ids) : ' + str(len(all_query_ids)))\n",
        "print('len(all_queries) : ' + str(len(all_queries)))\n",
        "print('len(all_document_ids) : ' + str(len(all_document_ids)))\n",
        "print('len(all_documents) : ' + str(len(all_documents)))\n",
        "print('len(all_labels) : ' + str(len(all_labels)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 889
        },
        "id": "A2sRjHBDfIta",
        "outputId": "7098f277-578e-4a3d-b79b-bc1263781a3a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "***** Running training *****\n",
            "  Num examples = 12800\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 1600\n",
            "  Number of trainable parameters = 1026\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1600' max='1600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1600/1600 33:31, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Runid</th>\n",
              "      <th>Num Ret</th>\n",
              "      <th>Num Rel</th>\n",
              "      <th>Num Rel Ret</th>\n",
              "      <th>Num Q</th>\n",
              "      <th>Map</th>\n",
              "      <th>Gm Map</th>\n",
              "      <th>Bpref</th>\n",
              "      <th>Rprec</th>\n",
              "      <th>Recip Rank</th>\n",
              "      <th>P@5</th>\n",
              "      <th>P@10</th>\n",
              "      <th>P@15</th>\n",
              "      <th>P@20</th>\n",
              "      <th>P@30</th>\n",
              "      <th>P@100</th>\n",
              "      <th>P@200</th>\n",
              "      <th>P@500</th>\n",
              "      <th>P@1000</th>\n",
              "      <th>Ndcg@5</th>\n",
              "      <th>Ndcg@10</th>\n",
              "      <th>Ndcg@15</th>\n",
              "      <th>Ndcg@20</th>\n",
              "      <th>Ndcg@30</th>\n",
              "      <th>Ndcg@100</th>\n",
              "      <th>Ndcg@200</th>\n",
              "      <th>Ndcg@500</th>\n",
              "      <th>Ndcg@1000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.411900</td>\n",
              "      <td>0.324054</td>\n",
              "      <td>test</td>\n",
              "      <td>3200</td>\n",
              "      <td>2381</td>\n",
              "      <td>3285</td>\n",
              "      <td>1743</td>\n",
              "      <td>0.869092</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.001147</td>\n",
              "      <td>0.676946</td>\n",
              "      <td>0.531268</td>\n",
              "      <td>0.321170</td>\n",
              "      <td>0.185198</td>\n",
              "      <td>0.125301</td>\n",
              "      <td>0.094234</td>\n",
              "      <td>0.062823</td>\n",
              "      <td>0.018847</td>\n",
              "      <td>0.009423</td>\n",
              "      <td>0.003769</td>\n",
              "      <td>0.001885</td>\n",
              "      <td>0.675070</td>\n",
              "      <td>0.675278</td>\n",
              "      <td>0.675278</td>\n",
              "      <td>0.675278</td>\n",
              "      <td>0.675278</td>\n",
              "      <td>0.675278</td>\n",
              "      <td>0.675278</td>\n",
              "      <td>0.675278</td>\n",
              "      <td>0.675278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.349800</td>\n",
              "      <td>0.288268</td>\n",
              "      <td>test</td>\n",
              "      <td>3200</td>\n",
              "      <td>2381</td>\n",
              "      <td>3285</td>\n",
              "      <td>1743</td>\n",
              "      <td>0.868447</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.001147</td>\n",
              "      <td>0.676946</td>\n",
              "      <td>0.531268</td>\n",
              "      <td>0.321170</td>\n",
              "      <td>0.185198</td>\n",
              "      <td>0.125301</td>\n",
              "      <td>0.094234</td>\n",
              "      <td>0.062823</td>\n",
              "      <td>0.018847</td>\n",
              "      <td>0.009423</td>\n",
              "      <td>0.003769</td>\n",
              "      <td>0.001885</td>\n",
              "      <td>0.675070</td>\n",
              "      <td>0.675278</td>\n",
              "      <td>0.675278</td>\n",
              "      <td>0.675278</td>\n",
              "      <td>0.675278</td>\n",
              "      <td>0.675278</td>\n",
              "      <td>0.675278</td>\n",
              "      <td>0.675278</td>\n",
              "      <td>0.675278</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to ./results/checkpoint-500\n",
            "Configuration saved in ./results/checkpoint-500/config.json\n",
            "Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-1500] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3200\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7fb0edbfbaf0>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to ./results/checkpoint-1000\n",
            "Configuration saved in ./results/checkpoint-1000/config.json\n",
            "Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-500] due to args.save_total_limit\n",
            "Saving model checkpoint to ./results/checkpoint-1500\n",
            "Configuration saved in ./results/checkpoint-1500/config.json\n",
            "Model weights saved in ./results/checkpoint-1500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-1000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3200\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7fb0ee92b070>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1600, training_loss=0.379487726688385, metrics={'train_runtime': 2012.7463, 'train_samples_per_second': 12.719, 'train_steps_per_second': 0.795, 'total_flos': 253117897113600.0, 'train_loss': 0.379487726688385, 'epoch': 2.0})"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "from sklearn.metrics import ndcg_score\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "import evaluate\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def my_compute_metrics_ndcg(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    print ('predictions : ' + str(predictions))\n",
        "    predictions2 = tf.nn.log_softmax(predictions, axis=-1)\n",
        "    #print(classification_report(labels, predictions))\n",
        "    return ndcg_score(predictions2, labels)\n",
        "\"\"\"\n",
        "\n",
        "def my_compute_metrics_precision(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    metric = evaluate.load(\"precision\")\n",
        "    #print('predictions : ' + str(predictions))\n",
        "    #print('labels : ' + str(labels))\n",
        "    #if task != \"stsb\":\n",
        "    predictions = np.argmax(predictions, axis=-1)\n",
        "    #else:\n",
        "    #predictions = predictions[:]\n",
        "    print(classification_report(labels, predictions))\n",
        "    return metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "\n",
        "# You can define your custom compute_metrics function. It takes an `EvalPrediction` object (a namedtuple with a\n",
        "# predictions and label_ids field) and has to return a dictionary string to float.\n",
        "def compute_metrics2(pred):\n",
        "    \"\"\"\n",
        "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
        "    preds = np.argmax(preds, axis=1)\n",
        "    return metric.compute(predictions=preds, references=p.label_ids)   \n",
        "    \"\"\"\n",
        "    print('pred : ' + str(pred))\n",
        "    # Get the metric function\n",
        "    trec_eval = evaluate.load(\"trec_eval\")\n",
        "    qrel = {}\n",
        "    qids, seen, i = [], {}, 0\n",
        "    for q in val_queries:\n",
        "      if q in seen:\n",
        "        qids.append(seen[q])\n",
        "      else:\n",
        "        seen[q] = i\n",
        "        qids.append(i)\n",
        "        i+=1\n",
        "    qrel={\n",
        "      \"query\": qids,\n",
        "      \"q0\": val_queries,\n",
        "      \"docid\": val_docs,\n",
        "      \"rel\": val_labels\n",
        "    }\n",
        "    run = {\n",
        "      \"query\": qids,\n",
        "      \"q0\": val_queries,\n",
        "      \"docid\": val_docs,\n",
        "      \"rank\": pred[1].tolist(),\n",
        "      \"score\": [max(l) for l in pred[0].tolist()],\n",
        "      \"system\": [\"test\" for i in qids]\n",
        "    }    \n",
        "    results = trec_eval.compute(references=[qrel], predictions=[run]) \n",
        "    return results\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    evaluation_strategy=\"epoch\",     # Evaluation is done at the end of each epoch.\n",
        "    num_train_epochs=2,              # total number of training epochs\n",
        "    per_device_train_batch_size=16,  # batch size per device during training\n",
        "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
        "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    learning_rate=0.005,\n",
        "    save_total_limit=1,              # limit the total amount of checkpoints. Deletes the older checkpoints.    \n",
        ")\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,                         # the instantiated Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=val_dataset,             # evaluation dataset\n",
        "    compute_metrics = compute_metrics2\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDM-nJoLoq_b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCjanGDIorYQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Z-5IqAiora4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mz_Ewc0Torde",
        "outputId": "df7e4fa8-a6a0-4fb4-a2f4-aa77fa6c190c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "len(all_query_ids2) : 8000\n",
            "len(all_queries2) : 8000\n",
            "len(all_document_ids2) : 8000\n",
            "len(all_documents2) : 8000\n",
            "len(all_labels2) : 8000\n",
            "len(all_query_ids) : 8000\n",
            "len(all_queries) : 8000\n",
            "len(all_document_ids) : 8000\n",
            "len(all_documents) : 8000\n",
            "len(all_labels) : 8000\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import sys\n",
        "\n",
        "csv.field_size_limit(sys.maxsize)\n",
        "\n",
        "\n",
        "fr1 = open(\"/content/drive/MyDrive/collectionandqueries/all_query_ids.tsv\", \"r\")\n",
        "fr2 = open(\"/content/drive/MyDrive/collectionandqueries/all_queries.tsv\", \"r\")\n",
        "fr3 = open(\"/content/drive/MyDrive/collectionandqueries/all_document_ids.tsv\", \"r\")\n",
        "fr4 = open(\"/content/drive/MyDrive/collectionandqueries/all_documents.tsv\", \"r\")\n",
        "fr5 = open(\"/content/drive/MyDrive/collectionandqueries/all_labels.tsv\", \"r\")\n",
        "\n",
        "input_file1 = csv.reader(fr1, delimiter = \"\\t\")\n",
        "input_file2 = csv.reader(fr2, delimiter = \"\\t\")\n",
        "input_file3 = csv.reader(fr3, delimiter = \"\\t\")\n",
        "input_file4 = csv.reader(fr4, delimiter = \"\\t\")\n",
        "input_file5 = csv.reader(fr5, delimiter = \"\\t\")\n",
        "\n",
        "all_query_ids2 = []\n",
        "all_queries2 = []\n",
        "all_document_ids2 = []\n",
        "all_documents2 = []\n",
        "all_labels2 = []\n",
        "\n",
        "for w in input_file1: \n",
        "    #print('w : ' + str(w[0]))\n",
        "    all_query_ids2.append(w[0])\n",
        "\n",
        "for w in input_file2: \n",
        "    all_queries2.append(w[0])\n",
        "\n",
        "for w in input_file3: \n",
        "    all_document_ids2.append(w[0])\n",
        "\n",
        "for w in input_file4: \n",
        "    all_documents2.append(w[0])\n",
        "\n",
        "for w in input_file5: \n",
        "    all_labels2.append(w[0]) \n",
        "\n",
        "print('len(all_query_ids2) : ' + str(len(all_query_ids2)))\n",
        "print('len(all_queries2) : ' + str(len(all_queries2)))\n",
        "print('len(all_document_ids2) : ' + str(len(all_document_ids2)))\n",
        "print('len(all_documents2) : ' + str(len(all_documents2)))\n",
        "print('len(all_labels2) : ' + str(len(all_labels2)))\n",
        "\n",
        "all_query_ids = []\n",
        "all_queries = []\n",
        "all_document_ids = []\n",
        "all_documents = []\n",
        "all_labels = []\n",
        "\n",
        "length = len(all_query_ids2)\n",
        "index = 0\n",
        "\n",
        "for index in range(0, length): \n",
        "    #print('index : ' + str(index))\n",
        "    all_query_ids.append(all_query_ids2[index])\n",
        "    all_queries.append(all_queries2[index])\n",
        "    all_document_ids.append(all_document_ids2[index])\n",
        "    all_documents.append(all_documents2[index])\n",
        "    all_labels.append(int(all_labels2[index]))\n",
        "    \"\"\"\n",
        "    print('all_query_ids2[index] : ' + all_query_ids2[index])\n",
        "    print('all_queries2[index] : ' + all_queries2[index])\n",
        "    print('all_document_ids2[index] : ' + all_document_ids2[index])\n",
        "    print('all_documents2[index] : ' + all_documents2[index])\n",
        "    print('all_labels2[index] : ' + all_labels2[index])\n",
        "    \"\"\"\n",
        "\n",
        "print('len(all_query_ids) : ' + str(len(all_query_ids)))\n",
        "print('len(all_queries) : ' + str(len(all_queries)))\n",
        "print('len(all_document_ids) : ' + str(len(all_document_ids)))\n",
        "print('len(all_documents) : ' + str(len(all_documents)))\n",
        "print('len(all_labels) : ' + str(len(all_labels)))\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_queries, val_queries, train_docs, val_docs, train_labels, val_labels = train_test_split(\n",
        "    all_queries, \n",
        "    all_documents, \n",
        "    all_labels, \n",
        "    test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Orawct1ar389",
        "outputId": "02e687bc-eb5e-421a-a930-db237b78ed6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "len(all_query_ids2) : 8000\n",
            "len(all_queries2) : 8000\n",
            "len(all_document_ids2) : 8000\n",
            "len(all_documents2) : 8000\n",
            "len(all_labels2) : 8000\n",
            "len(all_query_ids) : 8000\n",
            "len(all_queries) : 8000\n",
            "len(all_document_ids) : 8000\n",
            "len(all_documents) : 8000\n",
            "len(all_labels) : 8000\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import sys\n",
        "\n",
        "csv.field_size_limit(sys.maxsize)\n",
        "\n",
        "\n",
        "fr1 = open(\"/content/drive/MyDrive/collectionandqueries/all_query_ids.tsv\", \"r\")\n",
        "fr2 = open(\"/content/drive/MyDrive/collectionandqueries/all_queries.tsv\", \"r\")\n",
        "fr3 = open(\"/content/drive/MyDrive/collectionandqueries/all_document_ids.tsv\", \"r\")\n",
        "fr4 = open(\"/content/drive/MyDrive/collectionandqueries/all_documents.tsv\", \"r\")\n",
        "fr5 = open(\"/content/drive/MyDrive/collectionandqueries/all_labels.tsv\", \"r\")\n",
        "\n",
        "input_file1 = csv.reader(fr1, delimiter = \"\\t\")\n",
        "input_file2 = csv.reader(fr2, delimiter = \"\\t\")\n",
        "input_file3 = csv.reader(fr3, delimiter = \"\\t\")\n",
        "input_file4 = csv.reader(fr4, delimiter = \"\\t\")\n",
        "input_file5 = csv.reader(fr5, delimiter = \"\\t\")\n",
        "\n",
        "all_query_ids2 = []\n",
        "all_queries2 = []\n",
        "all_document_ids2 = []\n",
        "all_documents2 = []\n",
        "all_labels2 = []\n",
        "\n",
        "for w in input_file1: \n",
        "    #print('w : ' + str(w[0]))\n",
        "    all_query_ids2.append(w[0])\n",
        "\n",
        "for w in input_file2: \n",
        "    all_queries2.append(w[0])\n",
        "\n",
        "for w in input_file3: \n",
        "    all_document_ids2.append(w[0])\n",
        "\n",
        "for w in input_file4: \n",
        "    all_documents2.append(w[0])\n",
        "\n",
        "for w in input_file5: \n",
        "    all_labels2.append(w[0]) \n",
        "\n",
        "print('len(all_query_ids2) : ' + str(len(all_query_ids2)))\n",
        "print('len(all_queries2) : ' + str(len(all_queries2)))\n",
        "print('len(all_document_ids2) : ' + str(len(all_document_ids2)))\n",
        "print('len(all_documents2) : ' + str(len(all_documents2)))\n",
        "print('len(all_labels2) : ' + str(len(all_labels2)))\n",
        "\n",
        "all_query_ids = []\n",
        "all_queries = []\n",
        "all_document_ids = []\n",
        "all_documents = []\n",
        "all_labels = []\n",
        "\n",
        "length = len(all_query_ids2)\n",
        "index = 0\n",
        "\n",
        "for index in range(0, length): \n",
        "    #print('index : ' + str(index))\n",
        "    all_query_ids.append(all_query_ids2[index])\n",
        "    all_queries.append(all_queries2[index])\n",
        "    all_document_ids.append(all_document_ids2[index])\n",
        "    all_documents.append(all_documents2[index])\n",
        "    all_labels.append(int(all_labels2[index]))\n",
        "    \"\"\"\n",
        "    print('all_query_ids2[index] : ' + all_query_ids2[index])\n",
        "    print('all_queries2[index] : ' + all_queries2[index])\n",
        "    print('all_document_ids2[index] : ' + all_document_ids2[index])\n",
        "    print('all_documents2[index] : ' + all_documents2[index])\n",
        "    print('all_labels2[index] : ' + all_labels2[index])\n",
        "    \"\"\"\n",
        "\n",
        "print('len(all_query_ids) : ' + str(len(all_query_ids)))\n",
        "print('len(all_queries) : ' + str(len(all_queries)))\n",
        "print('len(all_document_ids) : ' + str(len(all_document_ids)))\n",
        "print('len(all_documents) : ' + str(len(all_documents)))\n",
        "print('len(all_labels) : ' + str(len(all_labels)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7k3YtYtsr8qL",
        "outputId": "9f1ce957-0ebc-4153-be54-3add552ed0bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8000\n",
            "8000\n",
            "6400\n",
            "1600\n",
            "6400\n",
            "1600\n",
            "6400\n",
            "1600\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "print(len(all_queries))\n",
        "print(len(all_documents))\n",
        "train_queries, val_queries, train_docs, val_docs, train_labels, val_labels = train_test_split(\n",
        "    all_queries, \n",
        "    all_documents, \n",
        "    all_labels, \n",
        "    test_size=.2\n",
        "    )\n",
        "print(len(train_queries))\n",
        "print(len(val_queries))\n",
        "print(len(train_docs))\n",
        "print(len(val_docs))\n",
        "print(len(train_labels))\n",
        "print(len(val_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        },
        "id": "0BMn5iBRpPsm",
        "outputId": "ba7925c2-0bd5-4a77-a5db-5afa1285c1e5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "***** Running training *****\n",
            "  Num examples = 6400\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 800\n",
            "  Number of trainable parameters = 1026\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='800' max='800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [800/800 17:09, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Runid</th>\n",
              "      <th>Num Ret</th>\n",
              "      <th>Num Rel</th>\n",
              "      <th>Num Rel Ret</th>\n",
              "      <th>Num Q</th>\n",
              "      <th>Map</th>\n",
              "      <th>Gm Map</th>\n",
              "      <th>Bpref</th>\n",
              "      <th>Rprec</th>\n",
              "      <th>Recip Rank</th>\n",
              "      <th>P@5</th>\n",
              "      <th>P@10</th>\n",
              "      <th>P@15</th>\n",
              "      <th>P@20</th>\n",
              "      <th>P@30</th>\n",
              "      <th>P@100</th>\n",
              "      <th>P@200</th>\n",
              "      <th>P@500</th>\n",
              "      <th>P@1000</th>\n",
              "      <th>Ndcg@5</th>\n",
              "      <th>Ndcg@10</th>\n",
              "      <th>Ndcg@15</th>\n",
              "      <th>Ndcg@20</th>\n",
              "      <th>Ndcg@30</th>\n",
              "      <th>Ndcg@100</th>\n",
              "      <th>Ndcg@200</th>\n",
              "      <th>Ndcg@500</th>\n",
              "      <th>Ndcg@1000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.451969</td>\n",
              "      <td>test</td>\n",
              "      <td>1600</td>\n",
              "      <td>813</td>\n",
              "      <td>813</td>\n",
              "      <td>1391</td>\n",
              "      <td>0.434220</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.434220</td>\n",
              "      <td>0.434220</td>\n",
              "      <td>0.116894</td>\n",
              "      <td>0.058447</td>\n",
              "      <td>0.038965</td>\n",
              "      <td>0.029224</td>\n",
              "      <td>0.019482</td>\n",
              "      <td>0.005845</td>\n",
              "      <td>0.002922</td>\n",
              "      <td>0.001169</td>\n",
              "      <td>0.000584</td>\n",
              "      <td>0.434220</td>\n",
              "      <td>0.434220</td>\n",
              "      <td>0.434220</td>\n",
              "      <td>0.434220</td>\n",
              "      <td>0.434220</td>\n",
              "      <td>0.434220</td>\n",
              "      <td>0.434220</td>\n",
              "      <td>0.434220</td>\n",
              "      <td>0.434220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.472400</td>\n",
              "      <td>0.390789</td>\n",
              "      <td>test</td>\n",
              "      <td>1600</td>\n",
              "      <td>813</td>\n",
              "      <td>813</td>\n",
              "      <td>1391</td>\n",
              "      <td>0.434220</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.434220</td>\n",
              "      <td>0.434220</td>\n",
              "      <td>0.116894</td>\n",
              "      <td>0.058447</td>\n",
              "      <td>0.038965</td>\n",
              "      <td>0.029224</td>\n",
              "      <td>0.019482</td>\n",
              "      <td>0.005845</td>\n",
              "      <td>0.002922</td>\n",
              "      <td>0.001169</td>\n",
              "      <td>0.000584</td>\n",
              "      <td>0.434220</td>\n",
              "      <td>0.434220</td>\n",
              "      <td>0.434220</td>\n",
              "      <td>0.434220</td>\n",
              "      <td>0.434220</td>\n",
              "      <td>0.434220</td>\n",
              "      <td>0.434220</td>\n",
              "      <td>0.434220</td>\n",
              "      <td>0.434220</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7fb0ee9ee460>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Saving model checkpoint to ./results/checkpoint-500\n",
            "Configuration saved in ./results/checkpoint-500/config.json\n",
            "Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-1500] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7fb0ee945a60>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=800, training_loss=0.45462855339050295, metrics={'train_runtime': 1030.8804, 'train_samples_per_second': 12.417, 'train_steps_per_second': 0.776, 'total_flos': 126558948556800.0, 'train_loss': 0.45462855339050295, 'epoch': 2.0})"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "from sklearn.metrics import ndcg_score\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "import evaluate\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def my_compute_metrics_ndcg(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    print ('predictions : ' + str(predictions))\n",
        "    predictions2 = tf.nn.log_softmax(predictions, axis=-1)\n",
        "    #print(classification_report(labels, predictions))\n",
        "    return ndcg_score(predictions2, labels)\n",
        "\"\"\"\n",
        "\n",
        "def my_compute_metrics_precision(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    metric = evaluate.load(\"precision\")\n",
        "    #print('predictions : ' + str(predictions))\n",
        "    #print('labels : ' + str(labels))\n",
        "    #if task != \"stsb\":\n",
        "    predictions = np.argmax(predictions, axis=-1)\n",
        "    #else:\n",
        "    #predictions = predictions[:]\n",
        "    print(classification_report(labels, predictions))\n",
        "    return metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "\n",
        "# You can define your custom compute_metrics function. It takes an `EvalPrediction` object (a namedtuple with a\n",
        "# predictions and label_ids field) and has to return a dictionary string to float.\n",
        "def compute_metrics2(pred):\n",
        "    \"\"\"\n",
        "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
        "    preds = np.argmax(preds, axis=1)\n",
        "    return metric.compute(predictions=preds, references=p.label_ids)   \n",
        "    \"\"\"\n",
        "    print('pred : ' + str(pred))\n",
        "    # Get the metric function\n",
        "    trec_eval = evaluate.load(\"trec_eval\")\n",
        "    qrel = {}\n",
        "    qids, seen, i = [], {}, 0\n",
        "    for q in val_queries:\n",
        "      if q in seen:\n",
        "        qids.append(seen[q])\n",
        "      else:\n",
        "        seen[q] = i\n",
        "        qids.append(i)\n",
        "        i+=1\n",
        "    qrel={\n",
        "      \"query\": qids,\n",
        "      \"q0\": val_queries,\n",
        "      \"docid\": val_docs,\n",
        "      \"rel\": val_labels\n",
        "    }\n",
        "    run = {\n",
        "      \"query\": qids,\n",
        "      \"q0\": val_queries,\n",
        "      \"docid\": val_docs,\n",
        "      \"rank\": pred[1].tolist(),\n",
        "      \"score\": [max(l) for l in pred[0].tolist()],\n",
        "      \"system\": [\"test\" for i in qids]\n",
        "    }    \n",
        "    results = trec_eval.compute(references=[qrel], predictions=[run]) \n",
        "    return results\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    evaluation_strategy=\"epoch\",     # Evaluation is done at the end of each epoch.\n",
        "    num_train_epochs=2,              # total number of training epochs\n",
        "    per_device_train_batch_size=16,  # batch size per device during training\n",
        "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
        "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    learning_rate=0.005,\n",
        "    save_total_limit=1,              # limit the total amount of checkpoints. Deletes the older checkpoints.    \n",
        ")\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,                         # the instantiated Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=val_dataset,             # evaluation dataset\n",
        "    compute_metrics = compute_metrics2\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "oekvbIoSuoeI",
        "outputId": "8104af26-96ac-49c1-9571-d5f98d886298"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [25/25 01:29]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7fb0eeaf28b0>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Trainer is attempting to log a value of \"test\" of type <class 'str'> for key \"eval/runid\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
          ]
        }
      ],
      "source": [
        "eval = trainer.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GshC1sCbvH1j",
        "outputId": "60fc1e91-0771-4273-eff3-8a5fb1f6c059"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "eval : {'eval_loss': 0.39078933000564575, 'eval_runid': 'test', 'eval_num_ret': 1600, 'eval_num_rel': 813, 'eval_num_rel_ret': 813, 'eval_num_q': 1391, 'eval_map': 0.43421998562185476, 'eval_gm_map': nan, 'eval_bpref': 0.0, 'eval_Rprec': 0.43421998562185476, 'eval_recip_rank': 0.43421998562185476, 'eval_P@5': 0.11689432063263838, 'eval_P@10': 0.05844716031631919, 'eval_P@15': 0.0389647735442128, 'eval_P@20': 0.029223580158159596, 'eval_P@30': 0.0194823867721064, 'eval_P@100': 0.00584471603163192, 'eval_P@200': 0.00292235801581596, 'eval_P@500': 0.001168943206326384, 'eval_P@1000': 0.000584471603163192, 'eval_NDCG@5': 0.43421998562185476, 'eval_NDCG@10': 0.43421998562185476, 'eval_NDCG@15': 0.43421998562185476, 'eval_NDCG@20': 0.43421998562185476, 'eval_NDCG@30': 0.43421998562185476, 'eval_NDCG@100': 0.43421998562185476, 'eval_NDCG@200': 0.43421998562185476, 'eval_NDCG@500': 0.43421998562185476, 'eval_NDCG@1000': 0.43421998562185476, 'eval_runtime': 105.8722, 'eval_samples_per_second': 15.113, 'eval_steps_per_second': 0.236, 'epoch': 2.0}\n"
          ]
        }
      ],
      "source": [
        "print('eval : ' + str(eval))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "jLk66v3bvPkv",
        "outputId": "745b8fb5-728c-40cb-8bda-c5d1bad7d522"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pred : <transformers.trainer_utils.EvalPrediction object at 0x7fb0ee743c10>\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "PredictionOutput(predictions=array([[-0.248337  , -0.27784067],\n",
              "       [ 0.3606272 , -0.96695346],\n",
              "       [ 0.0452804 , -0.53285766],\n",
              "       ...,\n",
              "       [-2.5073123 ,  2.3747811 ],\n",
              "       [ 0.22137338, -0.970917  ],\n",
              "       [ 0.06851742, -1.2299039 ]], dtype=float32), label_ids=array([0, 0, 0, ..., 1, 0, 1]), metrics={'test_loss': 0.39078933000564575, 'test_runid': 'test', 'test_num_ret': 1600, 'test_num_rel': 813, 'test_num_rel_ret': 813, 'test_num_q': 1391, 'test_map': 0.43421998562185476, 'test_gm_map': nan, 'test_bpref': 0.0, 'test_Rprec': 0.43421998562185476, 'test_recip_rank': 0.43421998562185476, 'test_P@5': 0.11689432063263838, 'test_P@10': 0.05844716031631919, 'test_P@15': 0.0389647735442128, 'test_P@20': 0.029223580158159596, 'test_P@30': 0.0194823867721064, 'test_P@100': 0.00584471603163192, 'test_P@200': 0.00292235801581596, 'test_P@500': 0.001168943206326384, 'test_P@1000': 0.000584471603163192, 'test_NDCG@5': 0.43421998562185476, 'test_NDCG@10': 0.43421998562185476, 'test_NDCG@15': 0.43421998562185476, 'test_NDCG@20': 0.43421998562185476, 'test_NDCG@30': 0.43421998562185476, 'test_NDCG@100': 0.43421998562185476, 'test_NDCG@200': 0.43421998562185476, 'test_NDCG@500': 0.43421998562185476, 'test_NDCG@1000': 0.43421998562185476, 'test_runtime': 96.5519, 'test_samples_per_second': 16.571, 'test_steps_per_second': 0.259})"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.predict(val_dataset)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "149d527b097749a19144d6650bda81a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b1e96b2543c4405bf1fe3fea2fc0126",
            "placeholder": "​",
            "style": "IPY_MODEL_b4d22251c6864e2cacc67a17e39d66eb",
            "value": " 5.51k/5.51k [00:00&lt;00:00, 87.6kB/s]"
          }
        },
        "159e972280a94f478457d70c3d1cfb49": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "231e397745474ef4b74df4a83c00807e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b1e96b2543c4405bf1fe3fea2fc0126": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d60327b801a4faebf4ca42c46a977fb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ee0c7020eb94ce39b391f7f16f9feba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a02d8840ce8645b1b194521e9f318488": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4d22251c6864e2cacc67a17e39d66eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d4c65e0a7d484fa09a469a693a3ca8d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_159e972280a94f478457d70c3d1cfb49",
            "placeholder": "​",
            "style": "IPY_MODEL_231e397745474ef4b74df4a83c00807e",
            "value": "Downloading builder script: 100%"
          }
        },
        "e3b15587437d4748baa53d790422daf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d60327b801a4faebf4ca42c46a977fb",
            "max": 5514,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8ee0c7020eb94ce39b391f7f16f9feba",
            "value": 5514
          }
        },
        "edb1a3a1f56243ceaf572a0642a5edf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d4c65e0a7d484fa09a469a693a3ca8d3",
              "IPY_MODEL_e3b15587437d4748baa53d790422daf7",
              "IPY_MODEL_149d527b097749a19144d6650bda81a1"
            ],
            "layout": "IPY_MODEL_a02d8840ce8645b1b194521e9f318488"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
